{
  "success": true,
  "arxiv_id": "2510.27656v1",
  "processed_content": {
    "success": true,
    "arxiv_id": "2510.27656v1",
    "metadata": {
      "arxiv_id": "2510.27656v1",
      "authors": [],
      "abstract": "Emerging Large Language Model (LLM) system patterns, such as disaggregated inference, Mixture-of-Experts (MoE) routing, and asynchronous reinforcement fine-tuning, require flexible point-to-point communication beyond simple collectives.\nExisting implementations are locked to specific Network Interface Controllers (NICs), hindering integration into inference engines and portability across hardware providers.\nWe present TransferEngine, which bridges the functionality of common NICs to expose a uniform interface.\nTransferEngine exposes one-sided WriteImm operations with a ImmCounter primitive for completion notification, without ordering assumptions of network transport, transparently managing multiple NICs per GPU.\nWe demonstrate peak throughput of 400 Gbps on both NVIDIA ConnectX-7 and AWS Elastic Fabric Adapter (EFA).\nWe showcase TransferEngine through three production systems: (1) KvCache transfer for disaggregated inference with dynamic scaling, (2) RL weight updates achieving 1.3 seconds for trillion-parameter models, and (3) MoE dispatch/combine implementation exceeding DeepEP decode latency on ConnectX-7, with the first viable latencies on EFA. We demonstrate that our portable point-to-point communication complements collectives while avoiding lock-in."
    },
    "content": "<div class=\"arxiv-content\">\n<div class=\"ltx_page_content\">\n<article class=\"ltx_document\">\n<div class=\"ltx_para\" id=\"p1\">\n\n</div>\n<span class=\"ltx_rule ltx_align_center\" style=\"width:100%;height:2.0pt;--ltx-bg-color:black;display:inline-block;\">\u00a0</span>\n<div class=\"ltx_para ltx_noindent ltx_align_center\" id=\"p2\">\n<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_smallcaps\">RDMA Point-to-Point Communication for LLM Systems</span></p>\n</div>\n<span class=\"ltx_rule ltx_align_center\" style=\"width:100%;height:1.0pt;--ltx-bg-color:black;display:inline-block;\">\u00a0</span>\n<div class=\"ltx_para\" id=\"p3\">\n\n</div>\n<div class=\"ltx_abstract\">\n<h6 class=\"ltx_title ltx_title_abstract\" id=\"abstract\">Abstract</h6>\n\n</div>\n<span class=\"ltx_note ltx_role_footnotetext\" id=\"footnotex1\"><sup class=\"ltx_note_mark\">\u2020</sup><span class=\"ltx_note_outer\"><span class=\"ltx_note_content\"><sup class=\"ltx_note_mark\">\u2020</sup><span class=\"ltx_note_type\">footnotetext: </span><sup class=\"ltx_sup\">1</sup>Anonymous Institution, Anonymous City, Anonymous Region, Anonymous Country.\nCorrespondence to: Anonymous Author &lt;anon.email@domain.com&gt;.\n</span></span></span>\n<section class=\"ltx_section\" id=\"S1\">\n<h2 class=\"ltx_title ltx_title_section\" id=\"1-introduction\">\n<span class=\"ltx_tag ltx_tag_section\">1 </span>Introduction</h2>\n<div class=\"ltx_para ltx_noindent\" id=\"S1.p1\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S1.p2\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S1.p3\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S1.p4\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S1.p5\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S1.p6\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S1.p7\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S1.p8\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S1.p9\">\n<p class=\"ltx_p\">The systems we present span diverse communication patterns, ranging from paged writes to bulk transfers and coordinated scatter operations, all production-deployed on heterogeneous hardware.\nOur results demonstrate that point-to-point communication complements collectives for modern LLM workloads, and that portable abstractions can avoid vendor lock-in while retaining performance.</p>\n</div>\n</section>\n<section class=\"ltx_section\" id=\"S2\">\n<h2 class=\"ltx_title ltx_title_section\" id=\"2-background-and-related-work\">\n<span class=\"ltx_tag ltx_tag_section\">2 </span>Background and Related Work</h2>\n<section class=\"ltx_subsection\" id=\"S2.SS1\">\n<h3 class=\"ltx_title ltx_title_subsection\" id=\"21-network-technology\">\n<span class=\"ltx_tag ltx_tag_subsection\">2.1 </span>Network Technology</h3>\n<section class=\"ltx_paragraph\" id=\"S2.SS1.SSS0.Px1\">\n<h5 class=\"ltx_title ltx_title_paragraph\" id=\"rdma\">RDMA</h5>\n<div class=\"ltx_para ltx_noindent\" id=\"S2.SS1.SSS0.Px1.p1\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S2.SS1.SSS0.Px1.p2\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S2.SS1.SSS0.Px1.p3\">\n\n</div>\n<figure class=\"ltx_table\" id=\"S2.T1\">\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle table table-responsive\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_th ltx_th_column\"></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">RC</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">UC</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">UD</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\">SRD</th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span class=\"ltx_text ltx_font_bold\">Ours</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">Reliability</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">\u2713</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">\u2717</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">\u2717</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">\u2713</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\"><span class=\"ltx_text\" style=\"--ltx-fg-color:#009900;\">\u2713</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\">Ordering</td>\n<td class=\"ltx_td ltx_align_center\">\u2713</td>\n<td class=\"ltx_td ltx_align_center\">\u2717</td>\n<td class=\"ltx_td ltx_align_center\">\u2717</td>\n<td class=\"ltx_td ltx_align_center\">\u2717</td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"--ltx-fg-color:#FF3B21;\">\u2717</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\">Connection</td>\n<td class=\"ltx_td ltx_align_center\">\u2713</td>\n<td class=\"ltx_td ltx_align_center\">\u2713</td>\n<td class=\"ltx_td ltx_align_center\">\u2717</td>\n<td class=\"ltx_td ltx_align_center\">\u2717</td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"--ltx-fg-color:#FF3B21;\">\u2717</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\">\n<span class=\"ltx_text ltx_font_smallcaps\">Send</span>/<span class=\"ltx_text ltx_font_smallcaps\">Recv</span>\n</td>\n<td class=\"ltx_td ltx_align_center\">\u2713</td>\n<td class=\"ltx_td ltx_align_center\">\u2713</td>\n<td class=\"ltx_td ltx_align_center\">MTU</td>\n<td class=\"ltx_td ltx_align_center\">\u2713</td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"--ltx-fg-color:#009900;\">\u2713</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><span class=\"ltx_text ltx_font_smallcaps\">WriteImm</span></td>\n<td class=\"ltx_td ltx_align_center\">\u2713</td>\n<td class=\"ltx_td ltx_align_center\">\u2713</td>\n<td class=\"ltx_td ltx_align_center\">\u2717</td>\n<td class=\"ltx_td ltx_align_center\">\u2713</td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"--ltx-fg-color:#009900;\">\u2713</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_r\"><span class=\"ltx_text ltx_font_smallcaps\">Read</span></td>\n<td class=\"ltx_td ltx_align_center\">\u2713</td>\n<td class=\"ltx_td ltx_align_center\">\u2717</td>\n<td class=\"ltx_td ltx_align_center\">\u2717</td>\n<td class=\"ltx_td ltx_align_center\">\u2713</td>\n<td class=\"ltx_td ltx_align_center\"><span class=\"ltx_text\" style=\"--ltx-fg-color:#FF3B21;\">\u2717</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">Atomic</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\">\u2713</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\">\u2717</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\">\u2717</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\">\u2713</td>\n<td class=\"ltx_td ltx_align_center ltx_border_b\"><span class=\"ltx_text\" style=\"--ltx-fg-color:#FF3B21;\">\u2717</span></td>\n</tr>\n</tbody>\n</table>\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 1: </span>Comparison of RDMA transport types</figcaption>\n</figure>\n<div class=\"ltx_para ltx_noindent\" id=\"S2.SS1.SSS0.Px1.p4\">\n\n</div>\n</section>\n</section>\n<section class=\"ltx_subsection\" id=\"S2.SS2\">\n<h3 class=\"ltx_title ltx_title_subsection\" id=\"22-programming-interface\">\n<span class=\"ltx_tag ltx_tag_subsection\">2.2 </span>Programming Interface</h3>\n<div class=\"ltx_para ltx_noindent\" id=\"S2.SS2.p1\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S2.SS2.p2\">\n\n</div>\n</section>\n<section class=\"ltx_subsection\" id=\"S2.SS3\">\n<h3 class=\"ltx_title ltx_title_subsection\" id=\"23-related-work\">\n<span class=\"ltx_tag ltx_tag_subsection\">2.3 </span>Related Work</h3>\n<div class=\"ltx_para ltx_noindent\" id=\"S2.SS3.p1\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S2.SS3.p2\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S2.SS3.p3\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S2.SS3.p4\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S2.SS3.p5\">\n\n</div>\n</section>\n</section>\n<section class=\"ltx_section\" id=\"S3\">\n<h2 class=\"ltx_title ltx_title_section\" id=\"3-transferengine\">\n<span class=\"ltx_tag ltx_tag_section\">3 </span>TransferEngine</h2>\n<div class=\"ltx_para ltx_noindent\" id=\"S3.p1\">\n\n</div>\n<section class=\"ltx_subsection\" id=\"S3.SS1\">\n<h3 class=\"ltx_title ltx_title_subsection\" id=\"31-overview-and-design-goals\">\n<span class=\"ltx_tag ltx_tag_subsection\">3.1 </span>Overview and Design Goals</h3>\n<div class=\"ltx_para ltx_noindent\" id=\"S3.SS1.p1\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S3.SS1.p2\">\n\n</div>\n</section>\n<section class=\"ltx_subsection\" id=\"S3.SS2\">\n<h3 class=\"ltx_title ltx_title_subsection\" id=\"32-architecture\">\n<span class=\"ltx_tag ltx_tag_subsection\">3.2 </span>Architecture</h3>\n<figure class=\"ltx_figure\" id=\"S3.F1\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_centering ltx_img_landscape\" height=\"425\" id=\"S3.F1.g1\" src=\"https://arxiv.org/html/x1.png\" width=\"830\"/>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_figure\">Figure 1: </span><span class=\"ltx_text ltx_font_italic\">TransferEngine</span> managing GPUs across NUMA nodes, each with multiple NICs. Commands are forwarded to workers, which respond back to the callback handler or <span class=\"ltx_text ltx_font_smallcaps\">ImmCounter</span>.</figcaption>\n</figure>\n<figure class=\"ltx_figure\" id=\"S3.F2\">\n<div class=\"ltx_listing ltx_lstlisting ltx_listing\">\n<div class=\"ltx_listing_data\"><a download=\"\" href=\"data:text/plain;base64,CiNbc2VyZGVdIHN0cnVjdCBOZXRBZGRyKEJ5dGVzKTsKI1tzZXJkZV0gc3RydWN0IE1yRGVzY3sgcHRyOiB1NjQsIHJrZXlzOiBWZWM8KE5ldEFkZHIsIHU2NCk+IH0Kc3RydWN0IE1ySGFuZGxlKE5vbk51bGw8Y192b2lkPik7IHR5cGUgT2Zmc2V0ID0gdTY0OwpzdHJ1Y3QgUGFnZXN7IGluZGljZXM6IFZlYzx1MzI+LCBzdHJpZGU6IHU2NCwgb2Zmc2V0OiBPZmZzZXQgfQpzdHJ1Y3QgUGVlckdyb3VwSGFuZGxlKHU2NCk7CnN0cnVjdCBTY2F0dGVyRHN0eyBsZW46IHU2NCwgc3JjOiBPZmZzZXQsIGRzdDogKE1yRGVzYyxPZmZzZXQpfQplbnVtIE9uRG9uZSB7IENhbGxiYWNrKGZuICgpIC0+ICgpKSwgRmxhZyhBdG9taWM8Ym9vbD4pIH0KXHBhcnRyYWl0IFRyYW5zZmVyRW5naW5lIHsKZm4gbWFpbl9hZGRyZXNzKCkgLT4gTmV0QWRkcjsKLy8gTWVtb3J5IFJlZ2lvbiBNYW5hZ2VtZW50CmZuIHJlZ19tcihwdHIsIGxlbiwgZGV2aWNlKSAtPiAoTXJIYW5kbGUsIE1yRGVzYyk7Ci8vIFR3by1zaWRlZCBTZW5kL1JlY3YKZm4gc3VibWl0X3NlbmQoYWRkcjogTmV0QWRkciwgbXNnOiAmW3U4XSwgY2I6IGZuICgpIC0+ICgpKTsKZm4gc3VibWl0X3JlY3ZzKGxlbjogdTY0LCBjbnQ6IHU2NCwgY2I6IGZuICgmW3U4XSkgLT4gKCkpOwovLyBPbmUtc2lkZWQgV3JpdGUKZm4gZXhwZWN0X2ltbV9jb3VudChpbW06IHUzMiwgY291bnQ6IHUzMiwgY2I6IGZuICgpIC0+ICgpKTsKZm4gc3VibWl0X3NpbmdsZV93cml0ZShsZW46IHU2NCwgaW1tOiBPcHRpb248dTMyPgpzcmM6IChNckhhbmRsZSwgT2Zmc2V0KSwgZHN0OiAoTXJEZXNjLCBPZmZzZXQpLCBPbkRvbmUpOwpmbiBzdWJtaXRfcGFnZWRfd3JpdGVzKHBhZ2VfbGVuOiB1NjQsIGltbTogT3B0aW9uPHUzMj4sCnNyYzogKE1ySGFuZGxlLCBQYWdlcyksIGRzdDogKE1yRGVzYywgUGFnZXMpLCBPbkRvbmUpOwovLyBPbmUtc2lkZWQgV3JpdGUgdG8gYSBncm91cCBvZiBwZWVycwpmbiBhZGRfcGVlcl9ncm91cChhZGRyczogVmVjPE5ldEFkZHI+KSAtPiBQZWVyR3JvdXBIYW5kbGU7CmZuIHN1Ym1pdF9zY2F0dGVyKGg6IE9wdGlvbjxQZWVyR3JvdXBIYW5kbGU+LCBPbkRvbmUsCmltbTogT3B0aW9uPHUzMj4sIHNyYzogTXJIYW5kbGUsIGRzdDogVmVjPFNjYXR0ZXJEc3Q+KTsKZm4gc3VibWl0X2JhcnJpZXIoaDogT3B0aW9uPFBlZXJHcm91cEhhbmRsZT4sIE9uRG9uZSwKaW1tOiB1MzIsIGRzdDogVmVjPE1yRGVzYz4pOwovLyBXYXRjaGVyIGZvciBDUFUtR1BVIHN5bmNocm9uaXphdGlvbgpmbiBhbGxvY191dm1fd2F0Y2hlcihjYjogZm4odTY0LHU2NCkgLT4gKCkpIC0+IE5vbk51bGw8dTY0PjsKfQo=\">\u2b07</a></div>\n<div class=\"ltx_listingline\" id=\"lstnumberx1\">\n</div>\n<div class=\"ltx_listingline\" id=\"lstnumberx2\">#[<span class=\"ltx_text ltx_lst_identifier\">serde</span>]<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">struct</span><span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">NetAddr</span>(<span class=\"ltx_text ltx_lst_identifier\">Bytes</span>);\n</div>\n<div class=\"ltx_listingline\" id=\"lstnumberx3\">#[<span class=\"ltx_text ltx_lst_identifier\">serde</span>]<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">struct</span><span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">MrDesc</span>{<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">ptr</span>:<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">u64</span>,<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">rkeys</span>:<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">Vec</span>&lt;(<span class=\"ltx_text ltx_lst_identifier\">NetAddr</span>,<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">u64</span>)&gt;<span class=\"ltx_text ltx_lst_space\"> </span>}\n</div>\n<div class=\"ltx_listingline\" id=\"lstnumberx4\">\n<span class=\"ltx_text ltx_lst_identifier\">struct</span><span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">MrHandle</span>(<span class=\"ltx_text ltx_lst_identifier\">NonNull</span>&lt;<span class=\"ltx_text ltx_lst_identifier\">c_void</span>&gt;);<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">type</span><span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">Offset</span><span class=\"ltx_text ltx_lst_space\"> </span>=<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">u64</span>;\n</div>\n<div class=\"ltx_listingline\" id=\"lstnumberx5\">\n<span class=\"ltx_text ltx_lst_identifier\">struct</span><span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">Pages</span>{<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">indices</span>:<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">Vec</span>&lt;<span class=\"ltx_text ltx_lst_identifier\">u32</span>&gt;,<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">stride</span>:<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">u64</span>,<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">offset</span>:<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">Offset</span><span class=\"ltx_text ltx_lst_space\"> </span>}\n</div>\n<div class=\"ltx_listingline\" id=\"lstnumberx6\">\n<span class=\"ltx_text ltx_lst_identifier\">struct</span><span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">PeerGroupHandle</span>(<span class=\"ltx_text ltx_lst_identifier\">u64</span>);\n</div>\n<div class=\"ltx_listingline\" id=\"lstnumberx7\">\n<span class=\"ltx_text ltx_lst_identifier\">struct</span><span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">ScatterDst</span>{<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">len</span>:<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">u64</span>,<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">src</span>:<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">Offset</span>,<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">dst</span>:<span class=\"ltx_text ltx_lst_space\"> </span>(<span class=\"ltx_text ltx_lst_identifier\">MrDesc</span>,<span class=\"ltx_text ltx_lst_identifier\">Offset</span>)}\n</div>\n<div class=\"ltx_listingline\" id=\"lstnumberx8\">\n<span class=\"ltx_text ltx_lst_identifier\">enum</span><span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">OnDone</span><span class=\"ltx_text ltx_lst_space\"> </span>{<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">Callback</span>(<span class=\"ltx_text ltx_lst_identifier\">fn</span><span class=\"ltx_text ltx_lst_space\"> </span>()<span class=\"ltx_text ltx_lst_space\"> </span>-&gt;<span class=\"ltx_text ltx_lst_space\"> </span>()),<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">Flag</span>(<span class=\"ltx_text ltx_lst_identifier\">Atomic</span>&lt;<span class=\"ltx_text ltx_lst_identifier\">bool</span>&gt;)<span class=\"ltx_text ltx_lst_space\"> </span>}\n</div>\n<div class=\"ltx_listingline\" id=\"lstnumberx9\">\\<span class=\"ltx_text ltx_lst_identifier\">partrait</span><span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">TransferEngine</span><span class=\"ltx_text ltx_lst_space\"> </span>{\n</div>\n<div class=\"ltx_listingline\" id=\"lstnumberx10\">\n<span class=\"ltx_text ltx_lst_identifier\">fn</span><span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">main_address</span>()<span class=\"ltx_text ltx_lst_space\"> </span>-&gt;<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">NetAddr</span>;\n</div>\n<div class=\"ltx_listingline\" id=\"lstnumberx11\">//<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">Memory</span><span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">Region</span><span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">Management</span>\n</div>\n<div class=\"ltx_listingline\" id=\"lstnumberx12\">\n<span class=\"ltx_text ltx_lst_identifier\">fn</span><span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">reg_mr</span>(<span class=\"ltx_text ltx_lst_identifier\">ptr</span>,<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">len</span>,<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">device</span>)<span class=\"ltx_text ltx_lst_space\"> </span>-&gt;<span class=\"ltx_text ltx_lst_space\"> </span>(<span class=\"ltx_text ltx_lst_identifier\">MrHandle</span>,<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">MrDesc</span>);\n</div>\n<div class=\"ltx_listingline\" id=\"lstnumberx13\">//<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">Two</span>-<span class=\"ltx_text ltx_lst_identifier\">sided</span><span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">Send</span>/<span class=\"ltx_text ltx_lst_identifier\">Recv</span>\n</div>\n<div class=\"ltx_listingline\" id=\"lstnumberx14\">\n<span class=\"ltx_text ltx_lst_identifier\">fn</span><span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">submit_send</span>(<span class=\"ltx_text ltx_lst_identifier\">addr</span>:<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">NetAddr</span>,<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">msg</span>:<span class=\"ltx_text ltx_lst_space\"> </span>&amp;[<span class=\"ltx_text ltx_lst_identifier\">u8</span>],<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">cb</span>:<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">fn</span><span class=\"ltx_text ltx_lst_space\"> </span>()<span class=\"ltx_text ltx_lst_space\"> </span>-&gt;<span class=\"ltx_text ltx_lst_space\"> </span>());\n</div>\n<div class=\"ltx_listingline\" id=\"lstnumberx15\">\n<span class=\"ltx_text ltx_lst_identifier\">fn</span><span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">submit_recvs</span>(<span class=\"ltx_text ltx_lst_identifier\">len</span>:<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">u64</span>,<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">cnt</span>:<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">u64</span>,<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">cb</span>:<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">fn</span><span class=\"ltx_text ltx_lst_space\"> </span>(&amp;[<span class=\"ltx_text ltx_lst_identifier\">u8</span>])<span class=\"ltx_text ltx_lst_space\"> </span>-&gt;<span class=\"ltx_text ltx_lst_space\"> </span>());\n</div>\n<div class=\"ltx_listingline\" id=\"lstnumberx16\">//<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">One</span>-<span class=\"ltx_text ltx_lst_identifier\">sided</span><span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">Write</span>\n</div>\n<div class=\"ltx_listingline\" id=\"lstnumberx17\">\n<span class=\"ltx_text ltx_lst_identifier\">fn</span><span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">expect_imm_count</span>(<span class=\"ltx_text ltx_lst_identifier\">imm</span>:<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">u32</span>,<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">count</span>:<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">u32</span>,<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">cb</span>:<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">fn</span><span class=\"ltx_text ltx_lst_space\"> </span>()<span class=\"ltx_text ltx_lst_space\"> </span>-&gt;<span class=\"ltx_text ltx_lst_space\"> </span>());\n</div>\n<div class=\"ltx_listingline\" id=\"lstnumberx18\">\n<span class=\"ltx_text ltx_lst_identifier\">fn</span><span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">submit_single_write</span>(<span class=\"ltx_text ltx_lst_identifier\">len</span>:<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">u64</span>,<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">imm</span>:<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">Option</span>&lt;<span class=\"ltx_text ltx_lst_identifier\">u32</span>&gt;\n</div>\n<div class=\"ltx_listingline\" id=\"lstnumberx19\">\n<span class=\"ltx_text ltx_lst_identifier\">src</span>:<span class=\"ltx_text ltx_lst_space\"> </span>(<span class=\"ltx_text ltx_lst_identifier\">MrHandle</span>,<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">Offset</span>),<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">dst</span>:<span class=\"ltx_text ltx_lst_space\"> </span>(<span class=\"ltx_text ltx_lst_identifier\">MrDesc</span>,<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">Offset</span>),<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">OnDone</span>);\n</div>\n<div class=\"ltx_listingline\" id=\"lstnumberx20\">\n<span class=\"ltx_text ltx_lst_identifier\">fn</span><span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">submit_paged_writes</span>(<span class=\"ltx_text ltx_lst_identifier\">page_len</span>:<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">u64</span>,<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">imm</span>:<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">Option</span>&lt;<span class=\"ltx_text ltx_lst_identifier\">u32</span>&gt;,\n</div>\n<div class=\"ltx_listingline\" id=\"lstnumberx21\">\n<span class=\"ltx_text ltx_lst_identifier\">src</span>:<span class=\"ltx_text ltx_lst_space\"> </span>(<span class=\"ltx_text ltx_lst_identifier\">MrHandle</span>,<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">Pages</span>),<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">dst</span>:<span class=\"ltx_text ltx_lst_space\"> </span>(<span class=\"ltx_text ltx_lst_identifier\">MrDesc</span>,<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">Pages</span>),<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">OnDone</span>);\n</div>\n<div class=\"ltx_listingline\" id=\"lstnumberx22\">//<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">One</span>-<span class=\"ltx_text ltx_lst_identifier\">sided</span><span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">Write</span><span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">to</span><span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">a</span><span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">group</span><span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">of</span><span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">peers</span>\n</div>\n<div class=\"ltx_listingline\" id=\"lstnumberx23\">\n<span class=\"ltx_text ltx_lst_identifier\">fn</span><span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">add_peer_group</span>(<span class=\"ltx_text ltx_lst_identifier\">addrs</span>:<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">Vec</span>&lt;<span class=\"ltx_text ltx_lst_identifier\">NetAddr</span>&gt;)<span class=\"ltx_text ltx_lst_space\"> </span>-&gt;<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">PeerGroupHandle</span>;\n</div>\n<div class=\"ltx_listingline\" id=\"lstnumberx24\">\n<span class=\"ltx_text ltx_lst_identifier\">fn</span><span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">submit_scatter</span>(<span class=\"ltx_text ltx_lst_identifier\">h</span>:<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">Option</span>&lt;<span class=\"ltx_text ltx_lst_identifier\">PeerGroupHandle</span>&gt;,<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">OnDone</span>,\n</div>\n<div class=\"ltx_listingline\" id=\"lstnumberx25\">\n<span class=\"ltx_text ltx_lst_identifier\">imm</span>:<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">Option</span>&lt;<span class=\"ltx_text ltx_lst_identifier\">u32</span>&gt;,<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">src</span>:<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">MrHandle</span>,<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">dst</span>:<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">Vec</span>&lt;<span class=\"ltx_text ltx_lst_identifier\">ScatterDst</span>&gt;);\n</div>\n<div class=\"ltx_listingline\" id=\"lstnumberx26\">\n<span class=\"ltx_text ltx_lst_identifier\">fn</span><span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">submit_barrier</span>(<span class=\"ltx_text ltx_lst_identifier\">h</span>:<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">Option</span>&lt;<span class=\"ltx_text ltx_lst_identifier\">PeerGroupHandle</span>&gt;,<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">OnDone</span>,\n</div>\n<div class=\"ltx_listingline\" id=\"lstnumberx27\">\n<span class=\"ltx_text ltx_lst_identifier\">imm</span>:<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">u32</span>,<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">dst</span>:<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">Vec</span>&lt;<span class=\"ltx_text ltx_lst_identifier\">MrDesc</span>&gt;);\n</div>\n<div class=\"ltx_listingline\" id=\"lstnumberx28\">//<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">Watcher</span><span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">for</span><span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">CPU</span>-<span class=\"ltx_text ltx_lst_identifier\">GPU</span><span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">synchronization</span>\n</div>\n<div class=\"ltx_listingline\" id=\"lstnumberx29\">\n<span class=\"ltx_text ltx_lst_identifier\">fn</span><span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">alloc_uvm_watcher</span>(<span class=\"ltx_text ltx_lst_identifier\">cb</span>:<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">fn</span>(<span class=\"ltx_text ltx_lst_identifier\">u64</span>,<span class=\"ltx_text ltx_lst_identifier\">u64</span>)<span class=\"ltx_text ltx_lst_space\"> </span>-&gt;<span class=\"ltx_text ltx_lst_space\"> </span>())<span class=\"ltx_text ltx_lst_space\"> </span>-&gt;<span class=\"ltx_text ltx_lst_space\"> </span><span class=\"ltx_text ltx_lst_identifier\">NonNull</span>&lt;<span class=\"ltx_text ltx_lst_identifier\">u64</span>&gt;;\n</div>\n<div class=\"ltx_listingline\" id=\"lstnumberx30\">}\n</div>\n</div>\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_figure\">Figure 2: </span><span class=\"ltx_text ltx_font_italic\">TransferEngine</span> API pseudo-code. Error handling, domain sharding, and resource releasing are omitted.</figcaption>\n</figure>\n<div class=\"ltx_para ltx_noindent\" id=\"S3.SS2.p1\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S3.SS2.p2\">\n\n</div>\n</section>\n<section class=\"ltx_subsection\" id=\"S3.SS3\">\n<h3 class=\"ltx_title ltx_title_subsection\" id=\"33-api-design\">\n<span class=\"ltx_tag ltx_tag_subsection\">3.3 </span>API Design</h3>\n<div class=\"ltx_para ltx_noindent\" id=\"S3.SS3.p1\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S3.SS3.p2\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S3.SS3.p3\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S3.SS3.p4\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S3.SS3.p5\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S3.SS3.p6\">\n<p class=\"ltx_p\">Transfers execute between two devices: it is up to the user to coordinate operations across multiple devices in a system.</p>\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S3.SS3.p7\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S3.SS3.p8\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S3.SS3.p9\">\n\n</div>\n</section>\n<section class=\"ltx_subsection\" id=\"S3.SS4\">\n<h3 class=\"ltx_title ltx_title_subsection\" id=\"34-implementation\">\n<span class=\"ltx_tag ltx_tag_subsection\">3.4 </span>Implementation</h3>\n<div class=\"ltx_para ltx_noindent\" id=\"S3.SS4.p1\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S3.SS4.p2\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S3.SS4.p3\">\n\n</div>\n</section>\n<section class=\"ltx_subsection\" id=\"S3.SS5\">\n<h3 class=\"ltx_title ltx_title_subsection\" id=\"35-hardware-specific-optimizations\">\n<span class=\"ltx_tag ltx_tag_subsection\">3.5 </span>Hardware-Specific Optimizations</h3>\n<div class=\"ltx_para ltx_noindent\" id=\"S3.SS5.p1\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S3.SS5.p2\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S3.SS5.p3\">\n\n</div>\n</section>\n</section>\n<section class=\"ltx_section\" id=\"S4\">\n<h2 class=\"ltx_title ltx_title_section\" id=\"4-kvcache-transfer\">\n<span class=\"ltx_tag ltx_tag_section\">4 </span>KvCache Transfer</h2>\n<div class=\"ltx_para ltx_noindent\" id=\"S4.p1\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S4.p2\">\n\n</div>\n<figure class=\"ltx_figure\" id=\"S4.F3\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_centering ltx_img_landscape\" height=\"480\" id=\"S4.F3.g1\" src=\"https://arxiv.org/html/x2.png\" width=\"830\"/>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_figure\">Figure 3: </span>KV transfer between prefillers and decoders</figcaption>\n</figure>\n<div class=\"ltx_para ltx_noindent\" id=\"S4.p3\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S4.p4\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S4.p5\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S4.p6\">\n<p class=\"ltx_p\">The complexity of a production-ready implementation of disaggregated decoding lies in the handling of errors and cancellation.\nCancellation triggerred by a decoder must be explicitly confirmed by the prefiller, as the KV pages cannot be reused as long as there is a possibility of a remote write clobbering them.\nWe rely on heartbeat messages between prefillers and decoders to detect transport layer failures.\nIf a prefiller node is unresponsive, requests are cancelled on the decoder after a timeout, as transfers can no longer reach it.\nA per-request cancellation token can stop all future transfers whilst also waiting after all pending operations before sending the cancellation confirmation.</p>\n</div>\n</section>\n<section class=\"ltx_section\" id=\"S5\">\n<h2 class=\"ltx_title ltx_title_section\" id=\"5-rl-rollout-weight-transfer\">\n<span class=\"ltx_tag ltx_tag_section\">5 </span>RL Rollout Weight Transfer</h2>\n<figure class=\"ltx_figure\" id=\"S5.F4\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_centering ltx_img_landscape\" height=\"377\" id=\"S5.F4.g1\" src=\"https://arxiv.org/html/x3.png\" width=\"830\"/>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_figure\">Figure 4: </span>Weight transfer data path for different approaches.</figcaption>\n</figure>\n<figure class=\"ltx_figure\" id=\"S5.F5\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_centering ltx_img_landscape\" height=\"274\" id=\"S5.F5.g1\" src=\"https://arxiv.org/html/x4.png\" width=\"830\"/>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_figure\">Figure 5: </span>Pipelined weight transfer execution.</figcaption>\n</figure>\n<div class=\"ltx_para ltx_noindent\" id=\"S5.p1\">\n\n</div>\n<section class=\"ltx_subsection\" id=\"S5.SS1\">\n<h3 class=\"ltx_title ltx_title_subsection\" id=\"51-point-to-point-weight-transfer\">\n<span class=\"ltx_tag ltx_tag_subsection\">5.1 </span>Point-to-Point Weight Transfer</h3>\n<div class=\"ltx_para ltx_noindent\" id=\"S5.SS1.p1\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S5.SS1.p2\">\n<p class=\"ltx_p\">At initialization, the controller script performs three steps:\nFirst, it gathers parameter metadata from all training and inference GPUs, including weight name, shape, dtype, and DTensor sharding.\nNext, it computes a static weight transfer schedule, mapping which training GPU sends which parameter to which inference GPU, and in what order.\nFinally, it broadcasts the schedule to all training GPUs.</p>\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S5.SS1.p3\">\n<p class=\"ltx_p\">At each training step, the controller signals training GPUs to begin sending weights.\nThe inference nodes remain unaware of the transfer, as it uses one-sided operations.</p>\n</div>\n</section>\n<section class=\"ltx_subsection\" id=\"S5.SS2\">\n<h3 class=\"ltx_title ltx_title_subsection\" id=\"52-pipelined-weight-transfer-execution\">\n<span class=\"ltx_tag ltx_tag_subsection\">5.2 </span>Pipelined Weight Transfer Execution</h3>\n<div class=\"ltx_para ltx_noindent\" id=\"S5.SS2.p1\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S5.SS2.p2\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S5.SS2.p3\">\n\n</div>\n</section>\n</section>\n<section class=\"ltx_section\" id=\"S6\">\n<h2 class=\"ltx_title ltx_title_section\" id=\"6-moe-dispatchcombine\">\n<span class=\"ltx_tag ltx_tag_section\">6 </span>MoE Dispatch/Combine</h2>\n<figure class=\"ltx_figure\" id=\"S6.F6\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_img_landscape\" height=\"120\" id=\"S6.F6.g1\" src=\"https://arxiv.org/html/x5.png\" width=\"830\"/>\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_figure\">Figure 6: </span>Dispatch and Combine GPU-CPU-NIC coordination</figcaption>\n</figure>\n<div class=\"ltx_para ltx_noindent\" id=\"S6.p1\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S6.p2\">\n<p class=\"ltx_p\">These kernels demonstrate the feasibility of proxy-based MoE dispatch with support for a wider range of network cards, such as EFA.\nConsequently, we focus on decode performance (128 tokens per rank) as it is latency-bound, suffering more significantly from the added PCIe, driver and firmware overheads across the devices involved.</p>\n</div>\n<section class=\"ltx_subsection\" id=\"S6.SS1\">\n<h3 class=\"ltx_title ltx_title_subsection\" id=\"61-architecture\">\n<span class=\"ltx_tag ltx_tag_subsection\">6.1 </span>Architecture</h3>\n<div class=\"ltx_para ltx_noindent\" id=\"S6.SS1.p1\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S6.SS1.p2\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S6.SS1.p3\">\n\n</div>\n</section>\n<section class=\"ltx_subsection\" id=\"S6.SS2\">\n<h3 class=\"ltx_title ltx_title_subsection\" id=\"62-dispatch\">\n<span class=\"ltx_tag ltx_tag_subsection\">6.2 </span>Dispatch</h3>\n<div class=\"ltx_para ltx_noindent\" id=\"S6.SS2.p1\">\n\n</div>\n<figure class=\"ltx_figure\" id=\"S6.F7\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_centering ltx_img_landscape\" height=\"422\" id=\"S6.F7.g1\" src=\"https://arxiv.org/html/x6.png\" width=\"830\"/>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_figure\">Figure 7: </span>Dispatch into private and contiguous buffers</figcaption>\n</figure>\n<div class=\"ltx_para ltx_noindent\" id=\"S6.SS2.p2\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S6.SS2.p3\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S6.SS2.p4\">\n<p class=\"ltx_p\">Write ordering in send kernels is latency-critical due to the lack of granularity in memory barriers.\nNVLink is exposed via virtual memory, transparently translating reads and writes to peer devices mapped into the current address space into transactions on the interconnect.\nLoads are universally expensive, as they block the execution pipeline until they are satisfied.\nIn contrast, stores are fire-and-forget, until a memory barrier is encountered, which blocks until all prior stores within their scope complete.\nSince both the host system and NVLink peers are within the same scope,\na barrier ensuring ordering with the host might be slowed down by previously issued writes over NVLink.\nThis is avoided by first signalling the host, then issuing NVLink writes after a grid barrier.\nThis strategy increases the total execution time of send kernels, but it reduces latency on the critical path to the first RDMA transfer.</p>\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S6.SS2.p5\">\n<p class=\"ltx_p\">With NVLink, it is usually preferable to push data from a source device to a target, saving a trip time.\nAdditionally, after the stores are acknowledged on the current device, useful work can be executed while the transfers are in-flight to the remote.\nWith dispatch, we only push the tokens to the private receive buffers, since at this stage the centralized routing information is not available to determine exactly where the rest of the tokens should be placed on the peer.\nThe receiver half of the kernel kicks off by synchronizing on the barrier and reading the remaining tokens.\nThese loads are likely to complete before the RDMA operations.</p>\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S6.SS2.p6\">\n\n</div>\n</section>\n<section class=\"ltx_subsection\" id=\"S6.SS3\">\n<h3 class=\"ltx_title ltx_title_subsection\" id=\"63-combine\">\n<span class=\"ltx_tag ltx_tag_subsection\">6.3 </span>Combine</h3>\n<div class=\"ltx_para ltx_noindent\" id=\"S6.SS3.p1\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S6.SS3.p2\">\n\n</div>\n</section>\n<section class=\"ltx_subsection\" id=\"S6.SS4\">\n<h3 class=\"ltx_title ltx_title_subsection\" id=\"64-comparison-with-deepep\">\n<span class=\"ltx_tag ltx_tag_subsection\">6.4 </span>Comparison with DeepEP</h3>\n<div class=\"ltx_para ltx_noindent\" id=\"S6.SS4.p1\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S6.SS4.p2\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S6.SS4.p3\">\n\n</div>\n</section>\n</section>\n<section class=\"ltx_section\" id=\"S7\">\n<h2 class=\"ltx_title ltx_title_section\" id=\"7-evaluation\">\n<span class=\"ltx_tag ltx_tag_section\">7 </span>Evaluation</h2>\n<div class=\"ltx_para ltx_noindent\" id=\"S7.p1\">\n\n</div>\n<figure class=\"ltx_figure\" id=\"S7.F8\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_centering ltx_img_landscape\" height=\"249\" id=\"S7.F8.g1\" src=\"https://arxiv.org/html/x7.png\" width=\"831\"/>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_figure\">Figure 8: </span>Point-to-Point communication performance</figcaption>\n</figure>\n<figure class=\"ltx_table\" id=\"S7.T2\">\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:433.6pt;height:177.9pt;vertical-align:-84.9pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(83.2pt,-34.1pt) scale(1.62269145483905,1.62269145483905) ;\">\n<table class=\"ltx_tabular ltx_guessed_headers ltx_align_middle table table-responsive\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_th ltx_th_column ltx_th_row\" colspan=\"2\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\">EFA</span></th>\n<th class=\"ltx_td ltx_th ltx_th_column\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_column\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"><span class=\"ltx_text ltx_font_bold\">CX-7</span></th>\n<th class=\"ltx_td ltx_th ltx_th_column\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt\" rowspan=\"4\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">\n<div class=\"ltx_inline-block ltx_transformed_outer\" style=\"width:8.9pt;height:30.2pt;vertical-align:-12.6pt;\"><span class=\"ltx_transformed_inner\" style=\"width:30.2pt;transform:translate(-10.6pt,-10.6pt) rotate(-90deg) ;\">\n<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Single</span></p>\n</span></div>\n</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_tt\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">64 KiB</th>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">16 Gbps</td>\n<td class=\"ltx_td ltx_border_r ltx_border_tt\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n<td class=\"ltx_td ltx_align_right ltx_border_tt\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">44 Gbps</td>\n<td class=\"ltx_td ltx_border_tt\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">256 KiB</th>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">54 Gbps</td>\n<td class=\"ltx_td ltx_border_r\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">116 Gbps</td>\n<td class=\"ltx_td\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">1 MiB</th>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">145 Gbps</td>\n<td class=\"ltx_td ltx_border_r\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">245 Gbps</td>\n<td class=\"ltx_td\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">32 MiB</th>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">336 Gbps</td>\n<td class=\"ltx_td ltx_border_r\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">378 Gbps</td>\n<td class=\"ltx_td\" style=\"padding-left:2.0pt;padding-right:2.0pt;\"></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t\" rowspan=\"4\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">\n<div class=\"ltx_inline-block ltx_transformed_outer\" style=\"width:8.9pt;height:30.6pt;vertical-align:-12.8pt;\"><span class=\"ltx_transformed_inner\" style=\"width:30.5pt;transform:translate(-10.8pt,-10.8pt) rotate(-90deg) ;\">\n<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">Paged</span></p>\n</span></div>\n</th>\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">1 KiB</th>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">17 Gbps</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">2.11M op/s</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">91 Gbps</td>\n<td class=\"ltx_td ltx_align_right ltx_border_t\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">11.10M op/s</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">8 KiB</th>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">138 Gbps</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">2.10M op/s</td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">320 Gbps</td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">4.89M op/s</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">16 KiB</th>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">274 Gbps</td>\n<td class=\"ltx_td ltx_align_right ltx_border_r\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">2.08M op/s</td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">367 Gbps</td>\n<td class=\"ltx_td ltx_align_right\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">2.80M op/s</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_b ltx_border_r\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">64 KiB</th>\n<td class=\"ltx_td ltx_align_right ltx_border_b\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">364 Gbps</td>\n<td class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.69M op/s</td>\n<td class=\"ltx_td ltx_align_right ltx_border_b\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">370 Gbps</td>\n<td class=\"ltx_td ltx_align_right ltx_border_b\" style=\"padding-left:2.0pt;padding-right:2.0pt;\">0.71M op/s</td>\n</tr>\n</tbody>\n</table>\n</span></div>\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_table\">Table 2: </span>EFA and ConnectX-7 performance comparison</figcaption>\n</figure>\n<section class=\"ltx_subsection\" id=\"S7.SS1\">\n<h3 class=\"ltx_title ltx_title_subsection\" id=\"71-point-to-point-communication\">\n<span class=\"ltx_tag ltx_tag_subsection\">7.1 </span>Point-to-Point Communication</h3>\n<div class=\"ltx_para ltx_noindent\" id=\"S7.SS1.p1\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S7.SS1.p2\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S7.SS1.p3\">\n\n</div>\n</section>\n<section class=\"ltx_subsection\" id=\"S7.SS2\">\n<h3 class=\"ltx_title ltx_title_subsection\" id=\"72-moe-dispatchcombine\">\n<span class=\"ltx_tag ltx_tag_subsection\">7.2 </span>MoE Dispatch/Combine</h3>\n<div class=\"ltx_para ltx_noindent\" id=\"S7.SS2.p1\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S7.SS2.p2\">\n\n</div>\n<section class=\"ltx_subsubsection\" id=\"S7.SS2.SSS1\">\n<h4 class=\"ltx_title ltx_title_subsubsection\" id=\"721-private-buffer-size\">\n<span class=\"ltx_tag ltx_tag_subsubsection\">7.2.1 </span>Private Buffer Size</h4>\n<figure class=\"ltx_figure\" id=\"S7.F9\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_centering ltx_img_landscape\" height=\"249\" id=\"S7.F9.g1\" src=\"https://arxiv.org/html/x8.png\" width=\"831\"/>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_figure\">Figure 9: </span>Impact of private buffer size on p50 decode latency</figcaption>\n</figure>\n<div class=\"ltx_para ltx_noindent\" id=\"S7.SS2.SSS1.p1\">\n<p class=\"ltx_p\">The private buffers were designed to hide the latency of routing information exchange.\nWe compare the median latency of total decode dispatch times while varying the number of tokens with the peak latency achieved with a buffer size that can accommodate all tokens in one burst.</p>\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S7.SS2.SSS1.p2\">\n\n</div>\n</section>\n<section class=\"ltx_subsubsection\" id=\"S7.SS2.SSS2\">\n<h4 class=\"ltx_title ltx_title_subsubsection\" id=\"722-send-and-receive-latency\">\n<span class=\"ltx_tag ltx_tag_subsubsection\">7.2.2 </span>Send and Receive Latency</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"S7.SS2.SSS2.p1\">\n\n</div>\n<figure class=\"ltx_figure\" id=\"S7.F10\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_centering ltx_img_landscape\" height=\"216\" id=\"S7.F10.g1\" src=\"https://arxiv.org/html/x9.png\" width=\"831\"/>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_figure\">Figure 10: </span>Separate Send and Receive Latency for EP=64</figcaption>\n</figure>\n<div class=\"ltx_para ltx_noindent\" id=\"S7.SS2.SSS2.p2\">\n\n</div>\n<figure class=\"ltx_figure\" id=\"S7.F11\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_centering ltx_img_landscape\" height=\"223\" id=\"S7.F11.g1\" src=\"https://arxiv.org/html/x10.png\" width=\"830\"/>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_figure\">Figure 11: </span>MoE Decode Latency. Bar height is mean. Error bars show p01, p25, p50, p75, p95, p99. Error bars for <span class=\"ltx_text ltx_font_italic\">pplx</span> indicate stddev.</figcaption>\n</figure>\n<figure class=\"ltx_figure\" id=\"S7.F12\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_centering ltx_img_landscape\" height=\"124\" id=\"S7.F12.g1\" src=\"https://arxiv.org/html/x11.png\" width=\"830\"/>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_figure\">Figure 12: </span>MoE Prefill Latency. Bar height is mean. Error bars show p01, p25, p50, p75, p95, p99.</figcaption>\n</figure>\n</section>\n<section class=\"ltx_subsubsection\" id=\"S7.SS2.SSS3\">\n<h4 class=\"ltx_title ltx_title_subsubsection\" id=\"723-decode-latency\">\n<span class=\"ltx_tag ltx_tag_subsubsection\">7.2.3 </span>Decode Latency</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"S7.SS2.SSS3.p1\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S7.SS2.SSS3.p2\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S7.SS2.SSS3.p3\">\n<p class=\"ltx_p\">Inter-node on 16 and 32 ranks our kernels outperform DeepEP on both dispatch and combine, largely due to the bulk transfers and efficient pipelining in the combine phase.\nThe ordering of RDMA and NVLink writes also helps reduce the latency to the first RDMA transfer.\nWhen scaling to 64 ranks, combine still outperforms DeepEP, but the CPU overhead of the proxy thread becomes noticable and dispatch is slower due to the roughly microsecond overhead of enqueuing a transfer for each of the 56 inter-node peers.</p>\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S7.SS2.SSS3.p4\">\n<p class=\"ltx_p\">Since the bandwidth is not saturated by decode, EFA latencies are trailing behind by only 30%, despite 256KiB writes achieving less than half of the ConnectX-7 throughput.</p>\n</div>\n</section>\n<section class=\"ltx_subsubsection\" id=\"S7.SS2.SSS4\">\n<h4 class=\"ltx_title ltx_title_subsubsection\" id=\"724-prefill-latency\">\n<span class=\"ltx_tag ltx_tag_subsubsection\">7.2.4 </span>Prefill Latency</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"S7.SS2.SSS4.p1\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S7.SS2.SSS4.p2\">\n\n</div>\n</section>\n</section>\n</section>\n<section class=\"ltx_section\" id=\"S8\">\n<h2 class=\"ltx_title ltx_title_section\" id=\"8-conclusion\">\n<span class=\"ltx_tag ltx_tag_section\">8 </span>Conclusion</h2>\n<div class=\"ltx_para ltx_noindent\" id=\"S8.p1\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S8.p2\">\n\n</div>\n</section>\n<section class=\"ltx_section\" id=\"Sx1\">\n<h2 class=\"ltx_title ltx_title_section\" id=\"acknowledgements\">Acknowledgements</h2>\n<div class=\"ltx_para ltx_noindent\" id=\"Sx1.p1\">\n<p class=\"ltx_p\">We thank NVIDIA for generously providing access to the ConnectX-7 hardware for our evaluations, alongside valuable insights towards maximizing performance on H200 GPUs.\nWe thank AWS for their insights and advice towards improving performance on EFA.</p>\n</div>\n</section>\n<section class=\"ltx_bibliography\" id=\"bib\">\n<h2 class=\"ltx_title ltx_title_bibliography\" id=\"references\">References</h2>\n<ul class=\"ltx_biblist\">\n<li class=\"ltx_bibitem\" id=\"bib.bib1\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Agostini et\u00a0al. (2018)</span>\n<span class=\"ltx_bibblock\">\nAgostini, E., Rossetti, D., and Potluri, S.\n\n</span>\n<span class=\"ltx_bibblock\">GPUDirect async: Exploring GPU synchronous communication\ntechniques for InfiniBand clusters.\n\n</span>\n<span class=\"ltx_bibblock\"><em class=\"ltx_emph ltx_font_italic\">J. Parallel Distributed Comput.</em>, 114:28\u201345, 2018.\n\n</span>\n<span class=\"ltx_bibblock\">doi: <span class=\"ltx_ref ltx_nolink ltx_Url ltx_ref_self\">10.1016/J.JPDC.2017.12.007</span>.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://doi.org/10.1016/j.jpdc.2017.12.007\" title=\"\">https://doi.org/10.1016/j.jpdc.2017.12.007</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib2\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Ainslie et\u00a0al. (2023)</span>\n<span class=\"ltx_bibblock\">\nAinslie, J., Lee-Thorp, J., De\u00a0Jong, M., Zemlyanskiy, Y., Lebr\u00f3n, F., and\nSanghai, S.\n\n</span>\n<span class=\"ltx_bibblock\">Gqa: Training generalized multi-query transformer models from\nmulti-head checkpoints.\n\n</span>\n<span class=\"ltx_bibblock\"><em class=\"ltx_emph ltx_font_italic\">arXiv preprint arXiv:2305.13245</em>, 2023.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib3\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Alibaba Cloud (2025)</span>\n<span class=\"ltx_bibblock\">\nAlibaba Cloud.\n\n</span>\n<span class=\"ltx_bibblock\">Elastic compute service: eRDMA, 2025.\n\n</span>\n<span class=\"ltx_bibblock\">URL\n<a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://www.alibabacloud.com/help/en/ecs/user-guide/elastic-rdma-erdma/\" title=\"\">https://www.alibabacloud.com/help/en/ecs/user-guide/elastic-rdma-erdma/</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib4\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Chang et\u00a0al. (2024)</span>\n<span class=\"ltx_bibblock\">\nChang, L.-W., Bao, W., Hou, Q., Jiang, C., Zheng, N., Zhong, Y., Zhang, X.,\nSong, Z., Jiang, Z., Lin, H., Jin, X., and Liu, X.\n\n</span>\n<span class=\"ltx_bibblock\">Flux: Fast software-based communication overlap on gpus through\nkernel fusion, 2024.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib5\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">DeepSeek AI (2025)</span>\n<span class=\"ltx_bibblock\">\nDeepSeek AI.\n\n</span>\n<span class=\"ltx_bibblock\">Fire-flyer file system (3fs).\n\n</span>\n<span class=\"ltx_bibblock\"><a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://github.com/deepseek-ai/3FS\" title=\"\">https://github.com/deepseek-ai/3FS</a>, 2025.\n\n</span>\n<span class=\"ltx_bibblock\">High-performance distributed file system for AI training and\ninference workloads.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib6\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">DeepSeek-AI et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nDeepSeek-AI, Liu, A., Feng, B., Xue, B., Wang, B., Wu, B., Lu, C., Zhao, C.,\nDeng, C., Zhang, C., Ruan, C., Dai, D., Guo, D., Yang, D., Chen, D., Ji, D.,\nLi, E., Lin, F., Dai, F., Luo, F., Hao, G., Chen, G., Li, G., Zhang, H., Bao,\nH., Xu, H., Wang, H., Zhang, H., Ding, H., Xin, H., Gao, H., Li, H., Qu, H.,\nCai, J.\u00a0L., Liang, J., Guo, J., Ni, J., Li, J., Wang, J., Chen, J., Chen, J.,\nYuan, J., Qiu, J., Li, J., Song, J., Dong, K., Hu, K., Gao, K., Guan, K.,\nHuang, K., Yu, K., Wang, L., Zhang, L., Xu, L., Xia, L., Zhao, L., Wang, L.,\nZhang, L., Li, M., Wang, M., Zhang, M., Zhang, M., Tang, M., Li, M., Tian,\nN., Huang, P., Wang, P., Zhang, P., Wang, Q., Zhu, Q., Chen, Q., Du, Q.,\nChen, R.\u00a0J., Jin, R.\u00a0L., Ge, R., Zhang, R., Pan, R., Wang, R., Xu, R., Zhang,\nR., Chen, R., Li, S.\u00a0S., Lu, S., Zhou, S., Chen, S., Wu, S., Ye, S., Ye, S.,\nMa, S., Wang, S., Zhou, S., Yu, S., Zhou, S., Pan, S., Wang, T., Yun, T.,\nPei, T., Sun, T., Xiao, W.\u00a0L., Zeng, W., Zhao, W., An, W., Liu, W., Liang,\nW., Gao, W., Yu, W., Zhang, W., Li, X.\u00a0Q., Jin, X., Wang, X., Bi, X., Liu,\nX., Wang, X., Shen, X., Chen, X., Zhang, X., Chen, X., Nie, X., Sun, X.,\nWang, X., Cheng, X., Liu, X., Xie, X., Liu, X., Yu, X., Song, X., Shan, X.,\nZhou, X., Yang, X., Li, X., Su, X., Lin, X., Li, Y.\u00a0K., Wang, Y.\u00a0Q., Wei,\nY.\u00a0X., Zhu, Y.\u00a0X., Zhang, Y., Xu, Y., Xu, Y., Huang, Y., Li, Y., Zhao, Y.,\nSun, Y., Li, Y., Wang, Y., Yu, Y., Zheng, Y., Zhang, Y., Shi, Y., Xiong, Y.,\nHe, Y., Tang, Y., Piao, Y., Wang, Y., Tan, Y., Ma, Y., Liu, Y., Guo, Y., Wu,\nY., Ou, Y., Zhu, Y., Wang, Y., Gong, Y., Zou, Y., He, Y., Zha, Y., Xiong, Y.,\nMa, Y., Yan, Y., Luo, Y., You, Y., Liu, Y., Zhou, Y., Wu, Z.\u00a0F., Ren, Z.\u00a0Z.,\nRen, Z., Sha, Z., Fu, Z., Xu, Z., Huang, Z., Zhang, Z., Xie, Z., Zhang, Z.,\nHao, Z., Gou, Z., Ma, Z., Yan, Z., Shao, Z., Xu, Z., Wu, Z., Zhang, Z., Li,\nZ., Gu, Z., Zhu, Z., Liu, Z., Li, Z., Xie, Z., Song, Z., Gao, Z., and Pan, Z.\n\n</span>\n<span class=\"ltx_bibblock\">Deepseek-v3 technical report, 2025.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2412.19437\" title=\"\">https://arxiv.org/abs/2412.19437</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib7\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Fu et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nFu, W., Gao, J., Shen, X., Zhu, C., Mei, Z., He, C., Xu, S., Wei, G., Mei, J.,\nWang, J., Yang, T., Yuan, B., and Wu, Y.\n\n</span>\n<span class=\"ltx_bibblock\">Areal: A large-scale asynchronous reinforcement learning system for\nlanguage reasoning, 2025.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2505.24298\" title=\"\">https://arxiv.org/abs/2505.24298</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib8\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">He et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nHe, B., Zhu, Z., and Li, J.\n\n</span>\n<span class=\"ltx_bibblock\">Efficient rl training - optimizing weight sync in slime.\n\n</span>\n<span class=\"ltx_bibblock\"><a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://hebiao064.github.io/rl-weight-sync\" title=\"\">https://hebiao064.github.io/rl-weight-sync</a>, 2025.\n\n</span>\n<span class=\"ltx_bibblock\">Accessed: 2025-10-14.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib9\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Hu et\u00a0al. (2025a)</span>\n<span class=\"ltx_bibblock\">\nHu, J., Wu, X., Shen, W., Liu, J.\u00a0K., Zhu, Z., Wang, W., Jiang, S., Wang, H.,\nChen, H., Chen, B., Fang, W., Xianyu, Cao, Y., Xu, H., and Liu, Y.\n\n</span>\n<span class=\"ltx_bibblock\">Openrlhf: An easy-to-use, scalable and high-performance rlhf\nframework, 2025a.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2405.11143\" title=\"\">https://arxiv.org/abs/2405.11143</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib10\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Hu et\u00a0al. (2025b)</span>\n<span class=\"ltx_bibblock\">\nHu, Z., Shen, S., Bonato, T., Jeaugey, S., Alexander, C., Spada, E., Dinan, J.,\nHammond, J., and Hoefler, T.\n\n</span>\n<span class=\"ltx_bibblock\">Demystifying NCCL: An in-depth analysis of GPU communication\nprotocols and algorithms, 2025b.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2507.04786\" title=\"\">https://arxiv.org/abs/2507.04786</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib11\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Huang et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nHuang, G., Chadha, P., Kong, T., Gao, W., and Li, Z.\n\n</span>\n<span class=\"ltx_bibblock\">NeMo-RL: Journey of optimizing weight transfer in large moe\nmodels by 10x.\n\n</span>\n<span class=\"ltx_bibblock\"><a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://github.com/NVIDIA-NeMo/RL/discussions/1189\" title=\"\">https://github.com/NVIDIA-NeMo/RL/discussions/1189</a>, 2025.\n\n</span>\n<span class=\"ltx_bibblock\">Accessed: 2025-10-14.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib12\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Kalia et\u00a0al. (2016)</span>\n<span class=\"ltx_bibblock\">\nKalia, A., Kaminsky, M., and Andersen, D.\u00a0G.\n\n</span>\n<span class=\"ltx_bibblock\">Design guidelines for high performance RDMA systems.\n\n</span>\n<span class=\"ltx_bibblock\">In Gulati, A. and Weatherspoon, H. (eds.), <em class=\"ltx_emph ltx_font_italic\">Proceedings of the\n2016 USENIX Annual Technical Conference, USENIX ATC 2016, Denver, CO,\nUSA, June 22-24, 2016</em>, pp.  437\u2013450. USENIX Association, 2016.\n\n</span>\n<span class=\"ltx_bibblock\">URL\n<a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://www.usenix.org/conference/atc16/technical-sessions/presentation/kalia\" title=\"\">https://www.usenix.org/conference/atc16/technical-sessions/presentation/kalia</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib13\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Kimi Team et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nKimi Team, Bai, Y., Bao, Y., Chen, G., Chen, J., Chen, N., Chen, R., Chen,\nY., Chen, Y., Chen, Y., Chen, Z., Cui, J., Ding, H., Dong, M., Du, A., Du,\nC., Du, D., Du, Y., Fan, Y., Feng, Y., Fu, K., Gao, B., Gao, H., Gao, P.,\nGao, T., Gu, X., Guan, L., Guo, H., Guo, J., Hu, H., Hao, X., He, T., He, W.,\nHe, W., Hong, C., Hu, Y., Hu, Z., Huang, W., Huang, Z., Huang, Z., Jiang, T.,\nJiang, Z., Jin, X., Kang, Y., Lai, G., Li, C., Li, F., Li, H., Li, M., Li,\nW., Li, Y., Li, Y., Li, Z., Li, Z., Lin, H., Lin, X., Lin, Z., Liu, C., Liu,\nC., Liu, H., Liu, J., Liu, J., Liu, L., Liu, S., Liu, T.\u00a0Y., Liu, T., Liu,\nW., Liu, Y., Liu, Y., Liu, Y., Liu, Y., Liu, Z., Lu, E., Lu, L., Ma, S., Ma,\nX., Ma, Y., Mao, S., Mei, J., Men, X., Miao, Y., Pan, S., Peng, Y., Qin, R.,\nQu, B., Shang, Z., Shi, L., Shi, S., Song, F., Su, J., Su, Z., Sun, X., Sung,\nF., Tang, H., Tao, J., Teng, Q., Wang, C., Wang, D., Wang, F., Wang, H.,\nWang, J., Wang, J., Wang, J., Wang, S., Wang, S., Wang, Y., Wang, Y., Wang,\nY., Wang, Y., Wang, Y., Wang, Z., Wang, Z., Wang, Z., Wei, C., Wei, Q., Wu,\nW., Wu, X., Wu, Y., Xiao, C., Xie, X., Xiong, W., Xu, B., Xu, J., Xu, J., Xu,\nL.\u00a0H., Xu, L., Xu, S., Xu, W., Xu, X., Xu, Y., Xu, Z., Yan, J., Yan, Y.,\nYang, X., Yang, Y., Yang, Z., Yang, Z., Yang, Z., Yao, H., Yao, X., Ye, W.,\nYe, Z., Yin, B., Yu, L., Yuan, E., Yuan, H., Yuan, M., Zhan, H., Zhang, D.,\nZhang, H., Zhang, W., Zhang, X., Zhang, Y., Zhang, Y., Zhang, Y., Zhang, Y.,\nZhang, Y., Zhang, Y., Zhang, Z., Zhao, H., Zhao, Y., Zheng, H., Zheng, S.,\nZhou, J., Zhou, X., Zhou, Z., Zhu, Z., Zhuang, W., and Zu, X.\n\n</span>\n<span class=\"ltx_bibblock\">Kimi k2: Open agentic intelligence, 2025.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2507.20534\" title=\"\">https://arxiv.org/abs/2507.20534</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib14\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Kwon et\u00a0al. (2023)</span>\n<span class=\"ltx_bibblock\">\nKwon, W., Li, Z., Zhuang, S., Sheng, Y., Zheng, L., Yu, C.\u00a0H., Gonzalez, J.,\nZhang, H., and Stoica, I.\n\n</span>\n<span class=\"ltx_bibblock\">Efficient memory management for large language model serving with\npagedattention.\n\n</span>\n<span class=\"ltx_bibblock\">In Flinn, J., Seltzer, M.\u00a0I., Druschel, P., Kaufmann, A., and Mace,\nJ. (eds.), <em class=\"ltx_emph ltx_font_italic\">Proceedings of the 29th Symposium on Operating Systems\nPrinciples, SOSP 2023, Koblenz, Germany, October 23-26, 2023</em>, pp. 611\u2013626. ACM, 2023.\n\n</span>\n<span class=\"ltx_bibblock\">doi: <span class=\"ltx_ref ltx_nolink ltx_Url ltx_ref_self\">10.1145/3600006.3613165</span>.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://doi.org/10.1145/3600006.3613165\" title=\"\">https://doi.org/10.1145/3600006.3613165</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib15\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Langer et\u00a0al. (2021)</span>\n<span class=\"ltx_bibblock\">\nLanger, A., Howell, S., Potluri, S., Dinan, J., and Kraus, J.\n\n</span>\n<span class=\"ltx_bibblock\">Dynamic symmetric heap allocation in NVSHMEM.\n\n</span>\n<span class=\"ltx_bibblock\">In <em class=\"ltx_emph ltx_font_italic\">OpenSHMEM and Related Technologies. OpenSHMEM in the Era of\nExascale and Smart Networks: 8th Workshop on OpenSHMEM and Related\nTechnologies, OpenSHMEM 2021, Virtual Event, September 14\u201316, 2021, Revised\nSelected Papers</em>, pp.  187\u2013198, Berlin, Heidelberg, 2021. Springer-Verlag.\n\n</span>\n<span class=\"ltx_bibblock\">ISBN 978-3-031-04887-6.\n\n</span>\n<span class=\"ltx_bibblock\">doi: <span class=\"ltx_ref ltx_nolink ltx_Url ltx_ref_self\">10.1007/978-3-031-04888-3\u02d912</span>.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://doi.org/10.1007/978-3-031-04888-3_12\" title=\"\">https://doi.org/10.1007/978-3-031-04888-3_12</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib16\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Li et\u00a0al. (2020)</span>\n<span class=\"ltx_bibblock\">\nLi, S., Zhao, Y., Varma, R., Salpekar, O., Noordhuis, P., Li, T., Paszke, A.,\nSmith, J., Vaughan, B., Damania, P., and Chintala, S.\n\n</span>\n<span class=\"ltx_bibblock\">PyTorch Distributed: Experiences on accelerating data parallel\ntraining.\n\n</span>\n<span class=\"ltx_bibblock\"><em class=\"ltx_emph ltx_font_italic\">Proc. VLDB Endow.</em>, 13(12):3005\u20133018,\n2020.\n\n</span>\n<span class=\"ltx_bibblock\">doi: <span class=\"ltx_ref ltx_nolink ltx_Url ltx_ref_self\">10.14778/3415478.3415530</span>.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"http://www.vldb.org/pvldb/vol13/p3005-li.pdf\" title=\"\">http://www.vldb.org/pvldb/vol13/p3005-li.pdf</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib17\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Licker et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nLicker, N., Hu, K., Zaytsev, V., and Chen, L.\n\n</span>\n<span class=\"ltx_bibblock\">pplx-kernels: Perplexity MoE kernels.\n\n</span>\n<span class=\"ltx_bibblock\"><a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://github.com/perplexityai/pplx-kernels\" title=\"\">https://github.com/perplexityai/pplx-kernels</a>, 2025.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib18\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Liu et\u00a0al. (2024)</span>\n<span class=\"ltx_bibblock\">\nLiu, A., Feng, B., Wang, B., Wang, B., Liu, B., Zhao, C., Dengr, C., Ruan, C.,\nDai, D., Guo, D., et\u00a0al.\n\n</span>\n<span class=\"ltx_bibblock\">Deepseek-v2: A strong, economical, and efficient mixture-of-experts\nlanguage model.\n\n</span>\n<span class=\"ltx_bibblock\"><em class=\"ltx_emph ltx_font_italic\">arXiv preprint arXiv:2405.04434</em>, 2024.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib19\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Mao et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nMao, Z., Zhou, Y., Zhang, Y., Cui, C., Chen, Z., and Xu, Z.\n\n</span>\n<span class=\"ltx_bibblock\">Previewing UCCL-EP: Flexible and efficient expert parallelism for\ncloud and beyond.\n\n</span>\n<span class=\"ltx_bibblock\"><a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://uccl-project.github.io/posts/uccl-ep/\" title=\"\">https://uccl-project.github.io/posts/uccl-ep/</a>, 2025.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib20\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Mei et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nMei, Z., Fu, W., Li, K., Wang, G., Zhang, H., and Wu, Y.\n\n</span>\n<span class=\"ltx_bibblock\">Real: Efficient rlhf training of large language models with parameter\nreallocation.\n\n</span>\n<span class=\"ltx_bibblock\">In <em class=\"ltx_emph ltx_font_italic\">Proceedings of the Eighth Conference on Machine Learning and\nSystems, MLSys 2025, Santa Clara, CA, USA, May 12-15, 2025</em>. mlsys.org, 2025.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib21\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">MPI Forum (2025)</span>\n<span class=\"ltx_bibblock\">\nMPI Forum.\n\n</span>\n<span class=\"ltx_bibblock\"><em class=\"ltx_emph ltx_font_italic\">MPI: A Message-Passing Interface Standard Version 5.0</em>, June\n2025.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://www.mpi-forum.org/docs/mpi-5.0/mpi50-report.pdf\" title=\"\">https://www.mpi-forum.org/docs/mpi-5.0/mpi50-report.pdf</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib22\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">NVIDIA (2012)</span>\n<span class=\"ltx_bibblock\">\nNVIDIA.\n\n</span>\n<span class=\"ltx_bibblock\">GPUDirect RDMA, 2012.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://docs.nvidia.com/cuda/gpudirect-rdma/\" title=\"\">https://docs.nvidia.com/cuda/gpudirect-rdma/</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib23\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">NVIDIA (2015)</span>\n<span class=\"ltx_bibblock\">\nNVIDIA.\n\n</span>\n<span class=\"ltx_bibblock\">NVIDIA collective communication library (NCCL), 2015.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://developer.nvidia.com/nccl\" title=\"\">https://developer.nvidia.com/nccl</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib24\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">NVIDIA (2023)</span>\n<span class=\"ltx_bibblock\">\nNVIDIA.\n\n</span>\n<span class=\"ltx_bibblock\">TensorRT-LLM.\n\n</span>\n<span class=\"ltx_bibblock\"><a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://github.com/ai-dynamo/nixl\" title=\"\">https://github.com/ai-dynamo/nixl</a>, 2023.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib25\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">NVIDIA (2025)</span>\n<span class=\"ltx_bibblock\">\nNVIDIA.\n\n</span>\n<span class=\"ltx_bibblock\">NIXL: NVIDIA inference xfer library.\n\n</span>\n<span class=\"ltx_bibblock\"><a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://github.com/ai-dynamo/nixl\" title=\"\">https://github.com/ai-dynamo/nixl</a>, 2025.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib26\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">OFIWG (2014)</span>\n<span class=\"ltx_bibblock\">\nOFIWG.\n\n</span>\n<span class=\"ltx_bibblock\">libfabric: Open Fabrics Interfaces (OFI), 2014.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://github.com/ofiwg/libfabric\" title=\"\">https://github.com/ofiwg/libfabric</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib27\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Patel et\u00a0al. (2024)</span>\n<span class=\"ltx_bibblock\">\nPatel, P., Choukse, E., Zhang, C., Shah, A., Goiri, \u00cd., Maleki, S., and\nBianchini, R.\n\n</span>\n<span class=\"ltx_bibblock\">Splitwise: Efficient generative LLM inference using phase\nsplitting.\n\n</span>\n<span class=\"ltx_bibblock\">In <em class=\"ltx_emph ltx_font_italic\">51st ACM/IEEE Annual International Symposium on Computer\nArchitecture, ISCA 2024, Buenos Aires, Argentina, June 29 - July 3, 2024</em>,\npp.  118\u2013132. IEEE, 2024.\n\n</span>\n<span class=\"ltx_bibblock\">doi: <span class=\"ltx_ref ltx_nolink ltx_Url ltx_ref_self\">10.1109/ISCA59077.2024.00019</span>.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://doi.org/10.1109/ISCA59077.2024.00019\" title=\"\">https://doi.org/10.1109/ISCA59077.2024.00019</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib28\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Qin et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nQin, R., Li, Z., He, W., Cui, J., Ren, F., Zhang, M., Wu, Y., Zheng, W., and\nXu, X.\n\n</span>\n<span class=\"ltx_bibblock\">Mooncake: Trading more storage for less computation \u2014 a\nKVCache-centric architecture for serving LLM chatbot.\n\n</span>\n<span class=\"ltx_bibblock\">In <em class=\"ltx_emph ltx_font_italic\">23rd USENIX Conference on File and Storage Technologies\n(FAST 25)</em>, pp.  155\u2013170, Santa Clara, CA, February 2025. USENIX\nAssociation.\n\n</span>\n<span class=\"ltx_bibblock\">ISBN 978-1-939133-45-8.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://www.usenix.org/conference/fast25/presentation/qin\" title=\"\">https://www.usenix.org/conference/fast25/presentation/qin</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib29\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Reda et\u00a0al. (2022)</span>\n<span class=\"ltx_bibblock\">\nReda, W., Canini, M., Kostic, D., and Peter, S.\n\n</span>\n<span class=\"ltx_bibblock\">RDMA is turing complete, we just did not know it yet!\n\n</span>\n<span class=\"ltx_bibblock\">In Phanishayee, A. and Sekar, V. (eds.), <em class=\"ltx_emph ltx_font_italic\">19th USENIX\nSymposium on Networked Systems Design and Implementation, NSDI 2022,\nRenton, WA, USA, April 4-6, 2022</em>, pp.  71\u201385. USENIX Association, 2022.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://www.usenix.org/conference/nsdi22/presentation/reda\" title=\"\">https://www.usenix.org/conference/nsdi22/presentation/reda</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib30\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Sergeev &amp; Balso (2018)</span>\n<span class=\"ltx_bibblock\">\nSergeev, A. and Balso, M.\u00a0D.\n\n</span>\n<span class=\"ltx_bibblock\">Horovod: fast and easy distributed deep learning in tensorflow,\n2018.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/1802.05799\" title=\"\">https://arxiv.org/abs/1802.05799</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib31\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Shah et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nShah, A., Jangda, A., Li, B., Rocha, C., Hwang, C., Jose, J., Musuvathi, M.,\nSaarikivi, O., Cheng, P., Zhou, Q., Dathathri, R., Maleki, S., and Yang, Z.\n\n</span>\n<span class=\"ltx_bibblock\">Msccl++: Rethinking gpu communication abstractions for cutting-edge\nai applications, 2025.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2504.09014\" title=\"\">https://arxiv.org/abs/2504.09014</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib32\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Shalev et\u00a0al. (2020)</span>\n<span class=\"ltx_bibblock\">\nShalev, L., Ayoub, H., Bshara, N., and Sabbag, E.\n\n</span>\n<span class=\"ltx_bibblock\">A cloud-optimized transport protocol for elastic and scalable HPC.\n\n</span>\n<span class=\"ltx_bibblock\"><em class=\"ltx_emph ltx_font_italic\">IEEE Micro</em>, 40(6):67\u201373, 2020.\n\n</span>\n<span class=\"ltx_bibblock\">doi: <span class=\"ltx_ref ltx_nolink ltx_Url ltx_ref_self\">10.1109/MM.2020.3016891</span>.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://doi.org/10.1109/MM.2020.3016891\" title=\"\">https://doi.org/10.1109/MM.2020.3016891</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib33\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Shamis et\u00a0al. (2015)</span>\n<span class=\"ltx_bibblock\">\nShamis, P., Venkata, M.\u00a0G., Lopez, M.\u00a0G., Baker, M.\u00a0B., Hernandez, O., Itigin,\nY., Dubman, M., Shainer, G., Graham, R.\u00a0L., Liss, L., et\u00a0al.\n\n</span>\n<span class=\"ltx_bibblock\">UCX: an open source framework for HPC network APIs and beyond.\n\n</span>\n<span class=\"ltx_bibblock\">In <em class=\"ltx_emph ltx_font_italic\">2015 IEEE 23rd Annual Symposium on High-Performance\nInterconnects</em>, pp.  40\u201343. IEEE, 2015.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib34\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Shazeer et\u00a0al. (2017)</span>\n<span class=\"ltx_bibblock\">\nShazeer, N., Mirhoseini, A., Maziarz, K., Davis, A., Le, Q.\u00a0V., Hinton, G.\u00a0E.,\nand Dean, J.\n\n</span>\n<span class=\"ltx_bibblock\">Outrageously large neural networks: The sparsely-gated\nmixture-of-experts layer.\n\n</span>\n<span class=\"ltx_bibblock\">In <em class=\"ltx_emph ltx_font_italic\">5th International Conference on Learning Representations,\nICLR 2017, Toulon, France, April 24-26, 2017, Conference Track\nProceedings</em>. OpenReview.net, 2017.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://openreview.net/forum?id=B1ckMDqlg\" title=\"\">https://openreview.net/forum?id=B1ckMDqlg</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib35\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Sheng et\u00a0al. (2024)</span>\n<span class=\"ltx_bibblock\">\nSheng, G., Zhang, C., Ye, Z., Wu, X., Zhang, W., Zhang, R., Peng, Y., Lin, H.,\nand Wu, C.\n\n</span>\n<span class=\"ltx_bibblock\">Hybridflow: A flexible and efficient rlhf framework.\n\n</span>\n<span class=\"ltx_bibblock\"><em class=\"ltx_emph ltx_font_italic\">arXiv preprint arXiv: 2409.19256</em>, 2024.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib36\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Shi et\u00a0al. (2014)</span>\n<span class=\"ltx_bibblock\">\nShi, R., Potluri, S., Hamidouche, K., Perkins, J.\u00a0L., Li, M., Rossetti, D., and\nPanda, D.\u00a0K.\n\n</span>\n<span class=\"ltx_bibblock\">Designing efficient small message transfer mechanism for inter-node\nMPI communication on InfiniBand GPU clusters.\n\n</span>\n<span class=\"ltx_bibblock\">In <em class=\"ltx_emph ltx_font_italic\">21st International Conference on High Performance Computing,\nHiPC 2014, Goa, India, December 17-20, 2014</em>, pp.  1\u201310. IEEE Computer\nSociety, 2014.\n\n</span>\n<span class=\"ltx_bibblock\">doi: <span class=\"ltx_ref ltx_nolink ltx_Url ltx_ref_self\">10.1109/HIPC.2014.7116873</span>.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://doi.org/10.1109/HiPC.2014.7116873\" title=\"\">https://doi.org/10.1109/HiPC.2014.7116873</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib37\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Shoeybi et\u00a0al. (2020)</span>\n<span class=\"ltx_bibblock\">\nShoeybi, M., Patwary, M., Puri, R., LeGresley, P., Casper, J., and Catanzaro,\nB.\n\n</span>\n<span class=\"ltx_bibblock\">Megatron-LM: Training multi-billion parameter language models using\nmodel parallelism, 2020.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/1909.08053\" title=\"\">https://arxiv.org/abs/1909.08053</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib38\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Singhvi et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nSinghvi, A., Dukkipati, N., Chandra, P., Wassel, H. M.\u00a0G., Sharma, N.\u00a0K.,\nRebello, A., Schuh, H., Kumar, P., Montazeri, B., Bansod, N., Thomas, S.,\nCho, I., Seibert, H.\u00a0L., Wu, B., Yang, R., Li, Y., Huang, K., Yin, Q.,\nAgarwal, A., Vaduvatha, S., Wang, W., Moshref, M., Ji, T., Wetherall, D., and\nVahdat, A.\n\n</span>\n<span class=\"ltx_bibblock\">Falcon: A reliable, low latency hardware transport.\n\n</span>\n<span class=\"ltx_bibblock\">In Curado, M., Rothenberg, C.\u00a0E., Porter, G., and Kandula, S. (eds.),\n<em class=\"ltx_emph ltx_font_italic\">Proceedings of the ACM SIGCOMM 2025 Conference, SIGCOMM 2025,\nS\u00e3o Francisco Convent, Coimbra, Portugal, September 8-11, 2025</em>, pp. 248\u2013263. ACM, 2025.\n\n</span>\n<span class=\"ltx_bibblock\">doi: <span class=\"ltx_ref ltx_nolink ltx_Url ltx_ref_self\">10.1145/3718958.3754353</span>.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://doi.org/10.1145/3718958.3754353\" title=\"\">https://doi.org/10.1145/3718958.3754353</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib39\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Wu et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nWu, B., Wang, S., Tang, Y., Ding, J., Helenowski, E., Tan, L., Xu, T., Gowda,\nT., Chen, Z., Zhu, C., Tang, X., Qian, Y., Zhu, B., and Hou, R.\n\n</span>\n<span class=\"ltx_bibblock\">LlamaRL: A distributed asynchronous reinforcement learning\nframework for efficient large-scale LLM training, 2025.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2505.24034\" title=\"\">https://arxiv.org/abs/2505.24034</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib40\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Yang et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nYang, A., Li, A., Yang, B., Zhang, B., Hui, B., Zheng, B., Yu, B., Gao, C.,\nHuang, C., Lv, C., Zheng, C., Liu, D., Zhou, F., Huang, F., Hu, F., Ge, H.,\nWei, H., Lin, H., Tang, J., Yang, J., Tu, J., Zhang, J., Yang, J., Yang, J.,\nZhou, J., Zhou, J., Lin, J., Dang, K., Bao, K., Yang, K., Yu, L., Deng, L.,\nLi, M., Xue, M., Li, M., Zhang, P., Wang, P., Zhu, Q., Men, R., Gao, R., Liu,\nS., Luo, S., Li, T., Tang, T., Yin, W., Ren, X., Wang, X., Zhang, X., Ren,\nX., Fan, Y., Su, Y., Zhang, Y., Zhang, Y., Wan, Y., Liu, Y., Wang, Z., Cui,\nZ., Zhang, Z., Zhou, Z., and Qiu, Z.\n\n</span>\n<span class=\"ltx_bibblock\">Qwen3 technical report, 2025.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2505.09388\" title=\"\">https://arxiv.org/abs/2505.09388</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib41\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Ye et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nYe, Z., Chen, L., Lai, R., Lin, W., Zhang, Y., Wang, S., Chen, T., Kasikci, B.,\nGrover, V., Krishnamurthy, A., and Ceze, L.\n\n</span>\n<span class=\"ltx_bibblock\">FlashInfer: Efficient and customizable attention engine for LLM\ninference serving, 2025.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2501.01005\" title=\"\">https://arxiv.org/abs/2501.01005</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib42\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Zhang et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nZhang, S., Zheng, N., Lin, H., Jiang, Z., Bao, W., Jiang, C., Hou, Q., Cui, W.,\nZheng, S., Chang, L.-W., Chen, Q., and Liu, X.\n\n</span>\n<span class=\"ltx_bibblock\">COMET: Fine-grained computation-communication overlapping for\nmixture-of-experts.\n\n</span>\n<span class=\"ltx_bibblock\">In <em class=\"ltx_emph ltx_font_italic\">Eighth Conference on Machine Learning and Systems</em>, 2025.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://openreview.net/forum?id=fGgQS5VW09\" title=\"\">https://openreview.net/forum?id=fGgQS5VW09</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib43\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Zhao et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nZhao, C., Zhou, S., Zhang, L., Deng, C., Xu, Z., Liu, Y., Yu, K., Li, J., and\nZhao, L.\n\n</span>\n<span class=\"ltx_bibblock\">DeepEP: an efficient expert-parallel communication library.\n\n</span>\n<span class=\"ltx_bibblock\"><a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://github.com/deepseek-ai/DeepEP\" title=\"\">https://github.com/deepseek-ai/DeepEP</a>, 2025.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib44\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Zhao et\u00a0al. (2023)</span>\n<span class=\"ltx_bibblock\">\nZhao, Y., Gu, A., Varma, R., Luo, L., Huang, C.-C., Xu, M., Wright, L.,\nShojanazeri, H., Ott, M., Shleifer, S., Desmaison, A., Balioglu, C., Damania,\nP., Nguyen, B., Chauhan, G., Hao, Y., Mathews, A., and Li, S.\n\n</span>\n<span class=\"ltx_bibblock\">PyTorch FSDP: Experiences on scaling fully sharded data parallel.\n\n</span>\n<span class=\"ltx_bibblock\"><em class=\"ltx_emph ltx_font_italic\">Proc. VLDB Endow.</em>, 16(12):3848\u20133860,\nAugust 2023.\n\n</span>\n<span class=\"ltx_bibblock\">ISSN 2150-8097.\n\n</span>\n<span class=\"ltx_bibblock\">doi: <span class=\"ltx_ref ltx_nolink ltx_Url ltx_ref_self\">10.14778/3611540.3611569</span>.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://doi.org/10.14778/3611540.3611569\" title=\"\">https://doi.org/10.14778/3611540.3611569</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib45\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Zheng et\u00a0al. (2024)</span>\n<span class=\"ltx_bibblock\">\nZheng, L., Yin, L., Xie, Z., Sun, C., Huang, J., Yu, C.\u00a0H., Cao, S., Kozyrakis,\nC., Stoica, I., Gonzalez, J.\u00a0E., Barrett, C.\u00a0W., and Sheng, Y.\n\n</span>\n<span class=\"ltx_bibblock\">Sglang: Efficient execution of structured language model programs.\n\n</span>\n<span class=\"ltx_bibblock\">In Globersons, A., Mackey, L., Belgrave, D., Fan, A., Paquet, U.,\nTomczak, J.\u00a0M., and Zhang, C. (eds.), <em class=\"ltx_emph ltx_font_italic\">Advances in Neural Information\nProcessing Systems 38: Annual Conference on Neural Information Processing\nSystems 2024, NeurIPS 2024, Vancouver, BC, Canada, December 10 - 15, 2024</em>,\n2024.\n\n</span>\n<span class=\"ltx_bibblock\">URL\n<a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"http://papers.nips.cc/paper_files/paper/2024/hash/724be4472168f31ba1c9ac630f15dec8-Abstract-Conference.html\" title=\"\">http://papers.nips.cc/paper_files/paper/2024/hash/724be4472168f31ba1c9ac630f15dec8-Abstract-Conference.html</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib46\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Zheng et\u00a0al. (2025a)</span>\n<span class=\"ltx_bibblock\">\nZheng, S., Bao, W., Hou, Q., Zheng, X., Fang, J., Huang, C., Li, T., Duanmu,\nH., Chen, R., Xu, R., Guo, Y., Zheng, N., Jiang, Z., Di, X., Wang, D., Ye,\nJ., Lin, H., Chang, L.-W., Lu, L., Liang, Y., Zhai, J., and Liu, X.\n\n</span>\n<span class=\"ltx_bibblock\">Triton-distributed: Programming overlapping kernels on distributed ai\nsystems with the triton compiler, 2025a.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2504.19442\" title=\"\">https://arxiv.org/abs/2504.19442</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib47\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Zheng et\u00a0al. (2025b)</span>\n<span class=\"ltx_bibblock\">\nZheng, S., Fang, J., Zheng, X., Hou, Q., Bao, W., Zheng, N., Jiang, Z., Wang,\nD., Ye, J., Lin, H., et\u00a0al.\n\n</span>\n<span class=\"ltx_bibblock\">Tilelink: Generating efficient compute-communication overlapping\nkernels using tile-centric primitives.\n\n</span>\n<span class=\"ltx_bibblock\"><em class=\"ltx_emph ltx_font_italic\">arXiv preprint arXiv:2503.20313</em>, 2025b.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib48\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Zhong et\u00a0al. (2024)</span>\n<span class=\"ltx_bibblock\">\nZhong, Y., Liu, S., Chen, J., Hu, J., Zhu, Y., Liu, X., Jin, X., and Zhang, H.\n\n</span>\n<span class=\"ltx_bibblock\">Distserve: Disaggregating prefill and decoding for goodput-optimized\nlarge language model serving.\n\n</span>\n<span class=\"ltx_bibblock\">In Gavrilovska, A. and Terry, D.\u00a0B. (eds.), <em class=\"ltx_emph ltx_font_italic\">18th USENIX\nSymposium on Operating Systems Design and Implementation, OSDI 2024, Santa\nClara, CA, USA, July 10-12, 2024</em>, pp.  193\u2013210. USENIX Association,\n2024.\n\n</span>\n<span class=\"ltx_bibblock\">URL\n<a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://www.usenix.org/conference/osdi24/presentation/zhong-yinmin\" title=\"\">https://www.usenix.org/conference/osdi24/presentation/zhong-yinmin</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib49\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Zhou et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nZhou, Y., Chen, Z., Mao, Z., Lao, C., Yang, S., Kannan, P.\u00a0G., Gao, J., Zhao,\nY., Wu, Y., You, K., Ren, F., Xu, Z., Raiciu, C., and Stoica, I.\n\n</span>\n<span class=\"ltx_bibblock\">An extensible software transport layer for gpu networking, 2025.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2504.17307\" title=\"\">https://arxiv.org/abs/2504.17307</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib50\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Zhu et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nZhu, Z., Xie, C., Lv, X., and slime Contributors.\n\n</span>\n<span class=\"ltx_bibblock\">slime: An llm post-training framework for rl scaling.\n\n</span>\n<span class=\"ltx_bibblock\"><a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://github.com/THUDM/slime\" title=\"\">https://github.com/THUDM/slime</a>, 2025.\n\n</span>\n<span class=\"ltx_bibblock\">GitHub repository. Corresponding author: Xin Lv.\n\n</span>\n</li>\n</ul>\n</section><div about=\"\" class=\"ltx_rdf\" content=\"Anonymous Authors\" property=\"dcterms:creator\"></div>\n<div about=\"\" class=\"ltx_rdf\" property=\"dcterms:subject\"></div>\n<div about=\"\" class=\"ltx_rdf\" content=\"mlsys 2025\" property=\"dcterms:subject\"></div>\n<div about=\"\" class=\"ltx_rdf\" content=\"RDMA Point-to-Point Communication for LLM Systems\" property=\"dcterms:title\"></div>\n</article>\n</div>\n\n</div>",
    "sections": [
      {
        "id": "abstract",
        "title": "Abstract",
        "level": 6
      },
      {
        "id": "1-introduction",
        "title": "1 Introduction",
        "level": 2
      },
      {
        "id": "2-background-and-related-work",
        "title": "2 Background and Related Work",
        "level": 2
      },
      {
        "id": "21-network-technology",
        "title": "2.1 Network Technology",
        "level": 3
      },
      {
        "id": "rdma",
        "title": "RDMA",
        "level": 5
      },
      {
        "id": "22-programming-interface",
        "title": "2.2 Programming Interface",
        "level": 3
      },
      {
        "id": "23-related-work",
        "title": "2.3 Related Work",
        "level": 3
      },
      {
        "id": "3-transferengine",
        "title": "3 TransferEngine",
        "level": 2
      },
      {
        "id": "31-overview-and-design-goals",
        "title": "3.1 Overview and Design Goals",
        "level": 3
      },
      {
        "id": "32-architecture",
        "title": "3.2 Architecture",
        "level": 3
      },
      {
        "id": "33-api-design",
        "title": "3.3 API Design",
        "level": 3
      },
      {
        "id": "34-implementation",
        "title": "3.4 Implementation",
        "level": 3
      },
      {
        "id": "35-hardware-specific-optimizations",
        "title": "3.5 Hardware-Specific Optimizations",
        "level": 3
      },
      {
        "id": "4-kvcache-transfer",
        "title": "4 KvCache Transfer",
        "level": 2
      },
      {
        "id": "5-rl-rollout-weight-transfer",
        "title": "5 RL Rollout Weight Transfer",
        "level": 2
      },
      {
        "id": "51-point-to-point-weight-transfer",
        "title": "5.1 Point-to-Point Weight Transfer",
        "level": 3
      },
      {
        "id": "52-pipelined-weight-transfer-execution",
        "title": "5.2 Pipelined Weight Transfer Execution",
        "level": 3
      },
      {
        "id": "6-moe-dispatchcombine",
        "title": "6 MoE Dispatch/Combine",
        "level": 2
      },
      {
        "id": "61-architecture",
        "title": "6.1 Architecture",
        "level": 3
      },
      {
        "id": "62-dispatch",
        "title": "6.2 Dispatch",
        "level": 3
      },
      {
        "id": "63-combine",
        "title": "6.3 Combine",
        "level": 3
      },
      {
        "id": "64-comparison-with-deepep",
        "title": "6.4 Comparison with DeepEP",
        "level": 3
      },
      {
        "id": "7-evaluation",
        "title": "7 Evaluation",
        "level": 2
      },
      {
        "id": "71-point-to-point-communication",
        "title": "7.1 Point-to-Point Communication",
        "level": 3
      },
      {
        "id": "72-moe-dispatchcombine",
        "title": "7.2 MoE Dispatch/Combine",
        "level": 3
      },
      {
        "id": "721-private-buffer-size",
        "title": "7.2.1 Private Buffer Size",
        "level": 4
      },
      {
        "id": "722-send-and-receive-latency",
        "title": "7.2.2 Send and Receive Latency",
        "level": 4
      },
      {
        "id": "723-decode-latency",
        "title": "7.2.3 Decode Latency",
        "level": 4
      },
      {
        "id": "724-prefill-latency",
        "title": "7.2.4 Prefill Latency",
        "level": 4
      },
      {
        "id": "8-conclusion",
        "title": "8 Conclusion",
        "level": 2
      },
      {
        "id": "acknowledgements",
        "title": "Acknowledgements",
        "level": 2
      },
      {
        "id": "references",
        "title": "References",
        "level": 2
      }
    ],
    "has_math": true
  },
  "cached_at": 1762576364.582058
}