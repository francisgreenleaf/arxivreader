{
  "success": true,
  "arxiv_id": "2510.19773v1",
  "processed_content": {
    "success": true,
    "arxiv_id": "2510.19773v1",
    "metadata": {
      "arxiv_id": "2510.19773v1",
      "title": "The Tail Tells All: Estimating Model-Level Membership Inference Vulnerability Without Reference Models",
      "authors": [],
      "abstract": "Membership inference attacks (MIAs) have emerged as the standard tool for evaluating the privacy risks of AI models. However, state-of-the-art attacks require training numerous, often computationally expensive, reference models, limiting their practicality. We present a novel approach for estimating model-level vulnerability, the TPR at low FPR, to membership inference attacks without requiring reference models. Empirical analysis shows loss distributions to be asymmetric and heavy-tailed and suggests that most points at risk from MIAs have moved from the tail (high-loss region) to the head (low-loss region) of the distribution after training. We leverage this insight to propose a method to estimate model-level vulnerability from the training and testing distribution alone: using the absence of outliers from the high-loss region as a predictor of the risk. We evaluate our method, the TNR of a simple loss attack, across a wide range of architectures and datasets and show it to accurately estimate model-level vulnerability to the SOTA MIA attack (LiRA). We also show our method to outperform both low-cost (few reference models) attacks such as RMIA and other measures of distribution difference. We finally evaluate the use of non-linear functions to evaluate risk and show the approach to be promising to evaluate the risk in large-language models."
    },
    "content": "<div class=\"arxiv-content\">\n<div class=\"ltx_page_content\">\n<article class=\"ltx_document\">\n<h1 class=\"ltx_title ltx_title_document\" id=\"the-tail-tells-all-estimating-model-level-membership-inference-vulnerability-without-reference-models\">The Tail Tells All: Estimating Model-Level Membership Inference Vulnerability Without Reference Models</h1>\n<div class=\"ltx_authors\">\n<span class=\"ltx_creator ltx_role_author\">\n<span class=\"ltx_personname\">Euodia Dodd,\nNata\u0161a Kr\u010do,\nIgor Shilov,\nYves-Alexandre de Montjoye\n<br class=\"ltx_break\"/>Imperial College London \n<br class=\"ltx_break\"/>\n</span></span>\n</div>\n<div class=\"ltx_abstract\">\n<h6 class=\"ltx_title ltx_title_abstract\" id=\"abstract\">Abstract</h6>\n<p class=\"ltx_p\">Membership inference attacks (MIAs) have emerged as the standard tool for evaluating the privacy risks of AI models. However, state-of-the-art attacks require training numerous, often computationally expensive, reference models, limiting their practicality. We present a novel approach for estimating model-level vulnerability, the TPR at low FPR, to membership inference attacks without requiring reference models. Empirical analysis shows loss distributions to be asymmetric and heavy-tailed and suggests that most points at risk from MIAs have moved from the tail (high-loss region) to the head (low-loss region) of the distribution after training. We leverage this insight to propose a method to estimate model-level vulnerability from the training and testing distribution alone: using the absence of outliers from the high-loss region as a predictor of the risk. We evaluate our method, the TNR of a simple loss attack, across a wide range of architectures and datasets and show it to accurately estimate model-level vulnerability to the SOTA MIA attack (LiRA). We also show our method to outperform both low-cost (few reference models) attacks such as RMIA and other measures of distribution difference. We finally evaluate the use of non-linear functions to evaluate risk and show the approach to be promising to evaluate the risk in large-language models.</p>\n</div>\n<span class=\"ltx_rule ltx_align_left\" style=\"width:345.0pt;height:0.6pt;--ltx-bg-color:black;display:inline-block;\">\u00a0</span>\n<div class=\"ltx_para ltx_align_left ltx_noindent\" id=\"p1\">\n<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\" style=\"font-size:173%;\">The Tail Tells All: Estimating Model-Level Membership Inference Vulnerability Without Reference Models</span></p>\n</div>\n<div class=\"ltx_para ltx_align_left ltx_noindent\" id=\"p2\">\n\n</div>\n<section class=\"ltx_section\" id=\"S1\">\n<h2 class=\"ltx_title ltx_font_bold ltx_title_section\" id=\"1-introduction\" style=\"font-size:120%;\">1\u2002\u2004Introduction</h2>\n<div class=\"ltx_para\" id=\"S1.p1\">\n\n</div>\n<div class=\"ltx_para\" id=\"S1.p2\">\n\n</div>\n<section class=\"ltx_subsection\" id=\"S1.SS1\">\n<h3 class=\"ltx_title ltx_font_bold ltx_title_subsection\" id=\"11-problem-statement\">1.1\u2002\u2004Problem Statement</h3>\n<div class=\"ltx_para\" id=\"S1.SS1.p1\">\n\n</div>\n<div class=\"ltx_para\" id=\"S1.SS1.p2\">\n\n</div>\n<div class=\"ltx_para\" id=\"S1.SS1.p3\">\n<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">We here propose a new approach and method to estimate the vulnerability of a model to state-of-the-art membership inference attacks, leveraging new insights and using metrics available with no additional training.</span></p>\n</div>\n</section>\n<section class=\"ltx_subsection\" id=\"S1.SS2\">\n<h3 class=\"ltx_title ltx_font_bold ltx_title_subsection\" id=\"12-our-approach-measuring-whats-missing\">1.2\u2002\u2004Our Approach: Measuring what\u2019s missing</h3>\n<div class=\"ltx_para\" id=\"S1.SS2.p1\">\n<p class=\"ltx_p\">Membership inference attacks take advantage of the fact that models tend to be more confident and exhibit lower loss in their predictions for data samples they have seen during training. This differential behavior is a direct consequence of the optimization process that aims to minimize the loss with some samples being more difficult to learn than others due to their difficulty, rarity or position as outliers in the dataset distribution and being memorized.</p>\n</div>\n<div class=\"ltx_para\" id=\"S1.SS2.p2\">\n<p class=\"ltx_p\">We study train and test loss distributions across a wide range of setups and observe empirically that loss distributions tend to be asymmetric and heavy-tailed, with most samples having a near zero loss whilst a few have a much higher loss than average. We posit that the heavy tail of the test set\u2019s distribution, compared to that of the train set, is due to samples from the training set\u2019s distribution that should have a high loss (hard example) but have shifted to the low-loss region during training, having been effectively memorized.</p>\n</div>\n<div class=\"ltx_para\" id=\"S1.SS2.p3\">\n\n</div>\n<div class=\"ltx_para\" id=\"S1.SS2.p4\">\n<p class=\"ltx_p\">We also posit and empirically confirm across a wide variety of setups that samples missing from the tail of the training set distribution (high loss) constitute a significant fraction of the samples ultimately deemed to be most vulnerable to SOTA reference model-based MIAs.</p>\n</div>\n<div class=\"ltx_para\" id=\"S1.SS2.p5\">\n<p class=\"ltx_p\">Leveraging these insights, we propose a class of methods to estimate the model-level risk to SOTA MIAs from readily available train and test set loss distributions, measuring the absence of samples from the train distribution to estimate risks. In particular we show the TNR of the loss attack, its known ability to confidently identify non-members, to provide an accurate estimate of model-level risk.</p>\n</div>\n</section>\n</section>\n<section class=\"ltx_section\" id=\"S2\">\n<h2 class=\"ltx_title ltx_font_bold ltx_title_section\" id=\"2-preliminaries\" style=\"font-size:120%;\">2\u2002\u2004Preliminaries</h2>\n<section class=\"ltx_subsection\" id=\"S2.SS1\">\n<h3 class=\"ltx_title ltx_font_bold ltx_title_subsection\" id=\"21-notation\">2.1\u2002\u2004Notation</h3>\n<div class=\"ltx_para\" id=\"S2.SS1.p1\">\n\n</div>\n<div class=\"ltx_para\" id=\"S2.SS1.p2\">\n\n</div>\n<div class=\"ltx_para\" id=\"S2.SS1.p3\">\n<table class=\"ltx_equation ltx_eqn_table table table-responsive\" id=\"S2.E1\">\n<tbody><tr class=\"ltx_equation ltx_eqn_row ltx_align_baseline\">\n<td class=\"ltx_eqn_cell ltx_eqn_center_padleft\"></td>\n<td class=\"ltx_eqn_cell ltx_align_center\"><math alttext=\"A_{\\tau}(x,y,f_{\\theta})=\\begin{cases}1&amp;\\text{if }A(x,y,f_{\\theta})\\geq\\tau\\\\\n0&amp;\\text{otherwise}\\end{cases}\" class=\"ltx_Math\" display=\"block\" id=\"S2.E1.m1\" intent=\":literal\"><semantics><mrow><mrow><msub><mi>A</mi><mi>\u03c4</mi></msub><mo lspace=\"0em\" rspace=\"0em\">\u200b</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><msub><mi>f</mi><mi>\u03b8</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mo>{</mo><mtable columnspacing=\"5pt\" displaystyle=\"true\" rowspacing=\"0pt\"><mtr><mtd class=\"ltx_align_left\" columnalign=\"left\"><mn>1</mn></mtd><mtd class=\"ltx_align_left\" columnalign=\"left\"><mrow><mrow><mtext>if\u00a0</mtext><mo lspace=\"0em\" rspace=\"0em\">\u200b</mo><mi>A</mi><mo lspace=\"0em\" rspace=\"0em\">\u200b</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>,</mo><msub><mi>f</mi><mi>\u03b8</mi></msub><mo stretchy=\"false\">)</mo></mrow></mrow><mo>\u2265</mo><mi>\u03c4</mi></mrow></mtd></mtr><mtr><mtd class=\"ltx_align_left\" columnalign=\"left\"><mn>0</mn></mtd><mtd class=\"ltx_align_left\" columnalign=\"left\"><mtext>otherwise</mtext></mtd></mtr></mtable></mrow></mrow><annotation encoding=\"application/x-tex\">A_{\\tau}(x,y,f_{\\theta})=\\begin{cases}1&amp;\\text{if }A(x,y,f_{\\theta})\\geq\\tau\\\\\n0&amp;\\text{otherwise}\\end{cases}</annotation></semantics></math></td>\n<td class=\"ltx_eqn_cell ltx_eqn_center_padright\"></td>\n<td class=\"ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right\" rowspan=\"1\"><span class=\"ltx_tag ltx_tag_equation ltx_align_right\">(1)</span></td>\n</tr></tbody>\n</table>\n</div>\n<div class=\"ltx_para\" id=\"S2.SS1.p4\">\n\n<table class=\"ltx_equation ltx_eqn_table table table-responsive\" id=\"S2.E2\">\n<tbody><tr class=\"ltx_equation ltx_eqn_row ltx_align_baseline\">\n<td class=\"ltx_eqn_cell ltx_eqn_center_padleft\"></td>\n<td class=\"ltx_eqn_cell ltx_align_center\"><math alttext=\"A_{\\text{LOSS}}(x,y)=\\mathbbm{1}[-l(x,y)&gt;\\tau]\" class=\"ltx_Math\" display=\"block\" id=\"S2.E2.m1\" intent=\":literal\"><semantics><mrow><mrow><msub><mi>A</mi><mtext>LOSS</mtext></msub><mo lspace=\"0em\" rspace=\"0em\">\u200b</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mn>\ud835\udfd9</mn><mo lspace=\"0em\" rspace=\"0em\">\u200b</mo><mrow><mo stretchy=\"false\">[</mo><mrow><mrow><mo>\u2212</mo><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">\u200b</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow></mrow><mo>&gt;</mo><mi>\u03c4</mi></mrow><mo stretchy=\"false\">]</mo></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">A_{\\text{LOSS}}(x,y)=\\mathbbm{1}[-l(x,y)&gt;\\tau]</annotation></semantics></math></td>\n<td class=\"ltx_eqn_cell ltx_eqn_center_padright\"></td>\n<td class=\"ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right\" rowspan=\"1\"><span class=\"ltx_tag ltx_tag_equation ltx_align_right\">(2)</span></td>\n</tr></tbody>\n</table>\n</div>\n<div class=\"ltx_para\" id=\"S2.SS1.p5\">\n\n</div>\n<div class=\"ltx_para\" id=\"S2.SS1.p6\">\n\n</div>\n<div class=\"ltx_para\" id=\"S2.SS1.p7\">\n<table class=\"ltx_equation ltx_eqn_table table table-responsive\" id=\"S2.E3\">\n<tbody><tr class=\"ltx_equation ltx_eqn_row ltx_align_baseline\">\n<td class=\"ltx_eqn_cell ltx_eqn_center_padleft\"></td>\n<td class=\"ltx_eqn_cell ltx_align_center\"><math alttext=\"l_{in}(x,y)=\\frac{1}{K}\\sum_{k=1}^{K}l(f_{\\theta_{IN}^{k}}(x,y))\" class=\"ltx_Math\" display=\"block\" id=\"S2.E3.m1\" intent=\":literal\"><semantics><mrow><mrow><msub><mi>l</mi><mrow><mi>i</mi><mo lspace=\"0em\" rspace=\"0em\">\u200b</mo><mi>n</mi></mrow></msub><mo lspace=\"0em\" rspace=\"0em\">\u200b</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mrow><mfrac><mn>1</mn><mi>K</mi></mfrac><mo lspace=\"0em\" rspace=\"0em\">\u200b</mo><mrow><munderover><mo movablelimits=\"false\">\u2211</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><mrow><mi>l</mi><mo lspace=\"0em\" rspace=\"0em\">\u200b</mo><mrow><mo stretchy=\"false\">(</mo><mrow><msub><mi>f</mi><msubsup><mi>\u03b8</mi><mrow><mi>I</mi><mo lspace=\"0em\" rspace=\"0em\">\u200b</mo><mi>N</mi></mrow><mi>k</mi></msubsup></msub><mo lspace=\"0em\" rspace=\"0em\">\u200b</mo><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo stretchy=\"false\">)</mo></mrow></mrow></mrow></mrow></mrow><annotation encoding=\"application/x-tex\">l_{in}(x,y)=\\frac{1}{K}\\sum_{k=1}^{K}l(f_{\\theta_{IN}^{k}}(x,y))</annotation></semantics></math></td>\n<td class=\"ltx_eqn_cell ltx_eqn_center_padright\"></td>\n<td class=\"ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right\" rowspan=\"1\"><span class=\"ltx_tag ltx_tag_equation ltx_align_right\">(3)</span></td>\n</tr></tbody>\n</table>\n\n</div>\n</section>\n<section class=\"ltx_subsection\" id=\"S2.SS2\">\n<h3 class=\"ltx_title ltx_font_bold ltx_title_subsection\" id=\"22-sota-reference-model-based-membership-inference-attacks\">2.2\u2002\u2004SOTA Reference Model-Based Membership Inference Attacks</h3>\n<div class=\"ltx_para\" id=\"S2.SS2.p1\">\n\n</div>\n<div class=\"ltx_para\" id=\"S2.SS2.p2\">\n\n</div>\n</section>\n</section>\n<section class=\"ltx_section\" id=\"S3\">\n<h2 class=\"ltx_title ltx_font_bold ltx_title_section\" id=\"3-experimental-setup\" style=\"font-size:120%;\">3\u2002\u2004Experimental Setup</h2>\n<section class=\"ltx_paragraph\" id=\"S3.SS0.SSS0.Px1\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"datasets\">Datasets.</h4>\n<div class=\"ltx_para\" id=\"S3.SS0.SSS0.Px1.p1\">\n<p class=\"ltx_p\">We select 4 image classification datasets widely used in the literature: MNIST, CIFAR-10, CINIC-10 and CIFAR-100. MNIST contains 70,000 grayscale 28\u00d728 images of handwritten digits (0-9). CIFAR-10 has 60,000 32\u00d732 color images across 10 natural object classes, and CINIC-10 combines CIFAR-10 with downsampled ImageNet data, creating 270,000 32\u00d732 images across the same 10 classes as CIFAR-10 but with greater data volume and diversity. Finally, CIFAR-100 contains the same images as CIFAR10, but is divided into 100 fine-grained classes.</p>\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"S3.SS0.SSS0.Px2\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"models\">Models.</h4>\n<div class=\"ltx_para\" id=\"S3.SS0.SSS0.Px2.p1\">\n\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"S3.SS0.SSS0.Px3\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"attacks\">Attacks.</h4>\n<div class=\"ltx_para\" id=\"S3.SS0.SSS0.Px3.p1\">\n\n</div>\n<div class=\"ltx_para\" id=\"S3.SS0.SSS0.Px3.p2\">\n<p class=\"ltx_p\">For the LOSS attack, we collect per-sample loss values at the final epoch of training for the target model.</p>\n</div>\n</section>\n</section>\n<section class=\"ltx_section\" id=\"S4\">\n<h2 class=\"ltx_title ltx_font_bold ltx_title_section\" id=\"4-intuition\" style=\"font-size:120%;\">4\u2002\u2004Intuition</h2>\n<figure class=\"ltx_figure\" id=\"S4.F1\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_centering ltx_img_landscape\" height=\"350\" id=\"S4.F1.g1\" src=\"https://arxiv.org/html/x1.png\" width=\"830\"/>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_figure\"><span class=\"ltx_text\" style=\"font-size:90%;\">Figure 1</span>: </span><span class=\"ltx_text\" style=\"font-size:90%;\">Histograms showing loss distributions for training set members (orange) and non-members (blue) in log-log scale across three neural network architectures trained on CINIC-10: DenseNet121, WRN40-4, and ResNet-18. The distributions demonstrate clear separation between members and non-members, with members typically having lower loss values.</span></figcaption>\n</figure>\n<section class=\"ltx_paragraph\" id=\"S4.SS0.SSS0.Px1\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"loss-distributions-are-heavy-tailed\">Loss distributions are heavy-tailed.</h4>\n<div class=\"ltx_para\" id=\"S4.SS0.SSS0.Px1.p1\">\n\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"S4.SS0.SSS0.Px2\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"the-difference-between-member-and-non-member-loss-distributions-is-driven-by-the-tail\">The difference between member and non-member loss distributions is driven by the tail.</h4>\n<div class=\"ltx_para\" id=\"S4.SS0.SSS0.Px2.p1\">\n<p class=\"ltx_p\">The member and non-member distributions differ in mean but overlap substantially in the low-loss region. The meaningful separation arises in the high-loss tail, where the non-member distribution places much more mass than the member distribution.</p>\n</div>\n<div class=\"ltx_para\" id=\"S4.SS0.SSS0.Px2.p2\">\n<p class=\"ltx_p\">During the optimization process, gradient updates are likely larger for high-loss training examples; training pushes these extreme member losses into the low-loss region, shrinking the member tail rather than uniformly lowering all losses.</p>\n</div>\n<div class=\"ltx_para\" id=\"S4.SS0.SSS0.Px2.p3\">\n<p class=\"ltx_p\">Because this tail is composed almost entirely of high-loss non-members, the LOSS attack can identify these samples with high confidence.</p>\n</div>\n<figure class=\"ltx_figure ltx_align_floatright\" id=\"S4.F2\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_centering ltx_img_square\" height=\"355\" id=\"S4.F2.g1\" src=\"https://arxiv.org/html/x2.png\" width=\"330\"/>\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_figure\"><span class=\"ltx_text\" style=\"font-size:90%;\">Figure 2</span>: </span><span class=\"ltx_text\" style=\"font-size:90%;\">Loss distributions for members and non-members for ResNet-18 (CINIC10). Orange histogram shows member losses, blue shows non-member losses, with density curves overlaid. Green bars indicate the OUT model mean (<math alttext=\"l_{out}\" class=\"ltx_Math\" display=\"inline\" id=\"S4.F2.m2\" intent=\":literal\"><semantics><msub><mi>l</mi><mrow><mi>o</mi><mo lspace=\"0em\" rspace=\"0em\">\u200b</mo><mi>u</mi><mo lspace=\"0em\" rspace=\"0em\">\u200b</mo><mi>t</mi></mrow></msub><annotation encoding=\"application/x-tex\">l_{out}</annotation></semantics></math>) for samples identified by LiRA at FPR=0.001.</span></figcaption>\n</figure>\n</section>\n<section class=\"ltx_paragraph\" id=\"S4.SS0.SSS0.Px3\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"vulnerable-members-are-those-that-are-missing-from-the-tail\">Vulnerable members are those that are missing from the tail.</h4>\n<div class=\"ltx_para\" id=\"S4.SS0.SSS0.Px3.p1\">\n<p class=\"ltx_p\">The non-member distribution reflects the model\u2019s behavior on unseen data. The absence of a heavy tail for members then suggests that samples which would be in the high-loss region, had they not been seen by the model during training, have shifted into the low-loss region. These members now fall into the head of the distribution, where they are difficult to distinguish from easy non-members.</p>\n</div>\n<div class=\"ltx_para\" id=\"S4.SS0.SSS0.Px3.p2\">\n\n</div>\n</section>\n</section>\n<section class=\"ltx_section\" id=\"S5\">\n<h2 class=\"ltx_title ltx_font_bold ltx_title_section\" id=\"5-estimating-vulnerability-to-sota-mias\" style=\"font-size:120%;\">5\u2002\u2004Estimating Vulnerability to SOTA MIAs</h2>\n<div class=\"ltx_para\" id=\"S5.p1\">\n\n</div>\n<div class=\"ltx_para\" id=\"S5.p2\">\n<table class=\"ltx_equation ltx_eqn_table table table-responsive\" id=\"S5.E4\">\n<tbody><tr class=\"ltx_equation ltx_eqn_row ltx_align_baseline\">\n<td class=\"ltx_eqn_cell ltx_eqn_center_padleft\"></td>\n<td class=\"ltx_eqn_cell ltx_align_center\"><math alttext=\"\\text{TNR}_{\\text{LOSS}}(D_{\\text{test}},f_{\\theta},\\tau)=\\frac{|\\{A_{\\text{LOSS}}(f_{\\theta},x,y)&gt;\\tau|(x,y)\\in D_{\\text{test}}\\}|}{|D_{\\text{test}}|}\" class=\"ltx_Math\" display=\"block\" id=\"S5.E4.m1\" intent=\":literal\"><semantics><mrow><mrow><msub><mtext>TNR</mtext><mtext>LOSS</mtext></msub><mo lspace=\"0em\" rspace=\"0em\">\u200b</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>D</mi><mtext>test</mtext></msub><mo>,</mo><msub><mi>f</mi><mi>\u03b8</mi></msub><mo>,</mo><mi>\u03c4</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>=</mo><mfrac><mrow><mo stretchy=\"false\">|</mo><mrow><mo stretchy=\"false\">{</mo><mrow><mrow><msub><mi>A</mi><mtext>LOSS</mtext></msub><mo lspace=\"0em\" rspace=\"0em\">\u200b</mo><mrow><mo stretchy=\"false\">(</mo><msub><mi>f</mi><mi>\u03b8</mi></msub><mo>,</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow></mrow><mo>&gt;</mo><mi>\u03c4</mi></mrow><mo lspace=\"0em\" rspace=\"0em\">|</mo><mrow><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow><mo>\u2208</mo><msub><mi>D</mi><mtext>test</mtext></msub></mrow><mo stretchy=\"false\">}</mo></mrow><mo stretchy=\"false\">|</mo></mrow><mrow><mo stretchy=\"false\">|</mo><msub><mi>D</mi><mtext>test</mtext></msub><mo stretchy=\"false\">|</mo></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\text{TNR}_{\\text{LOSS}}(D_{\\text{test}},f_{\\theta},\\tau)=\\frac{|\\{A_{\\text{LOSS}}(f_{\\theta},x,y)&gt;\\tau|(x,y)\\in D_{\\text{test}}\\}|}{|D_{\\text{test}}|}</annotation></semantics></math></td>\n<td class=\"ltx_eqn_cell ltx_eqn_center_padright\"></td>\n<td class=\"ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right\" rowspan=\"1\"><span class=\"ltx_tag ltx_tag_equation ltx_align_right\">(4)</span></td>\n</tr></tbody>\n</table>\n</div>\n<figure class=\"ltx_figure\" id=\"S5.F3\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_centering ltx_img_landscape\" height=\"237\" id=\"S5.F3.g1\" src=\"https://arxiv.org/html/x3.png\" width=\"330\"/>\n<figcaption class=\"ltx_caption\"><span class=\"ltx_tag ltx_tag_figure\"><span class=\"ltx_text\" style=\"font-size:90%;\">Figure 3</span>: </span><span class=\"ltx_text\" style=\"font-size:90%;\">The LiRA TPR@FPR=0.001 as a linear function of the TNR@FPR for across all setups with the 97.5% confidence interval.</span></figcaption>\n</figure>\n<div class=\"ltx_para\" id=\"S5.p3\">\n\n</div>\n<div class=\"ltx_para\" id=\"S5.p4\">\n\n</div>\n<div class=\"ltx_para\" id=\"S5.p5\">\n\n</div>\n<div class=\"ltx_para\" id=\"S5.p6\">\n\n</div>\n<div class=\"ltx_para\" id=\"S5.p7\">\n<p class=\"ltx_p\">Aware of the prohibitive cost of SOTA MIA methods, a recent line of research aims to develop low-costs attacks which can be used by model developers to estimate the model-level risk. We also instantiate the SOTA low-cost attack, online RMIA, with two reference models and compare its predictive power to our method.</p>\n</div>\n<div class=\"ltx_para\" id=\"S5.p8\">\n\n</div>\n<figure class=\"ltx_table\" id=\"S5.T1\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" style=\"font-size:90%;\">Table 1</span>: </span><span class=\"ltx_text\" style=\"font-size:90%;\">Performance metrics comparison across different evaluation measures</span></figcaption>\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle table table-responsive\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">Metric</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">R\u00b2</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">RMSE</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">MAE</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">LOSS TNR (Ours)</th>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_font_bold\">0.945</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_font_bold\">0.036</span></td>\n<td class=\"ltx_td ltx_align_center ltx_border_t\"><span class=\"ltx_text ltx_font_bold\">0.025</span></td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Train-Test Gap</th>\n<td class=\"ltx_td ltx_align_center\">0.682</td>\n<td class=\"ltx_td ltx_align_center\">0.087</td>\n<td class=\"ltx_td ltx_align_center\">0.059</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">LT-IQR AUC</th>\n<td class=\"ltx_td ltx_align_center\">0.788</td>\n<td class=\"ltx_td ltx_align_center\">0.071</td>\n<td class=\"ltx_td ltx_align_center\">0.049</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Loss AUC</th>\n<td class=\"ltx_td ltx_align_center\">0.794</td>\n<td class=\"ltx_td ltx_align_center\">0.070</td>\n<td class=\"ltx_td ltx_align_center\">0.051</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">RMIA (2 reference models)</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">0.908</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">0.035</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">0.046</td>\n</tr>\n</tbody>\n</table>\n</figure>\n<div class=\"ltx_para\" id=\"S5.p9\">\n<p class=\"ltx_p\">If the memorization effect were more evenly distributed, our LOSS attack\u2019s AUC, which measures separability between distributions across all values, would provide better approximation. The train-test gap, a metric studied in the literature, simply captures the difference in means between loss distributions and performs moderately well as they struggle to detect tail differences caused by the asymmetric non-member distribution.</p>\n</div>\n<section class=\"ltx_subsection\" id=\"S5.SS1\">\n<h3 class=\"ltx_title ltx_font_bold ltx_title_subsection\" id=\"51-varying-the-number-of-reference-models\">5.1\u2002\u2004Varying the number of reference models</h3>\n<div class=\"ltx_para\" id=\"S5.SS1.p1\">\n\n</div>\n<div class=\"ltx_para\" id=\"S5.SS1.p2\">\n\n</div>\n<figure class=\"ltx_figure\" id=\"S5.F4\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_centering ltx_img_landscape\" height=\"216\" id=\"S5.F4.g1\" src=\"https://arxiv.org/html/x4.png\" width=\"529\"/>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_figure\"><span class=\"ltx_text\" style=\"font-size:90%;\">Figure 4</span>: </span><span class=\"ltx_text\" style=\"font-size:90%;\">Performance of linear models for predicting LiRA with varying numbers of reference models (K). Left panel shows the correlation between LOSS TNR (x-axis) and LiRA TPR@0.001 (y-axis) across different K values, with linear regression fits shown for each condition. Right panel shows slope parameter (<math alttext=\"\\alpha\" class=\"ltx_Math\" display=\"inline\" id=\"S5.F4.m2\" intent=\":literal\"><semantics><mi>\u03b1</mi><annotation encoding=\"application/x-tex\">\\alpha</annotation></semantics></math>) for different K. The error bars show the 97.5% confidence intervals obtained with boostrapping.</span></figcaption>\n</figure>\n</section>\n<section class=\"ltx_subsection\" id=\"S5.SS2\">\n<h3 class=\"ltx_title ltx_font_bold ltx_title_subsection\" id=\"52-fitting-different-functions\">5.2\u2002\u2004Fitting different functions</h3>\n<div class=\"ltx_para\" id=\"S5.SS2.p1\">\n<p class=\"ltx_p\">We have so far estimated LiRA TPR with a simple linear model. We now study non-linear models lead to better risk estimatates. Identifying non-members is indeed a matter of finding a good threshold to separate the tail of the loss distribution from the rest, while identifying members is dependent on reference models and is likely to be a more difficult task. We indeed find empirically that the LOSS TNR is typically higher than LiRA TPR at the same FPR.</p>\n</div>\n<div class=\"ltx_para\" id=\"S5.SS2.p2\">\n<p class=\"ltx_p\">We thus compute goodness-of-fit metrics for convex functions such as two-parameter polynomial, power-law, and exponential functions.</p>\n</div>\n<div class=\"ltx_para\" id=\"S5.SS2.p3\">\n\n</div>\n<figure class=\"ltx_table\" id=\"S5.T2\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\"><span class=\"ltx_text\" style=\"font-size:90%;\">Table 2</span>: </span><span class=\"ltx_text\" style=\"font-size:90%;\">Goodness-of-Fit Comparison for Different Functions</span></figcaption>\n<table class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle table table-responsive\">\n<thead class=\"ltx_thead\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">Function</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">R<sup class=\"ltx_sup\"><span class=\"ltx_text ltx_font_medium\">2</span></sup></span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">MAE</span></th>\n<th class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\"><span class=\"ltx_text ltx_font_bold\">RMSE</span></th>\n</tr>\n</thead>\n<tbody class=\"ltx_tbody\">\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt\">Exponential</th>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">0.983</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">0.014</td>\n<td class=\"ltx_td ltx_align_center ltx_border_tt\">0.020</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Quadratic</th>\n<td class=\"ltx_td ltx_align_center\">0.982</td>\n<td class=\"ltx_td ltx_align_center\">0.014</td>\n<td class=\"ltx_td ltx_align_center\">0.020</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">Power-Law</th>\n<td class=\"ltx_td ltx_align_center\">0.980</td>\n<td class=\"ltx_td ltx_align_center\">0.015</td>\n<td class=\"ltx_td ltx_align_center\">0.021</td>\n</tr>\n<tr class=\"ltx_tr\">\n<th class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb\">Linear</th>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">0.945</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">0.025</td>\n<td class=\"ltx_td ltx_align_center ltx_border_bb\">0.036</td>\n</tr>\n</tbody>\n</table>\n</figure>\n</section>\n<section class=\"ltx_subsection\" id=\"S5.SS3\">\n<h3 class=\"ltx_title ltx_font_bold ltx_title_subsection\" id=\"53-llms\">5.3\u2002\u2004LLMs</h3>\n<div class=\"ltx_para\" id=\"S5.SS3.p1\">\n\n</div>\n<div class=\"ltx_para\" id=\"S5.SS3.p2\">\n\n</div>\n<figure class=\"ltx_figure\" id=\"S5.F5\">\n<div class=\"ltx_flex_figure\">\n<div class=\"ltx_flex_cell ltx_flex_size_2\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_centering ltx_figure_panel ltx_img_square\" height=\"183\" id=\"S5.F5.g1\" src=\"https://arxiv.org/html/x5.png\" width=\"198\"/></div>\n<div class=\"ltx_flex_cell ltx_flex_size_2\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_centering ltx_figure_panel ltx_img_square\" height=\"185\" id=\"S5.F5.g2\" src=\"https://arxiv.org/html/x6.png\" width=\"198\"/></div>\n</div>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_figure\"><span class=\"ltx_text\" style=\"font-size:90%;\">Figure 5</span>: </span><span class=\"ltx_text\" style=\"font-size:90%;\">The distributions of members and non-members (left). The LIRA TPR@FPR LOSS as a linear function of the LOSS AUC evaluated on LLMs.</span></figcaption>\n</figure>\n<div class=\"ltx_para\" id=\"S5.SS3.p3\">\n<p class=\"ltx_p\">While more traditional image and other models show discrete, example-specific memorization that creates clear distributional differences and asymmetric, heavy-tailed distributions, LLMs show loss distributions that are much more symmetrical, with little difference between the train and test distributions even when models can be shown to have memorized training data. This rules out TNR as a risk estimator.</p>\n</div>\n<div class=\"ltx_para\" id=\"S5.SS3.p4\">\n<p class=\"ltx_p\">However, we posit that LOSS AUC, as a more general estimate of \u201cmissing records\u201d, might provide an estimation of model-level risk.</p>\n</div>\n<div class=\"ltx_para\" id=\"S5.SS3.p5\">\n\n</div>\n</section>\n</section>\n<section class=\"ltx_section\" id=\"S6\">\n<h2 class=\"ltx_title ltx_font_bold ltx_title_section\" id=\"6-related-work\" style=\"font-size:120%;\">6\u2002\u2004Related Work</h2>\n<section class=\"ltx_paragraph\" id=\"S6.SS0.SSS0.Px1\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"membership-inference-attacks\">Membership inference attacks.</h4>\n<div class=\"ltx_para\" id=\"S6.SS0.SSS0.Px1.p1\">\n\n</div>\n<div class=\"ltx_para\" id=\"S6.SS0.SSS0.Px1.p2\">\n\n</div>\n<div class=\"ltx_para\" id=\"S6.SS0.SSS0.Px1.p3\">\n\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"S6.SS0.SSS0.Px2\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"low-cost-attacks-and-free-identification-of-vulnerable-samples\">Low-cost attacks and free identification of vulnerable samples.</h4>\n<div class=\"ltx_para\" id=\"S6.SS0.SSS0.Px2.p1\">\n\n</div>\n<div class=\"ltx_para\" id=\"S6.SS0.SSS0.Px2.p2\">\n\n</div>\n<div class=\"ltx_para\" id=\"S6.SS0.SSS0.Px2.p3\">\n\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"S6.SS0.SSS0.Px3\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"factors-influencing-membership-inference-vulnerability\">Factors influencing membership inference vulnerability.</h4>\n<div class=\"ltx_para\" id=\"S6.SS0.SSS0.Px3.p1\">\n\n</div>\n</section>\n</section>\n<section class=\"ltx_section\" id=\"S7\">\n<h2 class=\"ltx_title ltx_font_bold ltx_title_section\" id=\"7-conclusion\" style=\"font-size:120%;\">7\u2002\u2004Conclusion</h2>\n<div class=\"ltx_para\" id=\"S7.p1\">\n<p class=\"ltx_p\">We present a novel method to estimate model-level vulnerability to SOTA membership inference attacks without reference models. We show a significant fraction of highly vulnerable samples being samples that are \u201cmissing\u201d from the tail of the training distribution and instead moved to the low loss head of the distribution. We propose to use the LOSS attack, and in particular it\u2019s TNR, to quantify the missing samples and estimates the model\u2019s vulnerability to LiRA.</p>\n</div>\n<div class=\"ltx_para\" id=\"S7.p2\">\n<p class=\"ltx_p\">Across 9 architectures and 4 datasets, we show our method to achieves an RMSE of 0.036 in predicting the LiRA TPR@FPR=0.001 with similar results for other FPR values. Our method outperforms other measures including train-test accuracy gap and LT-IQR, as well as recent low-cost attacks at estimating model-level risk. We also test non-linear risk estimation models and show the method to enable model developer to estimate the risk posed by strong attackers willing to train a large number of reference models.</p>\n</div>\n<div class=\"ltx_para\" id=\"S7.p3\">\n<p class=\"ltx_p\">Finally, given the importance of the task, we apply our approach to LLMs. While they are know to exhibit different memorization pattern, we show LOSS AUC might still serve as an effective estimation of model-level vulnerability to SOTA reference model-based MIAs.</p>\n</div>\n<div class=\"ltx_para\" id=\"S7.p4\">\n<p class=\"ltx_p\">Taken together, our work provides a novel practical approach to estimating model-level vulnerability to SOTA attacks with no additional computational cost. Where SOTA attacks often require training hundreds of reference models, our method uses only the target model\u2019s loss values. We believe this will greatly help enable privacy risk assessments in practice, in particular during iterative development workflows.</p>\n</div>\n<section class=\"ltx_paragraph\" id=\"S7.SS0.SSS0.Px1\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"limitations-and-future-work\">Limitations and future work.</h4>\n<div class=\"ltx_para\" id=\"S7.SS0.SSS0.Px1.p1\">\n<p class=\"ltx_p\">We evaluate in the work the use of LOSS TNR (and AUC) to estimate model vulnerability to LiRA. While LiRA is the state-of-the-art and has been shown to outperform other approaches, we have not assessed the transferability of our method to other MIAs or to broader privacy threats (e.g., reconstruction or inversion). While we test it on a range of setups (datasets and architectures) covering a range of risk level, TNR is an estimator of the risk and there might be cases where our results do not generalize. Due to computational constraints, our LLM study spans five mid-sized architectures. Evaluating scaling to larger models and datasets and sensitivity to training regimes are natural next steps.</p>\n</div>\n</section>\n</section>\n<section class=\"ltx_bibliography\" id=\"bib\">\n<h2 class=\"ltx_title ltx_title_bibliography\" id=\"references\">References</h2>\n<ul class=\"ltx_biblist\">\n<li class=\"ltx_bibitem\" id=\"bib.bib1\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Bertran et\u00a0al. (2023)</span>\n<span class=\"ltx_bibblock\">\nMartin Bertran, Shuai Tang, Aaron Roth, Michael Kearns, Jamie\u00a0H Morgenstern, and Steven\u00a0Z Wu.\n\n</span>\n<span class=\"ltx_bibblock\">Scalable membership inference attacks via quantile regression.\n\n</span>\n<span class=\"ltx_bibblock\"><em class=\"ltx_emph ltx_font_italic\">Advances in Neural Information Processing Systems</em>, 36:314\u2013330, 2023.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib2\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Carlini et\u00a0al. (2019)</span>\n<span class=\"ltx_bibblock\">\nNicholas Carlini, Chang Liu, \u00dalfar Erlingsson, Jernej Kos, and Dawn Song.\n\n</span>\n<span class=\"ltx_bibblock\">The secret sharer: Evaluating and testing unintended memorization in neural networks.\n\n</span>\n<span class=\"ltx_bibblock\">In <em class=\"ltx_emph ltx_font_italic\">28th USENIX security symposium (USENIX security 19)</em>, pp.  267\u2013284, 2019.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib3\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Carlini et\u00a0al. (2022a)</span>\n<span class=\"ltx_bibblock\">\nNicholas Carlini, Steve Chien, Milad Nasr, Shuang Song, Andreas Terzis, and Florian Tramer.\n\n</span>\n<span class=\"ltx_bibblock\">Membership inference attacks from first principles.\n\n</span>\n<span class=\"ltx_bibblock\">In <em class=\"ltx_emph ltx_font_italic\">2022 IEEE symposium on security and privacy (SP)</em>, pp.  1897\u20131914. IEEE, 2022a.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib4\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Carlini et\u00a0al. (2022b)</span>\n<span class=\"ltx_bibblock\">\nNicholas Carlini, Andreas Terzis, Matthew Jagielski, Florian Tramer, Nicolas Papernot, and Chiyuan Zhang.\n\n</span>\n<span class=\"ltx_bibblock\">The privacy onion effect: memorization is relative.\n\n</span>\n<span class=\"ltx_bibblock\">In <em class=\"ltx_emph ltx_font_italic\">Proceedings of the 36th International Conference on Neural Information Processing Systems</em>, NIPS \u201922, Red Hook, NY, USA, 2022b. Curran Associates Inc.\n\n</span>\n<span class=\"ltx_bibblock\">ISBN 9781713871088.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib5\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Chang &amp; Shokri (2021)</span>\n<span class=\"ltx_bibblock\">\nHongyan Chang and Reza Shokri.\n\n</span>\n<span class=\"ltx_bibblock\">On the privacy risks of algorithmic fairness.\n\n</span>\n<span class=\"ltx_bibblock\">In <em class=\"ltx_emph ltx_font_italic\">2021 IEEE European Symposium on Security and Privacy (EuroS&amp;P)</em>, pp.  292\u2013303. IEEE, 2021.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib6\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Chen et\u00a0al. (2020)</span>\n<span class=\"ltx_bibblock\">\nDingfan Chen, Ning Yu, Yang Zhang, and Mario Fritz.\n\n</span>\n<span class=\"ltx_bibblock\">Gan-leaks: A taxonomy of membership inference attacks against generative models.\n\n</span>\n<span class=\"ltx_bibblock\">In <em class=\"ltx_emph ltx_font_italic\">Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security</em>, CCS \u201920, pp.  343\u2013362, New York, NY, USA, 2020. Association for Computing Machinery.\n\n</span>\n<span class=\"ltx_bibblock\">ISBN 9781450370899.\n\n</span>\n<span class=\"ltx_bibblock\">doi: <span class=\"ltx_ref ltx_nolink ltx_Url ltx_ref_self\">10.1145/3372297.3417238</span>.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://doi.org/10.1145/3372297.3417238\" title=\"\">https://doi.org/10.1145/3372297.3417238</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib7\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">European Data Protection Board (2024)</span>\n<span class=\"ltx_bibblock\">\nEuropean Data Protection Board.\n\n</span>\n<span class=\"ltx_bibblock\">Opinion 28/2024 on certain data protection aspects related to the processing of personal data in the context of ai models.\n\n</span>\n<span class=\"ltx_bibblock\">Adopted on 17 December 2024, December 2024.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://www.edpb.europa.eu/system/files/2024-12/edpb_opinion_202428_ai-models_en.pdf\" title=\"\">https://www.edpb.europa.eu/system/files/2024-12/edpb_opinion_202428_ai-models_en.pdf</a>.\n\n</span>\n<span class=\"ltx_bibblock\">Version 1.0.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib8\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Fredrikson et\u00a0al. (2015)</span>\n<span class=\"ltx_bibblock\">\nMatt Fredrikson, Somesh Jha, and Thomas Ristenpart.\n\n</span>\n<span class=\"ltx_bibblock\">Model inversion attacks that exploit confidence information and basic countermeasures.\n\n</span>\n<span class=\"ltx_bibblock\">In <em class=\"ltx_emph ltx_font_italic\">Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security</em>, CCS \u201915, pp.  1322\u20131333, New York, NY, USA, 2015. Association for Computing Machinery.\n\n</span>\n<span class=\"ltx_bibblock\">ISBN 9781450338325.\n\n</span>\n<span class=\"ltx_bibblock\">doi: <span class=\"ltx_ref ltx_nolink ltx_Url ltx_ref_self\">10.1145/2810103.2813677</span>.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://doi.org/10.1145/2810103.2813677\" title=\"\">https://doi.org/10.1145/2810103.2813677</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib9\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Hayes et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nJamie Hayes, Ilia Shumailov, Christopher\u00a0A. Choquette-Choo, Matthew Jagielski, George Kaissis, Katherine Lee, Milad Nasr, Sahra Ghalebikesabi, Niloofar Mireshghallah, Meenatchi Sundaram Mutu\u00a0Selva Annamalai, Igor Shilov, Matthieu Meeus, Yves-Alexandre de\u00a0Montjoye, Franziska Boenisch, Adam Dziedzic, and A.\u00a0Feder Cooper.\n\n</span>\n<span class=\"ltx_bibblock\">Strong membership inference attacks on massive datasets and (moderately) large language models, 2025.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2505.18773\" title=\"\">https://arxiv.org/abs/2505.18773</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib10\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">He et\u00a0al. (2016)</span>\n<span class=\"ltx_bibblock\">\nKaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.\n\n</span>\n<span class=\"ltx_bibblock\">Deep residual learning for image recognition.\n\n</span>\n<span class=\"ltx_bibblock\">In <em class=\"ltx_emph ltx_font_italic\">Proceedings of the IEEE conference on computer vision and pattern recognition</em>, pp.  770\u2013778, 2016.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib11\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">He et\u00a0al. (2024)</span>\n<span class=\"ltx_bibblock\">\nYu\u00a0He, Boheng Li, Yao Wang, Mengda Yang, Juan Wang, Hongxin Hu, and Xingyu Zhao.\n\n</span>\n<span class=\"ltx_bibblock\">Is difficulty calibration all we need? towards more practical membership inference attacks, 2024.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2409.00426\" title=\"\">https://arxiv.org/abs/2409.00426</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib12\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Homer et\u00a0al. (2008)</span>\n<span class=\"ltx_bibblock\">\nNils Homer, Szabolcs Szelinger, Margot Redman, David Duggan, Waibhav Tembe, Jill Muehling, John\u00a0V Pearson, Dietrich\u00a0A Stephan, Stanley\u00a0F Nelson, and David\u00a0W Craig.\n\n</span>\n<span class=\"ltx_bibblock\">Resolving individuals contributing trace amounts of dna to highly complex mixtures using high-density snp genotyping microarrays.\n\n</span>\n<span class=\"ltx_bibblock\"><em class=\"ltx_emph ltx_font_italic\">PLoS genetics</em>, 4(8):e1000167, 2008.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib13\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Huang et\u00a0al. (2017)</span>\n<span class=\"ltx_bibblock\">\nGao Huang, Zhuang Liu, Laurens Van Der\u00a0Maaten, and Kilian\u00a0Q Weinberger.\n\n</span>\n<span class=\"ltx_bibblock\">Densely connected convolutional networks.\n\n</span>\n<span class=\"ltx_bibblock\">In <em class=\"ltx_emph ltx_font_italic\">Proceedings of the IEEE conference on computer vision and pattern recognition</em>, pp.  4700\u20134708, 2017.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib14\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">(14)</span>\n<span class=\"ltx_bibblock\">\nInformation Commissioner\u2019s\u00a0Office (ICO).\n\n</span>\n<span class=\"ltx_bibblock\">How should we assess security and data minimisation in ai?, 2025.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/artificial-intelligence/guidance-on-ai-and-data-protection/how-should-we-assess-security-and-data-minimisation-in-ai/\" title=\"\">https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/artificial-intelligence/guidance-on-ai-and-data-protection/how-should-we-assess-security-and-data-minimisation-in-ai/</a>.\n\n</span>\n<span class=\"ltx_bibblock\">Accessed: 2025-09-17.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib15\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Kulynych et\u00a0al. (2022)</span>\n<span class=\"ltx_bibblock\">\nBogdan Kulynych, Mohammad Yaghini, Giovanni Cherubin, Michael Veale, and Carmela Troncoso.\n\n</span>\n<span class=\"ltx_bibblock\">Disparate vulnerability to membership inference attacks.\n\n</span>\n<span class=\"ltx_bibblock\"><em class=\"ltx_emph ltx_font_italic\">Proceedings on Privacy Enhancing Technologies</em>, 1:460\u2013480, 2022.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib16\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Leemann et\u00a0al. (2024)</span>\n<span class=\"ltx_bibblock\">\nTobias Leemann, Bardh Prenkaj, and Gjergji Kasneci.\n\n</span>\n<span class=\"ltx_bibblock\">Is my data safe? predicting instance-level membership inference success for white-box and black-box attacks.\n\n</span>\n<span class=\"ltx_bibblock\">In <em class=\"ltx_emph ltx_font_italic\">ICML 2024 Next Generation of AI Safety Workshop</em>, 2024.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib17\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Li et\u00a0al. (2024)</span>\n<span class=\"ltx_bibblock\">\nHao Li, Zheng Li, Siyuan Wu, Chengrui Hu, Yutong Ye, Min Zhang, Dengguo Feng, and Yang Zhang.\n\n</span>\n<span class=\"ltx_bibblock\">Seqmia: sequential-metric based membership inference attack.\n\n</span>\n<span class=\"ltx_bibblock\">In <em class=\"ltx_emph ltx_font_italic\">Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security</em>, pp.  3496\u20133510, 2024.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib18\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Liu et\u00a0al. (2022)</span>\n<span class=\"ltx_bibblock\">\nYiyong Liu, Zhengyu Zhao, Michael Backes, and Yang Zhang.\n\n</span>\n<span class=\"ltx_bibblock\">Membership inference attacks by exploiting loss trajectory.\n\n</span>\n<span class=\"ltx_bibblock\">In <em class=\"ltx_emph ltx_font_italic\">Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security</em>, CCS \u201922, pp.  2085\u20132098, New York, NY, USA, 2022. Association for Computing Machinery.\n\n</span>\n<span class=\"ltx_bibblock\">ISBN 9781450394505.\n\n</span>\n<span class=\"ltx_bibblock\">doi: <span class=\"ltx_ref ltx_nolink ltx_Url ltx_ref_self\">10.1145/3548606.3560684</span>.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://doi.org/10.1145/3548606.3560684\" title=\"\">https://doi.org/10.1145/3548606.3560684</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib19\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Mattern et\u00a0al. (2023)</span>\n<span class=\"ltx_bibblock\">\nJustus Mattern, Fatemehsadat Mireshghallah, Zhijing Jin, Bernhard Sch\u00f6lkopf, Mrinmaya Sachan, and Taylor Berg-Kirkpatrick.\n\n</span>\n<span class=\"ltx_bibblock\">Membership inference attacks against language models via neighbourhood comparison, 2023.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2305.18462\" title=\"\">https://arxiv.org/abs/2305.18462</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib20\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">N\u00e9meth et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nGergely\u00a0D\u00e1niel N\u00e9meth, Miguel \u00c1ngel Lozano, Novi Quadrianto, and Nuria Oliver.\n\n</span>\n<span class=\"ltx_bibblock\">Privacy and accuracy implications of model complexity and integration in heterogeneous federated learning, 2025.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2311.17750\" title=\"\">https://arxiv.org/abs/2311.17750</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib21\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Pollock et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nJoseph Pollock, Igor Shilov, Euodia Dodd, and Yves-Alexandre de\u00a0Montjoye.\n\n</span>\n<span class=\"ltx_bibblock\">Free <math alttext=\"\\{\" class=\"ltx_Math\" display=\"inline\" id=\"bib.bib21.m1\" intent=\":literal\"><semantics><mo stretchy=\"false\">{</mo><annotation encoding=\"application/x-tex\">\\{</annotation></semantics></math>Record-Level<math alttext=\"\\}\" class=\"ltx_Math\" display=\"inline\" id=\"bib.bib21.m2\" intent=\":literal\"><semantics><mo stretchy=\"false\">}</mo><annotation encoding=\"application/x-tex\">\\}</annotation></semantics></math> privacy risk evaluation through <math alttext=\"\\{\" class=\"ltx_Math\" display=\"inline\" id=\"bib.bib21.m3\" intent=\":literal\"><semantics><mo stretchy=\"false\">{</mo><annotation encoding=\"application/x-tex\">\\{</annotation></semantics></math>Artifact-Based<math alttext=\"\\}\" class=\"ltx_Math\" display=\"inline\" id=\"bib.bib21.m4\" intent=\":literal\"><semantics><mo stretchy=\"false\">}</mo><annotation encoding=\"application/x-tex\">\\}</annotation></semantics></math> methods.\n\n</span>\n<span class=\"ltx_bibblock\">In <em class=\"ltx_emph ltx_font_italic\">34th USENIX Security Symposium (USENIX Security 25)</em>, pp.  5525\u20135544, 2025.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib22\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Ponomareva et\u00a0al. (2023)</span>\n<span class=\"ltx_bibblock\">\nNatalia Ponomareva, Sergei Vassilvitskii, Zheng Xu, Brendan McMahan, Alexey Kurakin, and Chiyaun Zhang.\n\n</span>\n<span class=\"ltx_bibblock\">How to dp-fy ml: A practical tutorial to machine learning with differential privacy.\n\n</span>\n<span class=\"ltx_bibblock\">In <em class=\"ltx_emph ltx_font_italic\">Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em>, KDD \u201923, pp.  5823\u20135824, New York, NY, USA, 2023. Association for Computing Machinery.\n\n</span>\n<span class=\"ltx_bibblock\">ISBN 9798400701030.\n\n</span>\n<span class=\"ltx_bibblock\">doi: <span class=\"ltx_ref ltx_nolink ltx_Url ltx_ref_self\">10.1145/3580305.3599561</span>.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://doi.org/10.1145/3580305.3599561\" title=\"\">https://doi.org/10.1145/3580305.3599561</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib23\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Sandler et\u00a0al. (2018)</span>\n<span class=\"ltx_bibblock\">\nMark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen.\n\n</span>\n<span class=\"ltx_bibblock\">Mobilenetv2: Inverted residuals and linear bottlenecks.\n\n</span>\n<span class=\"ltx_bibblock\">In <em class=\"ltx_emph ltx_font_italic\">Proceedings of the IEEE conference on computer vision and pattern recognition</em>, pp.  4510\u20134520, 2018.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib24\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Shilov et\u00a0al. (2024)</span>\n<span class=\"ltx_bibblock\">\nIgor Shilov, Matthieu Meeus, and Yves-Alexandre de\u00a0Montjoye.\n\n</span>\n<span class=\"ltx_bibblock\">The mosaic memory of large language models.\n\n</span>\n<span class=\"ltx_bibblock\"><em class=\"ltx_emph ltx_font_italic\">arXiv preprint arXiv:2405.15523</em>, 2024.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib25\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Shokri et\u00a0al. (2017)</span>\n<span class=\"ltx_bibblock\">\nReza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov.\n\n</span>\n<span class=\"ltx_bibblock\">Membership inference attacks against machine learning models.\n\n</span>\n<span class=\"ltx_bibblock\">In <em class=\"ltx_emph ltx_font_italic\">2017 IEEE symposium on security and privacy (SP)</em>, pp.  3\u201318. IEEE, 2017.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib26\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Simonyan &amp; Zisserman (2015)</span>\n<span class=\"ltx_bibblock\">\nK\u00a0Simonyan and A\u00a0Zisserman.\n\n</span>\n<span class=\"ltx_bibblock\">Very deep convolutional networks for large-scale image recognition.\n\n</span>\n<span class=\"ltx_bibblock\">In <em class=\"ltx_emph ltx_font_italic\">3rd International Conference on Learning Representations (ICLR 2015)</em>. Computational and Biological Learning Society, 2015.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib27\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Song &amp; Mittal (2020)</span>\n<span class=\"ltx_bibblock\">\nLiwei Song and Prateek Mittal.\n\n</span>\n<span class=\"ltx_bibblock\">Systematic evaluation of privacy risks of machine learning models, 2020.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2003.10595\" title=\"\">https://arxiv.org/abs/2003.10595</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib28\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Song et\u00a0al. (2019)</span>\n<span class=\"ltx_bibblock\">\nLiwei Song, Reza Shokri, and Prateek Mittal.\n\n</span>\n<span class=\"ltx_bibblock\">Privacy risks of securing machine learning models against adversarial examples.\n\n</span>\n<span class=\"ltx_bibblock\">In <em class=\"ltx_emph ltx_font_italic\">Proceedings of the 2019 ACM SIGSAC conference on computer and communications security</em>, pp.  241\u2013257, 2019.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib29\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Tirumala et\u00a0al. (2022)</span>\n<span class=\"ltx_bibblock\">\nKushal Tirumala, Aram Markosyan, Luke Zettlemoyer, and Armen Aghajanyan.\n\n</span>\n<span class=\"ltx_bibblock\">Memorization without overfitting: Analyzing the training dynamics of large language models.\n\n</span>\n<span class=\"ltx_bibblock\"><em class=\"ltx_emph ltx_font_italic\">Advances in Neural Information Processing Systems</em>, 35:38274\u201338290, 2022.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib30\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Tobaben et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nMarlon Tobaben, Hibiki Ito, Joonas J\u00e4lk\u00f6, Yuan He, and Antti Honkela.\n\n</span>\n<span class=\"ltx_bibblock\">Impact of dataset properties on membership inference vulnerability of deep transfer learning, 2025.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2402.06674\" title=\"\">https://arxiv.org/abs/2402.06674</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib31\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Watson et\u00a0al. (2021)</span>\n<span class=\"ltx_bibblock\">\nLauren Watson, Chuan Guo, Graham Cormode, and Alex Sablayrolles.\n\n</span>\n<span class=\"ltx_bibblock\">On the importance of difficulty calibration in membership inference attacks.\n\n</span>\n<span class=\"ltx_bibblock\"><em class=\"ltx_emph ltx_font_italic\">arXiv preprint arXiv:2111.08440</em>, 2021.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib32\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Ye et\u00a0al. (2022)</span>\n<span class=\"ltx_bibblock\">\nJiayuan Ye, Aadyaa Maddi, Sasi\u00a0Kumar Murakonda, Vincent Bindschaedler, and Reza Shokri.\n\n</span>\n<span class=\"ltx_bibblock\">Enhanced membership inference attacks against machine learning models.\n\n</span>\n<span class=\"ltx_bibblock\">In <em class=\"ltx_emph ltx_font_italic\">Proceedings of the 2022 ACM SIGSAC conference on computer and communications security</em>, pp.  3093\u20133106, 2022.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib33\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Yeom et\u00a0al. (2018)</span>\n<span class=\"ltx_bibblock\">\nSamuel Yeom, Irene Giacomelli, Matt Fredrikson, and Somesh Jha.\n\n</span>\n<span class=\"ltx_bibblock\">Privacy risk in machine learning: Analyzing the connection to overfitting.\n\n</span>\n<span class=\"ltx_bibblock\">In <em class=\"ltx_emph ltx_font_italic\">2018 IEEE 31st computer security foundations symposium (CSF)</em>, pp.  268\u2013282. IEEE, 2018.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib34\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Zagoruyko &amp; Komodakis (2016)</span>\n<span class=\"ltx_bibblock\">\nSergey Zagoruyko and Nikos Komodakis.\n\n</span>\n<span class=\"ltx_bibblock\">Wide residual networks.\n\n</span>\n<span class=\"ltx_bibblock\"><em class=\"ltx_emph ltx_font_italic\">arXiv preprint arXiv:1605.07146</em>, 2016.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib35\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Zarifzadeh et\u00a0al. (2023)</span>\n<span class=\"ltx_bibblock\">\nSajjad Zarifzadeh, Philippe Liu, and Reza Shokri.\n\n</span>\n<span class=\"ltx_bibblock\">Low-cost high-power membership inference attacks.\n\n</span>\n<span class=\"ltx_bibblock\"><em class=\"ltx_emph ltx_font_italic\">arXiv preprint arXiv:2312.03262</em>, 2023.\n\n</span>\n</li>\n</ul>\n</section>\n<section class=\"ltx_section\" id=\"S8\">\n<h2 class=\"ltx_title ltx_font_bold ltx_title_section\" id=\"8-appendix\" style=\"font-size:120%;\">8\u2002\u2004Appendix</h2>\n</section>\n<section class=\"ltx_appendix\" id=\"A1\">\n<h2 class=\"ltx_title ltx_title_appendix\" id=\"appendix-a-loss-distributions-across-all-setups\">\n<span class=\"ltx_tag ltx_tag_appendix\">Appendix A </span>Loss distributions across all setups</h2>\n<figure class=\"ltx_figure\" id=\"A1.F6\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_centering ltx_img_landscape\" height=\"353\" id=\"A1.F6.g1\" src=\"https://arxiv.org/html/x7.png\" width=\"830\"/>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_figure\"><span class=\"ltx_text\" style=\"font-size:90%;\">Figure 6</span>: </span><span class=\"ltx_text\" style=\"font-size:90%;\">Histograms showing loss distributions for training set members (orange) and non-members (blue) in log-log scale across all setups. The distributions demonstrate clear separation between members and non-members, with members typically having lower loss values.</span></figcaption>\n</figure>\n<figure class=\"ltx_figure\" id=\"A1.F7\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_centering ltx_img_landscape\" height=\"331\" id=\"A1.F7.g1\" src=\"https://arxiv.org/html/x8.png\" width=\"830\"/>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_figure\"><span class=\"ltx_text\" style=\"font-size:90%;\">Figure 7</span>: </span><span class=\"ltx_text\" style=\"font-size:90%;\">Loss distributions for training set members and non-members across all setups. Orange histogram shows member losses, blue shows non-member losses, with density curves overlaid. Green bars indicate the OUT model mean (<math alttext=\"l_{out}\" class=\"ltx_Math\" display=\"inline\" id=\"A1.F7.m2\" intent=\":literal\"><semantics><msub><mi>l</mi><mrow><mi>o</mi><mo lspace=\"0em\" rspace=\"0em\">\u200b</mo><mi>u</mi><mo lspace=\"0em\" rspace=\"0em\">\u200b</mo><mi>t</mi></mrow></msub><annotation encoding=\"application/x-tex\">l_{out}</annotation></semantics></math>) for points identified by LiRA at FPR=0.001.\n</span></figcaption>\n</figure>\n</section>\n<section class=\"ltx_appendix\" id=\"A2\">\n<h2 class=\"ltx_title ltx_title_appendix\" id=\"appendix-b-varying-fprs\">\n<span class=\"ltx_tag ltx_tag_appendix\">Appendix B </span>Varying FPRs</h2>\n<figure class=\"ltx_figure\" id=\"A2.F8\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_centering ltx_img_landscape\" height=\"450\" id=\"A2.F8.g1\" src=\"https://arxiv.org/html/x9.png\" width=\"747\"/>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_figure\"><span class=\"ltx_text\" style=\"font-size:90%;\">Figure 8</span>: </span><span class=\"ltx_text\" style=\"font-size:90%;\">The LiRA TPR as a linear function of different distributional measure at FPR=0.01, 0.001, and 0.0001.</span></figcaption>\n</figure>\n</section>\n</article>\n</div>\n\n</div>",
    "sections": [
      {
        "id": "the-tail-tells-all-estimating-model-level-membership-inference-vulnerability-without-reference-models",
        "title": "The Tail Tells All: Estimating Model-Level Membership Inference Vulnerability Without Reference Models",
        "level": 1
      },
      {
        "id": "abstract",
        "title": "Abstract",
        "level": 6
      },
      {
        "id": "1-introduction",
        "title": "1\u2002\u2004Introduction",
        "level": 2
      },
      {
        "id": "11-problem-statement",
        "title": "1.1\u2002\u2004Problem Statement",
        "level": 3
      },
      {
        "id": "12-our-approach-measuring-whats-missing",
        "title": "1.2\u2002\u2004Our Approach: Measuring what\u2019s missing",
        "level": 3
      },
      {
        "id": "2-preliminaries",
        "title": "2\u2002\u2004Preliminaries",
        "level": 2
      },
      {
        "id": "21-notation",
        "title": "2.1\u2002\u2004Notation",
        "level": 3
      },
      {
        "id": "22-sota-reference-model-based-membership-inference-attacks",
        "title": "2.2\u2002\u2004SOTA Reference Model-Based Membership Inference Attacks",
        "level": 3
      },
      {
        "id": "3-experimental-setup",
        "title": "3\u2002\u2004Experimental Setup",
        "level": 2
      },
      {
        "id": "datasets",
        "title": "Datasets.",
        "level": 4
      },
      {
        "id": "models",
        "title": "Models.",
        "level": 4
      },
      {
        "id": "attacks",
        "title": "Attacks.",
        "level": 4
      },
      {
        "id": "4-intuition",
        "title": "4\u2002\u2004Intuition",
        "level": 2
      },
      {
        "id": "loss-distributions-are-heavy-tailed",
        "title": "Loss distributions are heavy-tailed.",
        "level": 4
      },
      {
        "id": "the-difference-between-member-and-non-member-loss-distributions-is-driven-by-the-tail",
        "title": "The difference between member and non-member loss distributions is driven by the tail.",
        "level": 4
      },
      {
        "id": "vulnerable-members-are-those-that-are-missing-from-the-tail",
        "title": "Vulnerable members are those that are missing from the tail.",
        "level": 4
      },
      {
        "id": "5-estimating-vulnerability-to-sota-mias",
        "title": "5\u2002\u2004Estimating Vulnerability to SOTA MIAs",
        "level": 2
      },
      {
        "id": "51-varying-the-number-of-reference-models",
        "title": "5.1\u2002\u2004Varying the number of reference models",
        "level": 3
      },
      {
        "id": "52-fitting-different-functions",
        "title": "5.2\u2002\u2004Fitting different functions",
        "level": 3
      },
      {
        "id": "53-llms",
        "title": "5.3\u2002\u2004LLMs",
        "level": 3
      },
      {
        "id": "6-related-work",
        "title": "6\u2002\u2004Related Work",
        "level": 2
      },
      {
        "id": "membership-inference-attacks",
        "title": "Membership inference attacks.",
        "level": 4
      },
      {
        "id": "low-cost-attacks-and-free-identification-of-vulnerable-samples",
        "title": "Low-cost attacks and free identification of vulnerable samples.",
        "level": 4
      },
      {
        "id": "factors-influencing-membership-inference-vulnerability",
        "title": "Factors influencing membership inference vulnerability.",
        "level": 4
      },
      {
        "id": "7-conclusion",
        "title": "7\u2002\u2004Conclusion",
        "level": 2
      },
      {
        "id": "limitations-and-future-work",
        "title": "Limitations and future work.",
        "level": 4
      },
      {
        "id": "references",
        "title": "References",
        "level": 2
      },
      {
        "id": "8-appendix",
        "title": "8\u2002\u2004Appendix",
        "level": 2
      },
      {
        "id": "appendix-a-loss-distributions-across-all-setups",
        "title": "Appendix A Loss distributions across all setups",
        "level": 2
      },
      {
        "id": "appendix-b-varying-fprs",
        "title": "Appendix B Varying FPRs",
        "level": 2
      }
    ],
    "has_math": true
  },
  "cached_at": 1761248063.144625
}