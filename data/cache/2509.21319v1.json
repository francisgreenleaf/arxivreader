{
  "success": true,
  "arxiv_id": "2509.21319v1",
  "processed_content": {
    "success": true,
    "arxiv_id": "2509.21319v1",
    "metadata": {
      "arxiv_id": "2509.21319v1",
      "title": "RLBFF: Binary Flexible Feedback to bridge between Human Feedback & Verifiable Rewards",
      "authors": [],
      "abstract": "Reinforcement Learning with Human Feedback (RLHF) and Reinforcement Learning with Verifiable Rewards (RLVR) are the main RL paradigms used in LLM post-training, each offering distinct advantages. However, RLHF struggles with interpretability and reward hacking because it relies on human judgments that usually lack explicit criteria, whereas RLVR is limited in scope by its focus on correctness-based verifiers.\nWe propose Reinforcement Learning with Binary Flexible Feedback (RLBFF), which combines the versatility of human-driven preferences with the precision of rule-based verification, enabling reward models to capture nuanced aspects of response quality beyond mere correctness.\nRLBFF extracts principles that can be answered in a binary fashion (e.g. accuracy of information: \u201cyes\u201d, or code readability: \u201cno\u201d) from natural language feedback. Such principles can then be used to ground Reward Model training as an entailment task (response satisfies or does not satisfy an arbitrary principle). We show that Reward Models trained in this manner can outperform Bradley-Terry models when matched for data and achieve top performance on RM-Bench (86.2%) and JudgeBench (81.4%, #1 on leaderboard as of September 24, 2025). Additionally, users can specify principles of interest at inference time to customize the focus of our reward models, in contrast to Bradley-Terry models. Finally, we present a fully open source recipe (including data) to align Qwen3-32B using RLBFF and our Reward Model, to match or exceed the performance of o3-mini and DeepSeek R1 on general alignment benchmarks of MT-Bench, WildBench, and Arena Hard v2 (at <5<5% of the inference cost)."
    },
    "content": "<div class=\"arxiv-content\">\n<div class=\"ltx_page_content\">\n<article class=\"ltx_document ltx_authors_1line\">\n<h1 class=\"ltx_title ltx_title_document\" id=\"rlbff-binary-flexible-feedback-to-bridge-between-human-feedback-verifiable-rewards\">RLBFF: Binary Flexible Feedback to bridge between Human Feedback &amp; Verifiable Rewards</h1>\n<div class=\"ltx_authors\">\n<span class=\"ltx_creator ltx_role_author\">\n<span class=\"ltx_personname\">Zhilin Wang, Jiaqi Zeng, Olivier Delalleau, Ellie Evans, Daniel Egert,\n<br class=\"ltx_break\"/><span class=\"ltx_text ltx_font_bold\">Hoo-Chang Shin, Felipe Soares, Yi Dong, Oleksii Kuchaiev</span>\n<br class=\"ltx_break\"/>NVIDIA \n<br class=\"ltx_break\"/><span class=\"ltx_text ltx_font_typewriter\">{zhilinw, jiaqiz}@nvidia.com</span>\n<br class=\"ltx_break\"/>\n</span></span>\n</div>\n<div class=\"ltx_abstract\">\n<h6 class=\"ltx_title ltx_title_abstract\" id=\"abstract\">Abstract</h6>\n\n</div>\n<figure class=\"ltx_table\" id=\"S0.T1\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 1: </span>Comparison of Human Feedback with Verifiable Rewards for Reinforcement Learning, alongside our proposed Binary Flexible Feedback serving as a bridge between the two. See the Introduction for rationales behind the classification into good (<span class=\"ltx_text\" style=\"--ltx-fg-color:#76B900;\">\u2713</span>) and poor (<span class=\"ltx_text\" style=\"--ltx-fg-color:#FF0000;\">\u2717</span>) on various aspects.</figcaption>\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:433.6pt;height:31.2pt;vertical-align:-14.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;\">\n<div class=\"ltx_inline-block ltx_transformed_outer\" style=\"width:433.6pt;height:31.2pt;vertical-align:-14.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-127.8pt,9.2pt) scale(0.62923,0.62923) ;\">\n\n</span></div>\n</span></div>\n</figure>\n<section class=\"ltx_section\" id=\"S1\">\n<h2 class=\"ltx_title ltx_title_section\" id=\"1-introduction\">\n<span class=\"ltx_tag ltx_tag_section\">1 </span>Introduction</h2>\n<div class=\"ltx_para ltx_noindent\" id=\"S1.p1\">\n\n</div>\n<section class=\"ltx_paragraph\" id=\"S1.SS0.SSS0.Px1\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"formulation\">Formulation</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"S1.SS0.SSS0.Px1.p1\">\n\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"S1.SS0.SSS0.Px2\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"motivation\">Motivation</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"S1.SS0.SSS0.Px2.p1\">\n<p class=\"ltx_p\">To arrive at this formulation, we made a few design choices:</p>\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S1.SS0.SSS0.Px2.p2\">\n<ol class=\"ltx_enumerate\" id=\"S1.I1\">\n<li class=\"ltx_item\" id=\"S1.I1.i1\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">1.</span>\n<div class=\"ltx_para ltx_noindent\" id=\"S1.I1.i1.p1\">\n\n</div>\n</li>\n<li class=\"ltx_item\" id=\"S1.I1.i2\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">2.</span>\n<div class=\"ltx_para ltx_noindent\" id=\"S1.I1.i2.p1\">\n\n</div>\n</li>\n<li class=\"ltx_item\" id=\"S1.I1.i3\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">3.</span>\n<div class=\"ltx_para ltx_noindent\" id=\"S1.I1.i3.p1\">\n\n</div>\n</li>\n</ol>\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S1.SS0.SSS0.Px2.p3\">\n\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"S1.SS0.SSS0.Px3\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"wide-coverage\">Wide Coverage</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"S1.SS0.SSS0.Px3.p1\">\n\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"S1.SS0.SSS0.Px4\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"interpretability\">Interpretability</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"S1.SS0.SSS0.Px4.p1\">\n\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"S1.SS0.SSS0.Px5\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"precision-and-recall\">Precision and Recall</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"S1.SS0.SSS0.Px5.p1\">\n\n</div>\n<figure class=\"ltx_figure\" id=\"S1.F1\"><span class=\"ltx_inline-block\"><svg class=\"ltx_picture ltx_centering\" height=\"156.09\" id=\"S1.F1.pic1\" overflow=\"visible\" version=\"1.1\" viewbox=\"0 0 600 156.09\" width=\"600\"><g fill=\"#000000\" stroke=\"#000000\" stroke-width=\"0.4pt\" style=\"--ltx-stroke-color:#000000;--ltx-fill-color:#000000;\" transform=\"translate(0,156.09) matrix(1 0 0 -1 0 0)\"><g fill=\"#404040\" fill-opacity=\"1.0\" style=\"--ltx-fill-color:#404040;\"><path d=\"M 0 5.91 L 0 150.18 C 0 153.45 2.64 156.09 5.91 156.09 L 594.09 156.09 C 597.36 156.09 600 153.45 600 150.18 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z\" style=\"stroke:none\"></path></g><g fill=\"#F2F2F2\" fill-opacity=\"1.0\" style=\"--ltx-fill-color:#F2F2F2;\"><path d=\"M 1.97 5.91 L 1.97 150.18 C 1.97 152.36 3.73 154.12 5.91 154.12 L 594.09 154.12 C 596.27 154.12 598.03 152.36 598.03 150.18 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z\" style=\"stroke:none\"></path></g><g fill-opacity=\"1.0\" transform=\"matrix(1.0 0.0 0.0 1.0 21.65 16.47)\"><foreignobject color=\"#000000\" height=\"128.53\" overflow=\"visible\" style=\"--ltx-fg-color:#000000;--fo_width :40.23em;--fo_height:9.09em;--fo_depth :0.19em;\" transform=\"matrix(1 0 0 -1 0 125.84)\" width=\"556.69\"><span class=\"ltx_foreignobject_container\"><span class=\"ltx_foreignobject_content\">\n<span class=\"ltx_inline-block ltx_minipage ltx_align_bottom\" style=\"width:40.23em;\">\n<span class=\"ltx_p\">The response is mostly helpful. It resolves the issue directly, provides the corrected full code, and <span class=\"ltx_text\" style=\"--ltx-bg-color:#CCFFCC;\">follows the user\u2019s requirements</span> - <span class=\"ltx_text ltx_font_italic\">follows the user\u2019s requirements: <span class=\"ltx_text ltx_framed ltx_framed_underline\">yes</span></span>. It correctly interprets the real intent of the user and fixes the correct line. <span class=\"ltx_text\" style=\"--ltx-bg-color:#FFFFCC;\">However, it doesn\u2019t have any inline comments</span> - <span class=\"ltx_text ltx_font_italic\">includes inline comments: <span class=\"ltx_text ltx_framed ltx_framed_underline\">no</span></span>, especially where the update is done. It could be better if the code contained inline comments to line 5, where \u2018<math alttext=\"&lt;=\" class=\"ltx_Math\" display=\"inline\" id=\"S1.F1.pic1.m1\" intent=\":literal\"><semantics><mo>&lt;=</mo><annotation encoding=\"application/x-tex\">&lt;=</annotation></semantics></math>\u2019 is replaced with \u2018<math alttext=\"&lt;\" class=\"ltx_Math\" display=\"inline\" id=\"S1.F1.pic1.m2\" intent=\":literal\"><semantics><mo>&lt;</mo><annotation encoding=\"application/x-tex\">&lt;</annotation></semantics></math>\u2019.</span>\n</span></span></span></foreignobject></g></g></svg></span>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_figure\">Figure 1: </span>Example of Binary Flexible Feedback in Natural Language. <span class=\"ltx_text ltx_font_italic\">Text in italics</span> are generated principles and their fulfillment; Highlighted spans are evidence that supports the principle identification with <span class=\"ltx_text\" style=\"--ltx-bg-color:#CCFFCC;\">green</span> highlight indicating fulfillment while <span class=\"ltx_text\" style=\"--ltx-bg-color:#FFFFCC;\">yellow</span> highlights indicates non-fulfillment.</figcaption>\n</figure>\n</section>\n<section class=\"ltx_paragraph\" id=\"S1.SS0.SSS0.Px6\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"training-reward-models-using-binary-flexible-feedback\">Training Reward Models using Binary Flexible Feedback</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"S1.SS0.SSS0.Px6.p1\">\n\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"S1.SS0.SSS0.Px7\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"main-contributions\">Main Contributions</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"S1.SS0.SSS0.Px7.p1\">\n<ol class=\"ltx_enumerate\" id=\"S1.I2\">\n<li class=\"ltx_item\" id=\"S1.I2.i1\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">1.</span>\n<div class=\"ltx_para\" id=\"S1.I2.i1.p1\">\n<p class=\"ltx_p\">Reinforcement Learning with Binary Flexible Feedback, which combines the benefits of RLHF and RLVR. Reward Models trained on this technique have top performance on JudgeBench (81.4%, #1 on leaderboard as of 24 Sept 2025), RM-Bench and PrincipleBench.</p>\n</div>\n</li>\n<li class=\"ltx_item\" id=\"S1.I2.i2\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">2.</span>\n<div class=\"ltx_para ltx_noindent\" id=\"S1.I2.i2.p1\">\n<p class=\"ltx_p\">PrincipleBench, a benchmark to measure reward models\u2019 ability to follow specific principles when assigning reward, a feature not seen in prior public Reward Modeling benchmarks.</p>\n</div>\n</li>\n<li class=\"ltx_item\" id=\"S1.I2.i3\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">3.</span>\n<div class=\"ltx_para ltx_noindent\" id=\"S1.I2.i3.p1\">\n\n</div>\n</li>\n</ol>\n</div>\n</section>\n</section>\n<section class=\"ltx_section\" id=\"S2\">\n<h2 class=\"ltx_title ltx_title_section\" id=\"2-related-work\">\n<span class=\"ltx_tag ltx_tag_section\">2 </span>Related Work</h2>\n<section class=\"ltx_paragraph\" id=\"S2.SS0.SSS0.Px1\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"binary-flexible-feedback-for-safety-and-math\">Binary Flexible Feedback for Safety and Math</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"S2.SS0.SSS0.Px1.p1\">\n\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"S2.SS0.SSS0.Px2\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"generative-rewards-models-with-self-generated-criteria\">Generative Rewards Models with Self-Generated Criteria</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"S2.SS0.SSS0.Px2.p1\">\n\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"S2.SS0.SSS0.Px3\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"principle-following-generative-reward-models\">Principle-Following Generative Reward Models</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"S2.SS0.SSS0.Px3.p1\">\n\n</div>\n</section>\n</section>\n<section class=\"ltx_section\" id=\"S3\">\n<h2 class=\"ltx_title ltx_title_section\" id=\"3-training-data\">\n<span class=\"ltx_tag ltx_tag_section\">3 </span>Training Data</h2>\n<section class=\"ltx_paragraph\" id=\"S3.SS0.SSS0.Px1\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"downloading-helpsteer3-feedback\">Downloading HelpSteer3-Feedback</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"S3.SS0.SSS0.Px1.p1\">\n\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"S3.SS0.SSS0.Px2\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"extracting-principles-and-fulfillment\">Extracting Principles and Fulfillment</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"S3.SS0.SSS0.Px2.p1\">\n\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"S3.SS0.SSS0.Px3\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"filtering-principles-unsupported-by-feedback\">Filtering Principles Unsupported by Feedback</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"S3.SS0.SSS0.Px3.p1\">\n\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"S3.SS0.SSS0.Px4\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"removing-partially-fulfilled-principles\">Removing Partially Fulfilled Principles</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"S3.SS0.SSS0.Px4.p1\">\n<p class=\"ltx_p\">While we recognize that some principles can be partially fulfilled, natural language does not offer a clean way of determining whether partial means 10%, 25%, 50%, 75% or 90%. Similarly, using extent-markers in natural language such as slightly or moderately also does not offer precision, as different annotators might have different understandings of what each word means. We thus remove the principles marked as \u201dpartially\u201d fulfilled (only 13.8%, suggesting that a binary value is suitable for most principles). Among the remaining principles, 35.4% are no and 64.6% are yes - indicating only a slight imbalance in distribution.</p>\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"S3.SS0.SSS0.Px5\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"obtaining-high-precision-consensus-principles\">Obtaining High-Precision Consensus Principles</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"S3.SS0.SSS0.Px5.p1\">\n\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"S3.SS0.SSS0.Px6\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"human-verification\">Human Verification</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"S3.SS0.SSS0.Px6.p1\">\n\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"S3.SS0.SSS0.Px7\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"principle-distribution\">Principle Distribution</h4>\n<figure class=\"ltx_figure\" id=\"S3.F2\"><img alt=\"Refer to caption\" class=\"ltx_graphics ltx_centering ltx_img_landscape\" height=\"315\" id=\"S3.F2.g1\" src=\"https://arxiv.org/html/x1.png\" width=\"762\"/>\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_figure\">Figure 2: </span>40 most frequent words in principles, excluding stop-words. Clarity, accuracy and relevance are most common, followed by a long tail including comprehensiveness, readability and precision.</figcaption>\n</figure>\n<div class=\"ltx_para ltx_noindent\" id=\"S3.SS0.SSS0.Px7.p1\">\n\n</div>\n</section>\n</section>\n<section class=\"ltx_section\" id=\"S4\">\n<h2 class=\"ltx_title ltx_title_section\" id=\"4-reward-modeling\">\n<span class=\"ltx_tag ltx_tag_section\">4 </span>Reward Modeling</h2>\n<section class=\"ltx_subsection\" id=\"S4.SS1\">\n<h3 class=\"ltx_title ltx_title_subsection\" id=\"41-evaluation\">\n<span class=\"ltx_tag ltx_tag_subsection\">4.1 </span>Evaluation</h3>\n<section class=\"ltx_paragraph\" id=\"S4.SS1.SSS0.Px1\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"rm-bench-and-judgebench\">RM-Bench and JudgeBench</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"S4.SS1.SSS0.Px1.p1\">\n\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"S4.SS1.SSS0.Px2\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"principlebench\">PrincipleBench</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"S4.SS1.SSS0.Px2.p1\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"S4.SS1.SSS0.Px2.p2\">\n\n</div>\n</section>\n</section>\n<section class=\"ltx_subsection\" id=\"S4.SS2\">\n<h3 class=\"ltx_title ltx_title_subsection\" id=\"42-baselines\">\n<span class=\"ltx_tag ltx_tag_subsection\">4.2 </span>Baselines</h3>\n<section class=\"ltx_paragraph\" id=\"S4.SS2.SSS0.Px1\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"scalar-reward-models\">Scalar Reward Models</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"S4.SS2.SSS0.Px1.p1\">\n\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"S4.SS2.SSS0.Px2\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"generative-reward-models\">Generative Reward Models</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"S4.SS2.SSS0.Px2.p1\">\n\n</div>\n</section>\n</section>\n<section class=\"ltx_subsection\" id=\"S4.SS3\">\n<h3 class=\"ltx_title ltx_title_subsection\" id=\"43-training\">\n<span class=\"ltx_tag ltx_tag_subsection\">4.3 </span>Training</h3>\n<section class=\"ltx_paragraph\" id=\"S4.SS3.SSS0.Px1\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"scalar-reward-models\">Scalar Reward Models</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"S4.SS3.SSS0.Px1.p1\">\n\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"S4.SS3.SSS0.Px2\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"generative-reward-models\">Generative Reward Models</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"S4.SS3.SSS0.Px2.p1\">\n\n</div>\n</section>\n</section>\n<section class=\"ltx_subsection\" id=\"S4.SS4\">\n<h3 class=\"ltx_title ltx_title_subsection\" id=\"44-results\">\n<span class=\"ltx_tag ltx_tag_subsection\">4.4 </span>Results</h3>\n<figure class=\"ltx_table\" id=\"S4.T2\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 2: </span>Performance of Reward Models on RM-Bench and JudgeBench. Higher is better.</figcaption>\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:433.6pt;height:127.3pt;vertical-align:-62.1pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;\">\n<div class=\"ltx_inline-block ltx_transformed_outer\" style=\"width:433.6pt;height:127.3pt;vertical-align:-62.1pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-138.9pt,40.8pt) scale(0.60948,0.60948) ;\">\n\n</span></div>\n</span></div>\n</figure>\n<section class=\"ltx_paragraph\" id=\"S4.SS4.SSS0.Px1\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"flexible-principles-are-the-top-performing-model-across-scalar-and-generative-rms\">Flexible Principles are the top performing model across Scalar and Generative RMs</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"S4.SS4.SSS0.Px1.p1\">\n\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"S4.SS4.SSS0.Px2\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"poor-performance-of-baseline-genrms-on-judgebench\">Poor Performance of Baseline GenRMs on JudgeBench</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"S4.SS4.SSS0.Px2.p1\">\n\n</div>\n<figure class=\"ltx_table\" id=\"S4.T3\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 3: </span>Performance of Reward Models on PrincipleBench. Higher is better for each category.</figcaption>\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:433.6pt;height:117.2pt;vertical-align:-57.3pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;\">\n<div class=\"ltx_inline-block ltx_transformed_outer\" style=\"width:433.6pt;height:117.2pt;vertical-align:-57.3pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-191.7pt,51.8pt) scale(0.5307,0.5307) ;\">\n\n</span></div>\n</span></div>\n</figure>\n</section>\n<section class=\"ltx_paragraph\" id=\"S4.SS4.SSS0.Px3\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"flexible-principles-is-the-first-scalar-rm-to-enable-grounding-by-user-specified-principles\">Flexible Principles is the first Scalar RM to enable grounding by user-specified principles</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"S4.SS4.SSS0.Px3.p1\">\n\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"S4.SS4.SSS0.Px4\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"poor-performance-of-genrms-on-principlebench-relative-to-scalar-rms\">Poor Performance of GenRMs on PrincipleBench relative to Scalar RMs</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"S4.SS4.SSS0.Px4.p1\">\n\n</div>\n</section>\n</section>\n</section>\n<section class=\"ltx_section\" id=\"S5\">\n<h2 class=\"ltx_title ltx_title_section\" id=\"5-ablation-studies\">\n<span class=\"ltx_tag ltx_tag_section\">5 </span>Ablation Studies</h2>\n<figure class=\"ltx_table\" id=\"S5.T4\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 4: </span>Ablation of Scalar Reward Models on RM-Bench and JudgeBench. Higher is better.</figcaption>\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:433.6pt;height:70.2pt;vertical-align:-33.5pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;\">\n<div class=\"ltx_inline-block ltx_transformed_outer\" style=\"width:433.6pt;height:70.2pt;vertical-align:-33.5pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-121.6pt,19.7pt) scale(0.64062,0.64062) ;\">\n\n</span></div>\n</span></div>\n</figure>\n<section class=\"ltx_paragraph\" id=\"S5.SS0.SSS0.Px1\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"group-similarity-threshold-for-filtering-consensus-principles\">Group Similarity Threshold for Filtering Consensus Principles</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"S5.SS0.SSS0.Px1.p1\">\n\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"S5.SS0.SSS0.Px2\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"fixing-principle-to-accuracy-of-information-at-test-time\">Fixing Principle to Accuracy of Information at Test Time</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"S5.SS0.SSS0.Px2.p1\">\n\n</div>\n</section>\n</section>\n<section class=\"ltx_section\" id=\"S6\">\n<h2 class=\"ltx_title ltx_title_section\" id=\"6-model-alignment\">\n<span class=\"ltx_tag ltx_tag_section\">6 </span>Model Alignment</h2>\n<div class=\"ltx_para ltx_noindent\" id=\"S6.p1\">\n<p class=\"ltx_p\">Beyond evaluating the reward models\u2019 intrinsic performance, we also want to understand how they can be used to better align general-purpose LLMs. We conduct an alignment experiment with the Flexible Principles GenRM, the best performing model on RM-Bench and JudgeBench.</p>\n</div>\n<section class=\"ltx_paragraph\" id=\"S6.SS0.SSS0.Px1\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"evaluation\">Evaluation</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"S6.SS0.SSS0.Px1.p1\">\n\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"S6.SS0.SSS0.Px2\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"training\">Training</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"S6.SS0.SSS0.Px2.p1\">\n\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"S6.SS0.SSS0.Px3\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"results\">Results</h4>\n<figure class=\"ltx_table\" id=\"S6.T5\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 5: </span>Performance of Aligned Models. Higher is better for each metric except cost.</figcaption>\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:433.6pt;height:59pt;vertical-align:-28.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;\">\n<div class=\"ltx_inline-block ltx_transformed_outer\" style=\"width:433.6pt;height:59pt;vertical-align:-28.0pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(-144.4pt,19.7pt) scale(0.60015,0.60015) ;\">\n\n</span></div>\n</span></div>\n</figure>\n<div class=\"ltx_para ltx_noindent\" id=\"S6.SS0.SSS0.Px3.p1\">\n\n</div>\n</section>\n</section>\n<section class=\"ltx_section\" id=\"S7\">\n<h2 class=\"ltx_title ltx_title_section\" id=\"7-conclusion\">\n<span class=\"ltx_tag ltx_tag_section\">7 </span>Conclusion</h2>\n<div class=\"ltx_para ltx_noindent\" id=\"S7.p1\">\n\n</div>\n</section>\n<section class=\"ltx_section\" id=\"Sx1\">\n<h2 class=\"ltx_title ltx_title_section\" id=\"reproducibility-statement\">Reproducibility statement</h2>\n<div class=\"ltx_para ltx_noindent\" id=\"Sx1.p1\">\n\n</div>\n</section>\n<section class=\"ltx_bibliography\" id=\"bib\">\n<h2 class=\"ltx_title ltx_title_bibliography\" id=\"references\">References</h2>\n<ul class=\"ltx_biblist\">\n<li class=\"ltx_bibitem\" id=\"bib.bib1\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Anugraha et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nDavid Anugraha, Zilu Tang, Lester James\u00a0V. Miranda, Hanyang Zhao, Mohammad\u00a0Rifqi Farhansyah, Garry Kuwanto, Derry Wijaya, and Genta\u00a0Indra Winata.\n\n</span>\n<span class=\"ltx_bibblock\">R3: Robust rubric-agnostic reward models, 2025.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2505.13388\" title=\"\">https://arxiv.org/abs/2505.13388</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib2\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Bachmann (2025)</span>\n<span class=\"ltx_bibblock\">\nMax Bachmann.\n\n</span>\n<span class=\"ltx_bibblock\">rapidfuzz/rapidfuzz: Release 3.13.0, April 2025.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://doi.org/10.5281/zenodo.15133267\" title=\"\">https://doi.org/10.5281/zenodo.15133267</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib3\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Bai et\u00a0al. (2022)</span>\n<span class=\"ltx_bibblock\">\nYuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, Nicholas Joseph, Saurav Kadavath, Jackson Kernion, Tom Conerly, Sheer El-Showk, Nelson Elhage, Zac Hatfield-Dodds, Danny Hernandez, Tristan Hume, Scott Johnston, Shauna Kravec, Liane Lovitt, Neel Nanda, Catherine Olsson, Dario Amodei, Tom Brown, Jack Clark, Sam McCandlish, Chris Olah, Ben Mann, and Jared Kaplan.\n\n</span>\n<span class=\"ltx_bibblock\">Training a helpful and harmless assistant with reinforcement learning from human feedback, 2022.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib4\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Chen et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nXiusi Chen, Gaotang Li, Ziqi Wang, Bowen Jin, Cheng Qian, Yu\u00a0Wang, Hongru Wang, Yu\u00a0Zhang, Denghui Zhang, Tong Zhang, Hanghang Tong, and Heng Ji.\n\n</span>\n<span class=\"ltx_bibblock\">Rm-r1: Reward modeling as reasoning, 2025.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2505.02387\" title=\"\">https://arxiv.org/abs/2505.02387</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib5\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Chiang et\u00a0al. (2024)</span>\n<span class=\"ltx_bibblock\">\nWei-Lin Chiang, Lianmin Zheng, Ying Sheng, Anastasios\u00a0Nikolas Angelopoulos, Tianle Li, Dacheng Li, Hao Zhang, Banghua Zhu, Michael Jordan, Joseph\u00a0E. Gonzalez, and Ion Stoica.\n\n</span>\n<span class=\"ltx_bibblock\">Chatbot arena: An open platform for evaluating llms by human preference, 2024.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib6\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">ContextualAI (2025a)</span>\n<span class=\"ltx_bibblock\">\nContextualAI.\n\n</span>\n<span class=\"ltx_bibblock\">Lmunit-llama3.1-70b.\n\n</span>\n<span class=\"ltx_bibblock\"><a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://huggingface.co/ContextualAI/LMUnit-llama3.1-70b\" title=\"\">https://huggingface.co/ContextualAI/LMUnit-llama3.1-70b</a>, 2025a.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib7\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">ContextualAI (2025b)</span>\n<span class=\"ltx_bibblock\">\nContextualAI.\n\n</span>\n<span class=\"ltx_bibblock\">Lmunit-qwen2.5-72b.\n\n</span>\n<span class=\"ltx_bibblock\"><a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://huggingface.co/ContextualAI/LMUnit-qwen2.5-72b\" title=\"\">https://huggingface.co/ContextualAI/LMUnit-qwen2.5-72b</a>, 2025b.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib8\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">DeepSeek-AI et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nDeepSeek-AI, Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, Xiaokang Zhang, Xingkai Yu, Yu\u00a0Wu, Z.\u00a0F. Wu, Zhibin Gou, Zhihong Shao, Zhuoshu Li, Ziyi Gao, Aixin Liu, Bing Xue, Bingxuan Wang, Bochao Wu, Bei Feng, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, Damai Dai, Deli Chen, Dongjie Ji, Erhang Li, Fangyun Lin, Fucong Dai, Fuli Luo, Guangbo Hao, Guanting Chen, Guowei Li, H.\u00a0Zhang, Han Bao, Hanwei Xu, Haocheng Wang, Honghui Ding, Huajian Xin, Huazuo Gao, Hui Qu, Hui Li, Jianzhong Guo, Jiashi Li, Jiawei Wang, Jingchang Chen, Jingyang Yuan, Junjie Qiu, Junlong Li, J.\u00a0L. Cai, Jiaqi Ni, Jian Liang, Jin Chen, Kai Dong, Kai Hu, Kaige Gao, Kang Guan, Kexin Huang, Kuai Yu, Lean Wang, Lecong Zhang, Liang Zhao, Litong Wang, Liyue Zhang, Lei Xu, Leyi Xia, Mingchuan Zhang, Minghua Zhang, Minghui Tang, Meng Li, Miaojun Wang, Mingming Li, Ning Tian, Panpan Huang, Peng Zhang, Qiancheng Wang, Qinyu Chen, Qiushi Du, Ruiqi Ge, Ruisong\nZhang, Ruizhe Pan, Runji Wang, R.\u00a0J. Chen, R.\u00a0L. Jin, Ruyi Chen, Shanghao Lu, Shangyan Zhou, Shanhuang Chen, Shengfeng Ye, Shiyu Wang, Shuiping Yu, Shunfeng Zhou, Shuting Pan, S.\u00a0S. Li, Shuang Zhou, Shaoqing Wu, Shengfeng Ye, Tao Yun, Tian Pei, Tianyu Sun, T.\u00a0Wang, Wangding Zeng, Wanjia Zhao, Wen Liu, Wenfeng Liang, Wenjun Gao, Wenqin Yu, Wentao Zhang, W.\u00a0L. Xiao, Wei An, Xiaodong Liu, Xiaohan Wang, Xiaokang Chen, Xiaotao Nie, Xin Cheng, Xin Liu, Xin Xie, Xingchao Liu, Xinyu Yang, Xinyuan Li, Xuecheng Su, Xuheng Lin, X.\u00a0Q. Li, Xiangyue Jin, Xiaojin Shen, Xiaosha Chen, Xiaowen Sun, Xiaoxiang Wang, Xinnan Song, Xinyi Zhou, Xianzu Wang, Xinxia Shan, Y.\u00a0K. Li, Y.\u00a0Q. Wang, Y.\u00a0X. Wei, Yang Zhang, Yanhong Xu, Yao Li, Yao Zhao, Yaofeng Sun, Yaohui Wang, Yi\u00a0Yu, Yichao Zhang, Yifan Shi, Yiliang Xiong, Ying He, Yishi Piao, Yisong Wang, Yixuan Tan, Yiyang Ma, Yiyuan Liu, Yongqiang Guo, Yuan Ou, Yuduan Wang, Yue Gong, Yuheng Zou, Yujia He, Yunfan Xiong, Yuxiang Luo, Yuxiang You, Yuxuan Liu, Yuyang Zhou, Y.\u00a0X. Zhu,\nYanhong Xu, Yanping Huang, Yaohui Li, Yi\u00a0Zheng, Yuchen Zhu, Yunxian Ma, Ying Tang, Yukun Zha, Yuting Yan, Z.\u00a0Z. Ren, Zehui Ren, Zhangli Sha, Zhe Fu, Zhean Xu, Zhenda Xie, Zhengyan Zhang, Zhewen Hao, Zhicheng Ma, Zhigang Yan, Zhiyu Wu, Zihui Gu, Zijia Zhu, Zijun Liu, Zilin Li, Ziwei Xie, Ziyang Song, Zizheng Pan, Zhen Huang, Zhipeng Xu, Zhongyu Zhang, and Zhen Zhang.\n\n</span>\n<span class=\"ltx_bibblock\">Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning, 2025.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2501.12948\" title=\"\">https://arxiv.org/abs/2501.12948</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib9\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Dubois et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nYann Dubois, Bal\u00e1zs Galambosi, Percy Liang, and Tatsunori\u00a0B. Hashimoto.\n\n</span>\n<span class=\"ltx_bibblock\">Length-controlled alpacaeval: A simple way to debias automatic evaluators, 2025.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2404.04475\" title=\"\">https://arxiv.org/abs/2404.04475</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib10\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Ethayarajh et\u00a0al. (2024)</span>\n<span class=\"ltx_bibblock\">\nKawin Ethayarajh, Winnie Xu, Niklas Muennighoff, Dan Jurafsky, and Douwe Kiela.\n\n</span>\n<span class=\"ltx_bibblock\">Kto: Model alignment as prospect theoretic optimization, 2024.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2402.01306\" title=\"\">https://arxiv.org/abs/2402.01306</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib11\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Gemma et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nTeam Gemma, Aishwarya Kamath, Johan Ferret, Shreya Pathak, Nino Vieillard, Ramona Merhej, Sarah Perrin, Tatiana Matejovicova, Alexandre Ram\u00e9, Morgane Rivi\u00e8re, Louis Rouillard, Thomas Mesnard, Geoffrey Cideron, Jean bastien Grill, Sabela Ramos, Edouard Yvinec, Michelle Casbon, Etienne Pot, Ivo Penchev, Ga\u00ebl Liu, Francesco Visin, Kathleen Kenealy, Lucas Beyer, Xiaohai Zhai, Anton Tsitsulin, Robert Busa-Fekete, Alex Feng, Noveen Sachdeva, Benjamin Coleman, Yi\u00a0Gao, Basil Mustafa, Iain Barr, Emilio Parisotto, David Tian, Matan Eyal, Colin Cherry, Jan-Thorsten Peter, Danila Sinopalnikov, Surya Bhupatiraju, Rishabh Agarwal, Mehran Kazemi, Dan Malkin, Ravin Kumar, David Vilar, Idan Brusilovsky, Jiaming Luo, Andreas Steiner, Abe Friesen, Abhanshu Sharma, Abheesht Sharma, Adi\u00a0Mayrav Gilady, Adrian Goedeckemeyer, Alaa Saade, Alex Feng, Alexander Kolesnikov, Alexei Bendebury, Alvin Abdagic, Amit Vadi, Andr\u00e1s Gy\u00f6rgy, Andr\u00e9\u00a0Susano Pinto, Anil Das, Ankur Bapna, Antoine Miech, Antoine Yang, Antonia Paterson, Ashish\nShenoy, Ayan Chakrabarti, Bilal Piot, Bo\u00a0Wu, Bobak Shahriari, Bryce Petrini, Charlie Chen, Charline\u00a0Le Lan, Christopher\u00a0A. Choquette-Choo, CJ\u00a0Carey, Cormac Brick, Daniel Deutsch, Danielle Eisenbud, Dee Cattle, Derek Cheng, Dimitris Paparas, Divyashree\u00a0Shivakumar Sreepathihalli, Doug Reid, Dustin Tran, Dustin Zelle, Eric Noland, Erwin Huizenga, Eugene Kharitonov, Frederick Liu, Gagik Amirkhanyan, Glenn Cameron, Hadi Hashemi, Hanna Klimczak-Pluci\u0144ska, Harman Singh, Harsh Mehta, Harshal\u00a0Tushar Lehri, Hussein Hazimeh, Ian Ballantyne, Idan Szpektor, Ivan Nardini, Jean Pouget-Abadie, Jetha Chan, Joe Stanton, John Wieting, Jonathan Lai, Jordi Orbay, Joseph Fernandez, Josh Newlan, Ju\u00a0yeong Ji, Jyotinder Singh, Kat Black, Kathy Yu, Kevin Hui, Kiran Vodrahalli, Klaus Greff, Linhai Qiu, Marcella Valentine, Marina Coelho, Marvin Ritter, Matt Hoffman, Matthew Watson, Mayank Chaturvedi, Michael Moynihan, Min Ma, Nabila Babar, Natasha Noy, Nathan Byrd, Nick Roy, Nikola Momchev, Nilay Chauhan, Noveen Sachdeva, Oskar\nBunyan, Pankil Botarda, Paul Caron, Paul\u00a0Kishan Rubenstein, Phil Culliton, Philipp Schmid, Pier\u00a0Giuseppe Sessa, Pingmei Xu, Piotr Stanczyk, Pouya Tafti, Rakesh Shivanna, Renjie Wu, Renke Pan, Reza Rokni, Rob Willoughby, Rohith Vallu, Ryan Mullins, Sammy Jerome, Sara Smoot, Sertan Girgin, Shariq Iqbal, Shashir Reddy, Shruti Sheth, Siim P\u00f5der, Sijal Bhatnagar, Sindhu\u00a0Raghuram Panyam, Sivan Eiger, Susan Zhang, Tianqi Liu, Trevor Yacovone, Tyler Liechty, Uday Kalra, Utku Evci, Vedant Misra, Vincent Roseberry, Vlad Feinberg, Vlad Kolesnikov, Woohyun Han, Woosuk Kwon, Xi\u00a0Chen, Yinlam Chow, Yuvein Zhu, Zichuan Wei, Zoltan Egyed, Victor Cotruta, Minh Giang, Phoebe Kirk, Anand Rao, Kat Black, Nabila Babar, Jessica Lo, Erica Moreira, Luiz\u00a0Gustavo Martins, Omar Sanseviero, Lucas Gonzalez, Zach Gleicher, Tris Warkentin, Vahab Mirrokni, Evan Senter, Eli Collins, Joelle Barral, Zoubin Ghahramani, Raia Hadsell, Yossi Matias, D.\u00a0Sculley, Slav Petrov, Noah Fiedel, Noam Shazeer, Oriol Vinyals, Jeff Dean, Demis Hassabis,\nKoray Kavukcuoglu, Clement Farabet, Elena Buchatskaya, Jean-Baptiste Alayrac, Rohan Anil, Dmitry, Lepikhin, Sebastian Borgeaud, Olivier Bachem, Armand Joulin, Alek Andreev, Cassidy Hardin, Robert Dadashi, and L\u00e9onard Hussenot.\n\n</span>\n<span class=\"ltx_bibblock\">Gemma 3 technical report, 2025.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2503.19786\" title=\"\">https://arxiv.org/abs/2503.19786</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib12\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Huang et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nYuzhen Huang, Weihao Zeng, Xingshan Zeng, Qi\u00a0Zhu, and Junxian He.\n\n</span>\n<span class=\"ltx_bibblock\">Pitfalls of rule- and model-based verifiers \u2013 a case study on mathematical reasoning, 2025.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2505.22203\" title=\"\">https://arxiv.org/abs/2505.22203</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib13\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Kadavath et\u00a0al. (2022)</span>\n<span class=\"ltx_bibblock\">\nSaurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan, Dawn Drain, Ethan Perez, Nicholas Schiefer, Zac Hatfield-Dodds, Nova DasSarma, Eli Tran-Johnson, Scott Johnston, Sheer El-Showk, Andy Jones, Nelson Elhage, Tristan Hume, Anna Chen, Yuntao Bai, Sam Bowman, Stanislav Fort, Deep Ganguli, Danny Hernandez, Josh Jacobson, Jackson Kernion, Shauna Kravec, Liane Lovitt, Kamal Ndousse, Catherine Olsson, Sam Ringer, Dario Amodei, Tom Brown, Jack Clark, Nicholas Joseph, Ben Mann, Sam McCandlish, Chris Olah, and Jared Kaplan.\n\n</span>\n<span class=\"ltx_bibblock\">Language models (mostly) know what they know, 2022.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2207.05221\" title=\"\">https://arxiv.org/abs/2207.05221</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib14\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Keller &amp; Kostromitina (2020)</span>\n<span class=\"ltx_bibblock\">\nDaniel Keller and Maria Kostromitina.\n\n</span>\n<span class=\"ltx_bibblock\">Characterizing non-chain restaurants\u2019 yelp star-ratings: Generalizable findings from a representative sample of yelp reviews.\n\n</span>\n<span class=\"ltx_bibblock\"><em class=\"ltx_emph ltx_font_italic\">International Journal of Hospitality Management</em>, 86:102440, 2020.\n\n</span>\n<span class=\"ltx_bibblock\">ISSN 0278-4319.\n\n</span>\n<span class=\"ltx_bibblock\">doi: <span class=\"ltx_ref ltx_nolink ltx_Url ltx_ref_self\">https://doi.org/10.1016/j.ijhm.2019.102440</span>.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://www.sciencedirect.com/science/article/pii/S0278431919312332\" title=\"\">https://www.sciencedirect.com/science/article/pii/S0278431919312332</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib15\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Kim et\u00a0al. (2024)</span>\n<span class=\"ltx_bibblock\">\nSeungone Kim, Juyoung Suk, Shayne Longpre, Bill\u00a0Yuchen Lin, Jamin Shin, Sean Welleck, Graham Neubig, Moontae Lee, Kyungjae Lee, and Minjoon Seo.\n\n</span>\n<span class=\"ltx_bibblock\">Prometheus 2: An open source language model specialized in evaluating other language models, 2024.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2405.01535\" title=\"\">https://arxiv.org/abs/2405.01535</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib16\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Lambert et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nNathan Lambert, Jacob Morrison, Valentina Pyatkin, Shengyi Huang, Hamish Ivison, Faeze Brahman, Lester James\u00a0V. Miranda, Alisa Liu, Nouha Dziri, Shane Lyu, Yuling Gu, Saumya Malik, Victoria Graf, Jena\u00a0D. Hwang, Jiangjiang Yang, Ronan\u00a0Le Bras, Oyvind Tafjord, Chris Wilhelm, Luca Soldaini, Noah\u00a0A. Smith, Yizhong Wang, Pradeep Dasigi, and Hannaneh Hajishirzi.\n\n</span>\n<span class=\"ltx_bibblock\">Tulu 3: Pushing frontiers in open language model post-training, 2025.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2411.15124\" title=\"\">https://arxiv.org/abs/2411.15124</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib17\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Li et\u00a0al. (2024)</span>\n<span class=\"ltx_bibblock\">\nTianle Li, Wei-Lin Chiang, Evan Frick, Lisa Dunlap, Banghua Zhu, Joseph\u00a0E. Gonzalez, and Ion Stoica.\n\n</span>\n<span class=\"ltx_bibblock\">From live data to high-quality benchmarks: The Arena-Hard pipeline.\n\n</span>\n<span class=\"ltx_bibblock\"><a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://lmsys.org/blog/2024-04-19-arena-hard/\" title=\"\">https://lmsys.org/blog/2024-04-19-arena-hard/</a>, April 2024.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib18\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Lin et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nBill\u00a0Yuchen Lin, Yuntian Deng, Khyathi Chandu, Abhilasha Ravichander, Valentina Pyatkin, Nouha Dziri, Ronan\u00a0Le Bras, and Yejin Choi.\n\n</span>\n<span class=\"ltx_bibblock\">Wildbench: Benchmarking LLMs with challenging tasks from real users in the wild.\n\n</span>\n<span class=\"ltx_bibblock\">In <em class=\"ltx_emph ltx_font_italic\">The Thirteenth International Conference on Learning Representations</em>, 2025.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://openreview.net/forum?id=MKEHCx25xp\" title=\"\">https://openreview.net/forum?id=MKEHCx25xp</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib19\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Liu et\u00a0al. (2024)</span>\n<span class=\"ltx_bibblock\">\nYantao Liu, Zijun Yao, Rui Min, Yixin Cao, Lei Hou, and Juanzi Li.\n\n</span>\n<span class=\"ltx_bibblock\">Rm-bench: Benchmarking reward models of language models with subtlety and style, 2024.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2410.16184\" title=\"\">https://arxiv.org/abs/2410.16184</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib20\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Liu et\u00a0al. (2025a)</span>\n<span class=\"ltx_bibblock\">\nYantao Liu, Zijun Yao, Rui Min, Yixin Cao, Lei Hou, and Juanzi Li.\n\n</span>\n<span class=\"ltx_bibblock\">RM-bench: Benchmarking reward models of language models with subtlety and style.\n\n</span>\n<span class=\"ltx_bibblock\">In <em class=\"ltx_emph ltx_font_italic\">The Thirteenth International Conference on Learning Representations</em>, 2025a.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://openreview.net/forum?id=QEHrmQPBdd\" title=\"\">https://openreview.net/forum?id=QEHrmQPBdd</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib21\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Liu et\u00a0al. (2025b)</span>\n<span class=\"ltx_bibblock\">\nZijun Liu, Peiyi Wang, Runxin Xu, Shirong Ma, Chong Ruan, Peng Li, Yang Liu, and Yu\u00a0Wu.\n\n</span>\n<span class=\"ltx_bibblock\">Inference-time scaling for generalist reward modeling, 2025b.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2504.02495\" title=\"\">https://arxiv.org/abs/2504.02495</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib22\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">LMSys (2024)</span>\n<span class=\"ltx_bibblock\">\nLMSys.\n\n</span>\n<span class=\"ltx_bibblock\">Arena-hard-auto leaderboard.\n\n</span>\n<span class=\"ltx_bibblock\"><a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://github.com/lm-sys/arena-hard-auto\" title=\"\">https://github.com/lm-sys/arena-hard-auto</a>, 2024.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib23\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Meng et\u00a0al. (2024)</span>\n<span class=\"ltx_bibblock\">\nYu\u00a0Meng, Mengzhou Xia, and Danqi Chen.\n\n</span>\n<span class=\"ltx_bibblock\">SimPO: Simple preference optimization with a reference-free reward, 2024.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib24\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Mu et\u00a0al. (2024)</span>\n<span class=\"ltx_bibblock\">\nTong Mu, Alec Helyar, Johannes Heidecke, Joshua Achiam, Andrea Vallone, Ian Kivlichan, Molly Lin, Alex Beutel, John Schulman, and Lilian Weng.\n\n</span>\n<span class=\"ltx_bibblock\">Rule based rewards for language model safety, 2024.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2411.01111\" title=\"\">https://arxiv.org/abs/2411.01111</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib25\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Muennighoff et\u00a0al. (2023)</span>\n<span class=\"ltx_bibblock\">\nNiklas Muennighoff, Nouamane Tazi, Loic Magne, and Nils Reimers.\n\n</span>\n<span class=\"ltx_bibblock\">MTEB: Massive text embedding benchmark.\n\n</span>\n<span class=\"ltx_bibblock\">In Andreas Vlachos and Isabelle Augenstein (eds.), <em class=\"ltx_emph ltx_font_italic\">Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics</em>, pp.  2014\u20132037, Dubrovnik, Croatia, May 2023. Association for Computational Linguistics.\n\n</span>\n<span class=\"ltx_bibblock\">doi: <span class=\"ltx_ref ltx_nolink ltx_Url ltx_ref_self\">10.18653/v1/2023.eacl-main.148</span>.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://aclanthology.org/2023.eacl-main.148/\" title=\"\">https://aclanthology.org/2023.eacl-main.148/</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib26\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">NVIDIA (2025a)</span>\n<span class=\"ltx_bibblock\">\nNVIDIA.\n\n</span>\n<span class=\"ltx_bibblock\">nvidia/HelpSteer3#feedback.\n\n</span>\n<span class=\"ltx_bibblock\"><a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://huggingface.co/datasets/nvidia/HelpSteer3#feedback\" title=\"\">https://huggingface.co/datasets/nvidia/HelpSteer3#feedback</a>, 2025a.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib27\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">NVIDIA (2025b)</span>\n<span class=\"ltx_bibblock\">\nNemo NVIDIA.\n\n</span>\n<span class=\"ltx_bibblock\">Nemo rl: A scalable and efficient post-training library.\n\n</span>\n<span class=\"ltx_bibblock\"><a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://github.com/NVIDIA-NeMo/RL\" title=\"\">https://github.com/NVIDIA-NeMo/RL</a>, 2025b.\n\n</span>\n<span class=\"ltx_bibblock\">GitHub repository.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib28\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">OpenAI (2025)</span>\n<span class=\"ltx_bibblock\">\nOpenAI.\n\n</span>\n<span class=\"ltx_bibblock\">Openai model spec, Apr 2025.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://model-spec.openai.com/2025-04-11.html\" title=\"\">https://model-spec.openai.com/2025-04-11.html</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib29\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">OpenRouter (2025)</span>\n<span class=\"ltx_bibblock\">\nOpenRouter.\n\n</span>\n<span class=\"ltx_bibblock\">Openrouter.\n\n</span>\n<span class=\"ltx_bibblock\"><a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://openrouter.ai/models?fmt=table\" title=\"\">https://openrouter.ai/models?fmt=table</a>, 2025.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib30\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Ouyang et\u00a0al. (2022)</span>\n<span class=\"ltx_bibblock\">\nLong Ouyang, Jeff Wu, Xu\u00a0Jiang, Diogo Almeida, Carroll\u00a0L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe.\n\n</span>\n<span class=\"ltx_bibblock\">Training language models to follow instructions with human feedback, 2022.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib31\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Pyatkin et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nValentina Pyatkin, Saumya Malik, Victoria Graf, Hamish Ivison, Shengyi Huang, Pradeep Dasigi, Nathan Lambert, and Hannaneh Hajishirzi.\n\n</span>\n<span class=\"ltx_bibblock\">Generalizing verifiable instruction following, 2025.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2507.02833\" title=\"\">https://arxiv.org/abs/2507.02833</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib32\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Saad-Falcon et\u00a0al. (2024)</span>\n<span class=\"ltx_bibblock\">\nJon Saad-Falcon, Rajan Vivek, William Berrios, Nandita\u00a0Shankar Naik, Matija Franklin, Bertie Vidgen, Amanpreet Singh, Douwe Kiela, and Shikib Mehri.\n\n</span>\n<span class=\"ltx_bibblock\">Lmunit: Fine-grained evaluation with natural language unit tests, 2024.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2412.13091\" title=\"\">https://arxiv.org/abs/2412.13091</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib33\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Shao et\u00a0al. (2024)</span>\n<span class=\"ltx_bibblock\">\nZhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, Y.\u00a0K. Li, Y.\u00a0Wu, and Daya Guo.\n\n</span>\n<span class=\"ltx_bibblock\">Deepseekmath: Pushing the limits of mathematical reasoning in open language models, 2024.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2402.03300\" title=\"\">https://arxiv.org/abs/2402.03300</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib34\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Sharma et\u00a0al. (2023)</span>\n<span class=\"ltx_bibblock\">\nMrinank Sharma, Meg Tong, Tomasz Korbak, David Duvenaud, Amanda Askell, Samuel\u00a0R. Bowman, Newton Cheng, Esin Durmus, Zac Hatfield-Dodds, Scott\u00a0R. Johnston, Shauna Kravec, Timothy Maxwell, Sam McCandlish, Kamal Ndousse, Oliver Rausch, Nicholas Schiefer, Da\u00a0Yan, Miranda Zhang, and Ethan Perez.\n\n</span>\n<span class=\"ltx_bibblock\">Towards understanding sycophancy in language models, 2023.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib35\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Shen et\u00a0al. (2024)</span>\n<span class=\"ltx_bibblock\">\nGerald Shen, Zhilin Wang, Olivier Delalleau, Jiaqi Zeng, Yi\u00a0Dong, Daniel Egert, Shengyang Sun, Jimmy Zhang, Sahil Jain, Ali Taghibakhshi, Markel\u00a0Sanz Ausin, Ashwath Aithal, and Oleksii Kuchaiev.\n\n</span>\n<span class=\"ltx_bibblock\">NeMo-Aligner: Scalable toolkit for efficient model alignment, 2024.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib36\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Tan et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nSijun Tan, Siyuan Zhuang, Kyle Montgomery, William\u00a0Yuan Tang, Alejandro Cuadron, Chenguang Wang, Raluca Popa, and Ion Stoica.\n\n</span>\n<span class=\"ltx_bibblock\">Judgebench: A benchmark for evaluating LLM-based judges.\n\n</span>\n<span class=\"ltx_bibblock\">In <em class=\"ltx_emph ltx_font_italic\">The Thirteenth International Conference on Learning Representations</em>, 2025.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://openreview.net/forum?id=G0dksFayVq\" title=\"\">https://openreview.net/forum?id=G0dksFayVq</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib37\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Team et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nKimi Team, Yifan Bai, Yiping Bao, Guanduo Chen, Jiahao Chen, Ningxin Chen, Ruijue Chen, Yanru Chen, Yuankun Chen, Yutian Chen, Zhuofu Chen, Jialei Cui, Hao Ding, Mengnan Dong, Angang Du, Chenzhuang Du, Dikang Du, Yulun Du, Yu\u00a0Fan, Yichen Feng, Kelin Fu, Bofei Gao, Hongcheng Gao, Peizhong Gao, Tong Gao, Xinran Gu, Longyu Guan, Haiqing Guo, Jianhang Guo, Hao Hu, Xiaoru Hao, Tianhong He, Weiran He, Wenyang He, Chao Hong, Yangyang Hu, Zhenxing Hu, Weixiao Huang, Zhiqi Huang, Zihao Huang, Tao Jiang, Zhejun Jiang, Xinyi Jin, Yongsheng Kang, Guokun Lai, Cheng Li, Fang Li, Haoyang Li, Ming Li, Wentao Li, Yanhao Li, Yiwei Li, Zhaowei Li, Zheming Li, Hongzhan Lin, Xiaohan Lin, Zongyu Lin, Chengyin Liu, Chenyu Liu, Hongzhang Liu, Jingyuan Liu, Junqi Liu, Liang Liu, Shaowei Liu, T.\u00a0Y. Liu, Tianwei Liu, Weizhou Liu, Yangyang Liu, Yibo Liu, Yiping Liu, Yue Liu, Zhengying Liu, Enzhe Lu, Lijun Lu, Shengling Ma, Xinyu Ma, Yingwei Ma, Shaoguang Mao, Jie Mei, Xin Men, Yibo Miao, Siyuan Pan, Yebo Peng, Ruoyu Qin, Bowen Qu, Zeyu\nShang, Lidong Shi, Shengyuan Shi, Feifan Song, Jianlin Su, Zhengyuan Su, Xinjie Sun, Flood Sung, Heyi Tang, Jiawen Tao, Qifeng Teng, Chensi Wang, Dinglu Wang, Feng Wang, Haiming Wang, Jianzhou Wang, Jiaxing Wang, Jinhong Wang, Shengjie Wang, Shuyi Wang, Yao Wang, Yejie Wang, Yiqin Wang, Yuxin Wang, Yuzhi Wang, Zhaoji Wang, Zhengtao Wang, Zhexu Wang, Chu Wei, Qianqian Wei, Wenhao Wu, Xingzhe Wu, Yuxin Wu, Chenjun Xiao, Xiaotong Xie, Weimin Xiong, Boyu Xu, Jing Xu, Jinjing Xu, L.\u00a0H. Xu, Lin Xu, Suting Xu, Weixin Xu, Xinran Xu, Yangchuan Xu, Ziyao Xu, Junjie Yan, Yuzi Yan, Xiaofei Yang, Ying Yang, Zhen Yang, Zhilin Yang, Zonghan Yang, Haotian Yao, Xingcheng Yao, Wenjie Ye, Zhuorui Ye, Bohong Yin, Longhui Yu, Enming Yuan, Hongbang Yuan, Mengjie Yuan, Haobing Zhan, Dehao Zhang, Hao Zhang, Wanlu Zhang, Xiaobin Zhang, Yangkun Zhang, Yizhi Zhang, Yongting Zhang, Yu\u00a0Zhang, Yutao Zhang, Yutong Zhang, Zheng Zhang, Haotian Zhao, Yikai Zhao, Huabin Zheng, Shaojie Zheng, Jianren Zhou, Xinyu Zhou, Zaida Zhou, Zhen Zhu,\nWeiyu Zhuang, and Xinxing Zu.\n\n</span>\n<span class=\"ltx_bibblock\">Kimi k2: Open agentic intelligence, 2025.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2507.20534\" title=\"\">https://arxiv.org/abs/2507.20534</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib38\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">THU-KEG (2025)</span>\n<span class=\"ltx_bibblock\">\nTHU-KEG.\n\n</span>\n<span class=\"ltx_bibblock\">Rm-bench leaderboard.\n\n</span>\n<span class=\"ltx_bibblock\"><a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://github.com/THU-KEG/RM-Bench-Leaderboard\" title=\"\">https://github.com/THU-KEG/RM-Bench-Leaderboard</a>, 2025.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib39\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Wake et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nAlan Wake, Bei Chen, C.\u00a0X. Lv, Chao Li, Chengen Huang, Chenglin Cai, Chujie Zheng, Daniel Cooper, Fan Zhou, Feng Hu, Ge\u00a0Zhang, Guoyin Wang, Heng Ji, Howard Qiu, Jiangcheng Zhu, Jun Tian, Katherine Su, Lihuan Zhang, Liying Li, Ming Song, Mou Li, Peng Liu, Qicheng Hu, Shawn Wang, Shijun Zhou, Shiming Yang, Shiyong Li, Tianhang Zhu, Wen Xie, Wenhao Huang, Xiang He, Xiaobo Chen, Xiaohui Hu, Xiaoyi Ren, Xinyao Niu, Yanpeng Li, Yongke Zhao, Yongzhen Luo, Yuchi Xu, Yuxuan Sha, Zhaodong Yan, Zhiyuan Liu, Zirui Zhang, and Zonghong Dai.\n\n</span>\n<span class=\"ltx_bibblock\">Yi-lightning technical report, 2025.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2412.01253\" title=\"\">https://arxiv.org/abs/2412.01253</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib40\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Wang et\u00a0al. (2024)</span>\n<span class=\"ltx_bibblock\">\nZhilin Wang, Yi\u00a0Dong, Olivier Delalleau, Jiaqi Zeng, Gerald Shen, Daniel Egert, Jimmy\u00a0J. Zhang, Makesh\u00a0Narsimhan Sreedhar, and Oleksii Kuchaiev.\n\n</span>\n<span class=\"ltx_bibblock\">Helpsteer 2: Open-source dataset for training top-performing reward models.\n\n</span>\n<span class=\"ltx_bibblock\">In <em class=\"ltx_emph ltx_font_italic\">The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track</em>, 2024.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://openreview.net/forum?id=PvVKUFhaNy\" title=\"\">https://openreview.net/forum?id=PvVKUFhaNy</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib41\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Wang et\u00a0al. (2025a)</span>\n<span class=\"ltx_bibblock\">\nZhilin Wang, Alexander Bukharin, Olivier Delalleau, Daniel Egert, Gerald Shen, Jiaqi Zeng, Oleksii Kuchaiev, and Yi\u00a0Dong.\n\n</span>\n<span class=\"ltx_bibblock\">Helpsteer2-preference: Complementing ratings with preferences.\n\n</span>\n<span class=\"ltx_bibblock\">In <em class=\"ltx_emph ltx_font_italic\">The Thirteenth International Conference on Learning Representations</em>, 2025a.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://openreview.net/forum?id=MnfHxPP5gs\" title=\"\">https://openreview.net/forum?id=MnfHxPP5gs</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib42\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Wang et\u00a0al. (2025b)</span>\n<span class=\"ltx_bibblock\">\nZhilin Wang, Jiaqi Zeng, Olivier Delalleau, Daniel Egert, Ellie Evans, Hoo-Chang Shin, Felipe Soares, Yi\u00a0Dong, and Oleksii Kuchaiev.\n\n</span>\n<span class=\"ltx_bibblock\">HelpSteer3: Human-annotated feedback and edit data to empower inference-time scaling in open-ended general-domain tasks.\n\n</span>\n<span class=\"ltx_bibblock\">In Wanxiang Che, Joyce Nabende, Ekaterina Shutova, and Mohammad\u00a0Taher Pilehvar (eds.), <em class=\"ltx_emph ltx_font_italic\">Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pp.  25640\u201325662, Vienna, Austria, July 2025b. Association for Computational Linguistics.\n\n</span>\n<span class=\"ltx_bibblock\">ISBN 979-8-89176-251-0.\n\n</span>\n<span class=\"ltx_bibblock\">doi: <span class=\"ltx_ref ltx_nolink ltx_Url ltx_ref_self\">10.18653/v1/2025.acl-long.1246</span>.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://aclanthology.org/2025.acl-long.1246/\" title=\"\">https://aclanthology.org/2025.acl-long.1246/</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib43\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Wang et\u00a0al. (2025c)</span>\n<span class=\"ltx_bibblock\">\nZhilin Wang, Jiaqi Zeng, Olivier Delalleau, Hoo-Chang Shin, Felipe Soares, Alexander Bukharin, Ellie Evans, Yi\u00a0Dong, and Oleksii Kuchaiev.\n\n</span>\n<span class=\"ltx_bibblock\">Helpsteer3-preference: Open human-annotated preference data across diverse tasks and languages, 2025c.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2505.11475\" title=\"\">https://arxiv.org/abs/2505.11475</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib44\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Wei et\u00a0al. (2022)</span>\n<span class=\"ltx_bibblock\">\nJason Wei, Maarten Bosma, Vincent\u00a0Y. Zhao, Kelvin Guu, Adams\u00a0Wei Yu, Brian Lester, Nan Du, Andrew\u00a0M. Dai, and Quoc\u00a0V. Le.\n\n</span>\n<span class=\"ltx_bibblock\">Finetuned language models are zero-shot learners, 2022.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2109.01652\" title=\"\">https://arxiv.org/abs/2109.01652</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib45\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Weng (2024)</span>\n<span class=\"ltx_bibblock\">\nLilian Weng.\n\n</span>\n<span class=\"ltx_bibblock\">Reward hacking in reinforcement learning.\n\n</span>\n<span class=\"ltx_bibblock\"><em class=\"ltx_emph ltx_font_italic\">lilianweng.github.io</em>, Nov 2024.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://lilianweng.github.io/posts/2024-11-28-reward-hacking/\" title=\"\">https://lilianweng.github.io/posts/2024-11-28-reward-hacking/</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib46\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Yang et\u00a0al. (2025a)</span>\n<span class=\"ltx_bibblock\">\nAn\u00a0Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo\u00a0Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, Chujie Zheng, Dayiheng Liu, Fan Zhou, Fei Huang, Feng Hu, Hao Ge, Haoran Wei, Huan Lin, Jialong Tang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jing Zhou, Jingren Zhou, Junyang Lin, Kai Dang, Keqin Bao, Kexin Yang, Le\u00a0Yu, Lianghao Deng, Mei Li, Mingfeng Xue, Mingze Li, Pei Zhang, Peng Wang, Qin Zhu, Rui Men, Ruize Gao, Shixuan Liu, Shuang Luo, Tianhao Li, Tianyi Tang, Wenbiao Yin, Xingzhang Ren, Xinyu Wang, Xinyu Zhang, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yinger Zhang, Yu\u00a0Wan, Yuqiong Liu, Zekun Wang, Zeyu Cui, Zhenru Zhang, Zhipeng Zhou, and Zihan Qiu.\n\n</span>\n<span class=\"ltx_bibblock\">Qwen3 technical report, 2025a.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2505.09388\" title=\"\">https://arxiv.org/abs/2505.09388</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib47\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Yang et\u00a0al. (2025b)</span>\n<span class=\"ltx_bibblock\">\nAn\u00a0Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo\u00a0Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, et\u00a0al.\n\n</span>\n<span class=\"ltx_bibblock\">Qwen3 technical report.\n\n</span>\n<span class=\"ltx_bibblock\"><em class=\"ltx_emph ltx_font_italic\">arXiv preprint arXiv:2505.09388</em>, 2025b.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib48\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Yu et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nZhuohao Yu, Jiali Zeng, Weizheng Gu, Yidong Wang, Jindong Wang, Fandong Meng, Jie Zhou, Yue Zhang, Shikun Zhang, and Wei Ye.\n\n</span>\n<span class=\"ltx_bibblock\">Rewardanything: Generalizable principle-following reward models, 2025.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2506.03637\" title=\"\">https://arxiv.org/abs/2506.03637</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib49\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Zhang et\u00a0al. (2024)</span>\n<span class=\"ltx_bibblock\">\nLunjun Zhang, Arian Hosseini, Hritik Bansal, Mehran Kazemi, Aviral Kumar, and Rishabh Agarwal.\n\n</span>\n<span class=\"ltx_bibblock\">Generative verifiers: Reward modeling as next-token prediction, 2024.\n\n</span>\n<span class=\"ltx_bibblock\"><em class=\"ltx_emph ltx_font_italic\">URL https://arxiv. org/abs/2408.15240</em>, 2024.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib50\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Zhang et\u00a0al. (2025)</span>\n<span class=\"ltx_bibblock\">\nYanzhao Zhang, Mingxin Li, Dingkun Long, Xin Zhang, Huan Lin, Baosong Yang, Pengjun Xie, An\u00a0Yang, Dayiheng Liu, Junyang Lin, Fei Huang, and Jingren Zhou.\n\n</span>\n<span class=\"ltx_bibblock\">Qwen3 embedding: Advancing text embedding and reranking through foundation models, 2025.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2506.05176\" title=\"\">https://arxiv.org/abs/2506.05176</a>.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib51\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Zheng et\u00a0al. (2023)</span>\n<span class=\"ltx_bibblock\">\nLianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi\u00a0Lin, Zhuohan Li, Dacheng Li, Eric.\u00a0P Xing, Hao Zhang, Joseph\u00a0E. Gonzalez, and Ion Stoica.\n\n</span>\n<span class=\"ltx_bibblock\">Judging llm-as-a-judge with mt-bench and chatbot arena, 2023.\n\n</span>\n</li>\n<li class=\"ltx_bibitem\" id=\"bib.bib52\">\n<span class=\"ltx_tag ltx_role_refnum ltx_tag_bibitem\">Zhu et\u00a0al. (2024)</span>\n<span class=\"ltx_bibblock\">\nBanghua Zhu, Michael\u00a0I. Jordan, and Jiantao Jiao.\n\n</span>\n<span class=\"ltx_bibblock\">Iterative data smoothing: Mitigating reward overfitting and overoptimization in rlhf, 2024.\n\n</span>\n<span class=\"ltx_bibblock\">URL <a class=\"ltx_ref ltx_url ltx_font_typewriter\" href=\"https://arxiv.org/abs/2401.16335\" title=\"\">https://arxiv.org/abs/2401.16335</a>.\n\n</span>\n</li>\n</ul>\n</section>\n<div class=\"ltx_pagination ltx_role_newpage\"></div>\n<section class=\"ltx_appendix\" id=\"A1\">\n<h2 class=\"ltx_title ltx_title_appendix\" id=\"appendix-a-prompt-templates\">\n<span class=\"ltx_tag ltx_tag_appendix\">Appendix A </span>Prompt Templates</h2>\n<section class=\"ltx_paragraph\" id=\"A1.SS0.SSS0.Px1\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"extracting-principles-and-fulfillment\">Extracting Principles and Fulfillment</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"A1.SS0.SSS0.Px1.p1\">\n\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"A1.SS0.SSS0.Px2\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"scalar-reward-model\">Scalar Reward Model</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"A1.SS0.SSS0.Px2.p1\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"A1.SS0.SSS0.Px2.p2\">\n<p class=\"ltx_p\">For evaluation, here are the principles used:</p>\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"A1.SS0.SSS0.Px2.p3\">\n<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">PrincipleBench</span></p>\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"A1.SS0.SSS0.Px2.p4\">\n<ul class=\"ltx_itemize\" id=\"A1.I1\">\n<li class=\"ltx_item\" id=\"A1.I1.i1\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">\u2022</span>\n<div class=\"ltx_para\" id=\"A1.I1.i1.p1\">\n<p class=\"ltx_p\">Clarity: clarity of expression</p>\n</div>\n</li>\n<li class=\"ltx_item\" id=\"A1.I1.i2\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">\u2022</span>\n<div class=\"ltx_para\" id=\"A1.I1.i2.p1\">\n<p class=\"ltx_p\">Accuracy: accuracy of facts</p>\n</div>\n</li>\n<li class=\"ltx_item\" id=\"A1.I1.i3\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">\u2022</span>\n<div class=\"ltx_para\" id=\"A1.I1.i3.p1\">\n<p class=\"ltx_p\">Relevance: alignment with prompt</p>\n</div>\n</li>\n<li class=\"ltx_item\" id=\"A1.I1.i4\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">\u2022</span>\n<div class=\"ltx_para\" id=\"A1.I1.i4.p1\">\n<p class=\"ltx_p\">No Repetition: avoidance of repetition</p>\n</div>\n</li>\n<li class=\"ltx_item\" id=\"A1.I1.i5\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">\u2022</span>\n<div class=\"ltx_para\" id=\"A1.I1.i5.p1\">\n<p class=\"ltx_p\">Language Alignment: language compliance</p>\n</div>\n</li>\n<li class=\"ltx_item\" id=\"A1.I1.i6\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">\u2022</span>\n<div class=\"ltx_para\" id=\"A1.I1.i6.p1\">\n<p class=\"ltx_p\">Essential Information: completeness of essential information</p>\n</div>\n</li>\n<li class=\"ltx_item\" id=\"A1.I1.i7\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">\u2022</span>\n<div class=\"ltx_para ltx_noindent\" id=\"A1.I1.i7.p1\">\n<p class=\"ltx_p\">Requirements Complete: adherence to prompt requirements</p>\n</div>\n</li>\n</ul>\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"A1.SS0.SSS0.Px2.p5\">\n<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">RM-Bench</span></p>\n<ul class=\"ltx_itemize\" id=\"A1.I2\">\n<li class=\"ltx_item\" id=\"A1.I2.i1\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">\u2022</span>\n<div class=\"ltx_para\" id=\"A1.I2.i1.p1\">\n<p class=\"ltx_p\">Math: correctness of answer</p>\n</div>\n</li>\n<li class=\"ltx_item\" id=\"A1.I2.i2\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">\u2022</span>\n<div class=\"ltx_para\" id=\"A1.I2.i2.p1\">\n<p class=\"ltx_p\">Chat: accuracy of facts</p>\n</div>\n</li>\n<li class=\"ltx_item\" id=\"A1.I2.i3\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">\u2022</span>\n<div class=\"ltx_para\" id=\"A1.I2.i3.p1\">\n<p class=\"ltx_p\">Code: accuracy</p>\n</div>\n</li>\n<li class=\"ltx_item\" id=\"A1.I2.i4\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">\u2022</span>\n<div class=\"ltx_para\" id=\"A1.I2.i4.p1\">\n<p class=\"ltx_p\">Safety-Refuse: safety compliance</p>\n</div>\n</li>\n<li class=\"ltx_item\" id=\"A1.I2.i5\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">\u2022</span>\n<div class=\"ltx_para ltx_noindent\" id=\"A1.I2.i5.p1\">\n<p class=\"ltx_p\">Safety-Respond: compliance with prompt instructions</p>\n</div>\n</li>\n</ul>\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"A1.SS0.SSS0.Px2.p6\">\n<p class=\"ltx_p\"><span class=\"ltx_text ltx_font_bold\">JudgeBench</span></p>\n<ul class=\"ltx_itemize\" id=\"A1.I3\">\n<li class=\"ltx_item\" id=\"A1.I3.i1\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">\u2022</span>\n<div class=\"ltx_para\" id=\"A1.I3.i1.p1\">\n<p class=\"ltx_p\">Knowledge: accuracy</p>\n</div>\n</li>\n<li class=\"ltx_item\" id=\"A1.I3.i2\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">\u2022</span>\n<div class=\"ltx_para\" id=\"A1.I3.i2.p1\">\n<p class=\"ltx_p\">Reasoning: ethical compliance</p>\n</div>\n</li>\n<li class=\"ltx_item\" id=\"A1.I3.i3\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">\u2022</span>\n<div class=\"ltx_para\" id=\"A1.I3.i3.p1\">\n<p class=\"ltx_p\">Math: correctness of answer</p>\n</div>\n</li>\n<li class=\"ltx_item\" id=\"A1.I3.i4\" style=\"list-style-type:none;\">\n<span class=\"ltx_tag ltx_tag_item\">\u2022</span>\n<div class=\"ltx_para ltx_noindent\" id=\"A1.I3.i4.p1\">\n<p class=\"ltx_p\">Code: instruction compliance</p>\n</div>\n</li>\n</ul>\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"A1.SS0.SSS0.Px3\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"generative-reward-model\">Generative Reward Model</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"A1.SS0.SSS0.Px3.p1\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"A1.SS0.SSS0.Px3.p2\">\n<span class=\"ltx_inline-block\"><svg class=\"ltx_picture\" height=\"388.55\" id=\"A1.SS0.SSS0.Px3.p2.pic1\" overflow=\"visible\" version=\"1.1\" viewbox=\"0 0 600 388.55\" width=\"600\"><g fill=\"#000000\" stroke=\"#000000\" stroke-width=\"0.4pt\" style=\"--ltx-stroke-color:#000000;--ltx-fill-color:#000000;\" transform=\"translate(0,388.55) matrix(1 0 0 -1 0 0)\"><g fill=\"#404040\" fill-opacity=\"1.0\" style=\"--ltx-fill-color:#404040;\"><path d=\"M 0 5.91 L 0 382.65 C 0 385.91 2.64 388.55 5.91 388.55 L 594.09 388.55 C 597.36 388.55 600 385.91 600 382.65 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z\" style=\"stroke:none\"></path></g><g fill=\"#F2F2F2\" fill-opacity=\"1.0\" style=\"--ltx-fill-color:#F2F2F2;\"><path d=\"M 1.97 5.91 L 1.97 382.65 C 1.97 384.82 3.73 386.58 5.91 386.58 L 594.09 386.58 C 596.27 386.58 598.03 384.82 598.03 382.65 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z\" style=\"stroke:none\"></path></g><g fill-opacity=\"1.0\" transform=\"matrix(1.0 0.0 0.0 1.0 21.65 16.47)\"><foreignobject color=\"#000000\" height=\"360.99\" overflow=\"visible\" style=\"--ltx-fg-color:#000000;--fo_width :40.23em;--fo_height:25.89em;--fo_depth :0.19em;\" transform=\"matrix(1 0 0 -1 0 358.3)\" width=\"556.69\"><span class=\"ltx_foreignobject_container\"><span class=\"ltx_foreignobject_content\">\n<span class=\"ltx_inline-block ltx_minipage ltx_align_bottom\" style=\"width:40.23em;\">\n<span class=\"ltx_p\">You are an expert evaluator tasked with assessing assistant responses based on specific principles. Below is a multi-turn conversation between a user and an assistant. Your task is to judge whether the last assistant response adheres to the specified principle.</span>\n<span class=\"ltx_p\">[Start of Conversation]</span>\n<span class=\"ltx_p\">User:</span>\n<span class=\"ltx_p\">xxxxx</span>\n<span class=\"ltx_p\">Assistant:</span>\n<span class=\"ltx_p\">xxxxx</span>\n<span class=\"ltx_p\">User:</span>\n<span class=\"ltx_p\">xxxxx</span>\n<span class=\"ltx_p\">Assistant:</span>\n<span class=\"ltx_p\">xxxxx</span>\n<span class=\"ltx_p\">[End of Conversation]</span>\n<span class=\"ltx_p\">[Start of Principle]</span>\n<span class=\"ltx_p\">xxxxx</span>\n<span class=\"ltx_p\">[End of Principle]</span>\n<span class=\"ltx_p\">Your task:</span>\n<span class=\"ltx_p\">1. Carefully read the entire conversation.</span>\n<span class=\"ltx_p\">2. Judge whether the assistant\u2019s final response adheres to the principle above.</span>\n<span class=\"ltx_p\">3. Think step by step, citing concrete evidence from the conversation.</span>\n<span class=\"ltx_p\">4. After your reasoning, output exactly: \u201cFinal Judgment: Yes\u201d or \u201cFinal Judgment: No\u201d.</span>\n<span class=\"ltx_p\">Do NOT output anything after the line that contains the final judgment.</span>\n</span></span></span></foreignobject></g></g></svg></span>\n</div>\n</section>\n</section>\n<section class=\"ltx_appendix\" id=\"A2\">\n<h2 class=\"ltx_title ltx_title_appendix\" id=\"appendix-b-training-details\">\n<span class=\"ltx_tag ltx_tag_appendix\">Appendix B </span>Training Details</h2>\n<section class=\"ltx_paragraph\" id=\"A2.SS0.SSS0.Px1\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"scalar-reward-model\">Scalar Reward Model</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"A2.SS0.SSS0.Px1.p1\">\n\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"A2.SS0.SSS0.Px2\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"generative-reward-model\">Generative Reward Model</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"A2.SS0.SSS0.Px2.p1\">\n\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"A2.SS0.SSS0.Px3\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"model-alignment\">Model Alignment</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"A2.SS0.SSS0.Px3.p1\">\n\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"A2.SS0.SSS0.Px4\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"compute-requirements-and-optimal-hyperparameters\">Compute Requirements and Optimal Hyperparameters</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"A2.SS0.SSS0.Px4.p1\">\n\n</div>\n<figure class=\"ltx_table\" id=\"A2.T6\">\n<figcaption class=\"ltx_caption ltx_centering\"><span class=\"ltx_tag ltx_tag_table\">Table 6: </span>Compute required and optimal hyperparameters for training each model, measured in H100-node-hours. Experiments are run on nodes of 8 H100-80GB SXM GPUs on internal clusters.</figcaption>\n<div class=\"ltx_inline-block ltx_align_center ltx_transformed_outer\" style=\"width:351.3pt;height:111.2pt;vertical-align:-53.1pt;\"><span class=\"ltx_transformed_inner\" style=\"transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;\">\n\n</span></div>\n</figure>\n</section>\n</section>\n<section class=\"ltx_appendix\" id=\"A3\">\n<h2 class=\"ltx_title ltx_title_appendix\" id=\"appendix-c-reward-model-results\">\n<span class=\"ltx_tag ltx_tag_appendix\">Appendix C </span>Reward Model Results</h2>\n<div class=\"ltx_para ltx_noindent\" id=\"A3.p1\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"A3.p2\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"A3.p3\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"A3.p4\">\n<p class=\"ltx_p\">If we use the domain-average and calculate a sample-average, we get:</p>\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"A3.p5\">\n\n</div>\n<div class=\"ltx_para ltx_noindent\" id=\"A3.p6\">\n\n</div>\n</section>\n<section class=\"ltx_appendix\" id=\"A4\">\n<h2 class=\"ltx_title ltx_title_appendix\" id=\"appendix-d-model-alignment-evaluation-details\">\n<span class=\"ltx_tag ltx_tag_appendix\">Appendix D </span>Model Alignment Evaluation Details</h2>\n<section class=\"ltx_paragraph\" id=\"A4.SS0.SSS0.Px1\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"inference\">Inference</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"A4.SS0.SSS0.Px1.p1\">\n\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"A4.SS0.SSS0.Px2\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"mt-bench\">MT-Bench</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"A4.SS0.SSS0.Px2.p1\">\n\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"A4.SS0.SSS0.Px3\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"wildbench\">WildBench</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"A4.SS0.SSS0.Px3.p1\">\n\n</div>\n</section>\n<section class=\"ltx_paragraph\" id=\"A4.SS0.SSS0.Px4\">\n<h4 class=\"ltx_title ltx_title_paragraph\" id=\"arena-hard\">Arena Hard</h4>\n<div class=\"ltx_para ltx_noindent\" id=\"A4.SS0.SSS0.Px4.p1\">\n\n</div>\n</section>\n</section>\n</article>\n</div>\n\n</div>",
    "sections": [
      {
        "id": "rlbff-binary-flexible-feedback-to-bridge-between-human-feedback-verifiable-rewards",
        "title": "RLBFF: Binary Flexible Feedback to bridge between Human Feedback & Verifiable Rewards",
        "level": 1
      },
      {
        "id": "abstract",
        "title": "Abstract",
        "level": 6
      },
      {
        "id": "1-introduction",
        "title": "1 Introduction",
        "level": 2
      },
      {
        "id": "formulation",
        "title": "Formulation",
        "level": 4
      },
      {
        "id": "motivation",
        "title": "Motivation",
        "level": 4
      },
      {
        "id": "wide-coverage",
        "title": "Wide Coverage",
        "level": 4
      },
      {
        "id": "interpretability",
        "title": "Interpretability",
        "level": 4
      },
      {
        "id": "precision-and-recall",
        "title": "Precision and Recall",
        "level": 4
      },
      {
        "id": "training-reward-models-using-binary-flexible-feedback",
        "title": "Training Reward Models using Binary Flexible Feedback",
        "level": 4
      },
      {
        "id": "main-contributions",
        "title": "Main Contributions",
        "level": 4
      },
      {
        "id": "2-related-work",
        "title": "2 Related Work",
        "level": 2
      },
      {
        "id": "binary-flexible-feedback-for-safety-and-math",
        "title": "Binary Flexible Feedback for Safety and Math",
        "level": 4
      },
      {
        "id": "generative-rewards-models-with-self-generated-criteria",
        "title": "Generative Rewards Models with Self-Generated Criteria",
        "level": 4
      },
      {
        "id": "principle-following-generative-reward-models",
        "title": "Principle-Following Generative Reward Models",
        "level": 4
      },
      {
        "id": "3-training-data",
        "title": "3 Training Data",
        "level": 2
      },
      {
        "id": "downloading-helpsteer3-feedback",
        "title": "Downloading HelpSteer3-Feedback",
        "level": 4
      },
      {
        "id": "extracting-principles-and-fulfillment",
        "title": "Extracting Principles and Fulfillment",
        "level": 4
      },
      {
        "id": "filtering-principles-unsupported-by-feedback",
        "title": "Filtering Principles Unsupported by Feedback",
        "level": 4
      },
      {
        "id": "removing-partially-fulfilled-principles",
        "title": "Removing Partially Fulfilled Principles",
        "level": 4
      },
      {
        "id": "obtaining-high-precision-consensus-principles",
        "title": "Obtaining High-Precision Consensus Principles",
        "level": 4
      },
      {
        "id": "human-verification",
        "title": "Human Verification",
        "level": 4
      },
      {
        "id": "principle-distribution",
        "title": "Principle Distribution",
        "level": 4
      },
      {
        "id": "4-reward-modeling",
        "title": "4 Reward Modeling",
        "level": 2
      },
      {
        "id": "41-evaluation",
        "title": "4.1 Evaluation",
        "level": 3
      },
      {
        "id": "rm-bench-and-judgebench",
        "title": "RM-Bench and JudgeBench",
        "level": 4
      },
      {
        "id": "principlebench",
        "title": "PrincipleBench",
        "level": 4
      },
      {
        "id": "42-baselines",
        "title": "4.2 Baselines",
        "level": 3
      },
      {
        "id": "scalar-reward-models",
        "title": "Scalar Reward Models",
        "level": 4
      },
      {
        "id": "generative-reward-models",
        "title": "Generative Reward Models",
        "level": 4
      },
      {
        "id": "43-training",
        "title": "4.3 Training",
        "level": 3
      },
      {
        "id": "scalar-reward-models",
        "title": "Scalar Reward Models",
        "level": 4
      },
      {
        "id": "generative-reward-models",
        "title": "Generative Reward Models",
        "level": 4
      },
      {
        "id": "44-results",
        "title": "4.4 Results",
        "level": 3
      },
      {
        "id": "flexible-principles-are-the-top-performing-model-across-scalar-and-generative-rms",
        "title": "Flexible Principles are the top performing model across Scalar and Generative RMs",
        "level": 4
      },
      {
        "id": "poor-performance-of-baseline-genrms-on-judgebench",
        "title": "Poor Performance of Baseline GenRMs on JudgeBench",
        "level": 4
      },
      {
        "id": "flexible-principles-is-the-first-scalar-rm-to-enable-grounding-by-user-specified-principles",
        "title": "Flexible Principles is the first Scalar RM to enable grounding by user-specified principles",
        "level": 4
      },
      {
        "id": "poor-performance-of-genrms-on-principlebench-relative-to-scalar-rms",
        "title": "Poor Performance of GenRMs on PrincipleBench relative to Scalar RMs",
        "level": 4
      },
      {
        "id": "5-ablation-studies",
        "title": "5 Ablation Studies",
        "level": 2
      },
      {
        "id": "group-similarity-threshold-for-filtering-consensus-principles",
        "title": "Group Similarity Threshold for Filtering Consensus Principles",
        "level": 4
      },
      {
        "id": "fixing-principle-to-accuracy-of-information-at-test-time",
        "title": "Fixing Principle to Accuracy of Information at Test Time",
        "level": 4
      },
      {
        "id": "6-model-alignment",
        "title": "6 Model Alignment",
        "level": 2
      },
      {
        "id": "evaluation",
        "title": "Evaluation",
        "level": 4
      },
      {
        "id": "training",
        "title": "Training",
        "level": 4
      },
      {
        "id": "results",
        "title": "Results",
        "level": 4
      },
      {
        "id": "7-conclusion",
        "title": "7 Conclusion",
        "level": 2
      },
      {
        "id": "reproducibility-statement",
        "title": "Reproducibility statement",
        "level": 2
      },
      {
        "id": "references",
        "title": "References",
        "level": 2
      },
      {
        "id": "appendix-a-prompt-templates",
        "title": "Appendix A Prompt Templates",
        "level": 2
      },
      {
        "id": "extracting-principles-and-fulfillment",
        "title": "Extracting Principles and Fulfillment",
        "level": 4
      },
      {
        "id": "scalar-reward-model",
        "title": "Scalar Reward Model",
        "level": 4
      },
      {
        "id": "generative-reward-model",
        "title": "Generative Reward Model",
        "level": 4
      },
      {
        "id": "appendix-b-training-details",
        "title": "Appendix B Training Details",
        "level": 2
      },
      {
        "id": "scalar-reward-model",
        "title": "Scalar Reward Model",
        "level": 4
      },
      {
        "id": "generative-reward-model",
        "title": "Generative Reward Model",
        "level": 4
      },
      {
        "id": "model-alignment",
        "title": "Model Alignment",
        "level": 4
      },
      {
        "id": "compute-requirements-and-optimal-hyperparameters",
        "title": "Compute Requirements and Optimal Hyperparameters",
        "level": 4
      },
      {
        "id": "appendix-c-reward-model-results",
        "title": "Appendix C Reward Model Results",
        "level": 2
      },
      {
        "id": "appendix-d-model-alignment-evaluation-details",
        "title": "Appendix D Model Alignment Evaluation Details",
        "level": 2
      },
      {
        "id": "inference",
        "title": "Inference",
        "level": 4
      },
      {
        "id": "mt-bench",
        "title": "MT-Bench",
        "level": 4
      },
      {
        "id": "wildbench",
        "title": "WildBench",
        "level": 4
      },
      {
        "id": "arena-hard",
        "title": "Arena Hard",
        "level": 4
      }
    ],
    "has_math": true
  },
  "cached_at": 1759020923.4089277
}